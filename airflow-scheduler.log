2025-10-22 14:02:20,756 INFO - Loaded executor: CeleryExecutor
2025-10-22 14:02:20,788 INFO - Starting the scheduler
2025-10-22 14:02:20,788 INFO - Processing each file at most -1 times
2025-10-22 14:02:20,793 INFO - Launched DagFileProcessorManager with pid: 14217
2025-10-22 14:02:20,795 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:02:20,799 INFO - Configured default timezone UTC
2025-10-22 14:07:20,863 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:12:20,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:17:20,947 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:22:20,991 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:27:21,033 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:32:21,088 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:37:21,125 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:42:21,167 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:47:21,205 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:52:21,244 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 14:57:21,276 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:02:21,327 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:07:21,367 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:12:21,412 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:17:21,453 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:22:21,493 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:27:21,535 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:32:21,583 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:37:21,629 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:42:21,673 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:47:21,719 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:52:21,763 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 15:57:21,804 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:02:21,861 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:07:21,896 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:12:21,936 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:17:21,970 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:22:22,007 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:27:22,042 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:32:22,082 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:37:22,127 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:42:22,168 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:47:22,225 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:52:22,271 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 16:57:22,320 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:02:22,381 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:07:22,428 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:12:22,480 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:17:22,532 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:22:22,579 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:27:22,623 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:32:22,672 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:37:22,720 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:42:22,761 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:47:22,804 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:52:22,844 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 17:57:22,886 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:02:22,936 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:07:22,973 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:12:23,013 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:17:23,066 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:22:23,106 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:27:23,147 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:32:23,202 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:37:23,240 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:42:23,283 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:47:23,328 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:52:23,369 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 18:57:23,411 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:02:23,467 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:07:23,511 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:12:23,552 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:17:23,592 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:22:23,631 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:27:23,647 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:32:23,709 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:37:23,743 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:42:23,787 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:47:23,834 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:52:23,878 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 19:57:23,934 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:02:23,996 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:07:24,043 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:12:24,082 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:17:24,125 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:22:24,171 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:27:24,224 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:32:24,258 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:37:24,301 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:42:24,354 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:47:24,403 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:52:24,447 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 20:57:24,497 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:02:24,553 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:07:24,583 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:12:24,629 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:17:24,667 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:22:24,710 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:27:24,751 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:32:24,802 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:37:24,847 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:42:24,886 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:47:24,930 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:52:24,971 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 21:57:25,008 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:02:25,059 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:07:25,092 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:12:25,130 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:17:25,164 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:22:25,196 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:27:25,231 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:32:25,281 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:37:25,316 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:42:25,348 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:47:25,381 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:52:25,415 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 22:57:25,451 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:02:25,508 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:07:25,544 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:12:25,582 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:17:25,629 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:22:25,663 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:27:25,699 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:32:25,751 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:37:25,786 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:42:25,818 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:47:25,850 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:52:25,884 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-22 23:57:25,928 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:02:25,990 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:07:26,040 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:12:26,097 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:17:26,147 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:22:26,197 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:27:26,234 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:32:26,295 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:37:26,331 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:42:26,371 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:47:26,406 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:52:26,441 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 00:57:26,476 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:02:26,535 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:07:26,569 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:12:26,611 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:17:26,649 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:22:26,702 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:27:26,756 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:32:26,791 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:37:26,828 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:42:26,861 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:47:26,899 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:52:26,937 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 01:57:26,975 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:02:27,037 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:07:27,074 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:12:27,111 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:17:27,152 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:22:27,200 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:27:27,246 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:32:27,296 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:37:27,338 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:42:27,379 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:47:27,436 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:52:27,479 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 02:57:27,522 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:02:27,569 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:07:27,609 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:12:27,646 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:17:27,686 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:22:27,736 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:27:27,778 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:32:27,831 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:37:27,870 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:42:27,910 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:47:27,949 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:52:27,989 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 03:57:28,006 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:02:28,042 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:07:28,074 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:12:28,119 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:17:28,161 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:22:28,205 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:27:28,246 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:32:28,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:37:28,315 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:42:28,352 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:47:28,394 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:52:28,436 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 04:57:28,474 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:02:28,515 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:07:28,549 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:12:28,582 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:17:28,617 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:22:28,652 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:27:28,683 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:32:28,748 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:37:28,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:40:31,966 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [scheduled]>
2025-10-23 05:40:31,967 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 05:40:31,967 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [scheduled]>
2025-10-23 05:40:31,970 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 05:40:31,971 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T05:40:31.792195+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-23 05:40:31,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-23T05:40:31.792195+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 05:40:32,112 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T05:40:31.792195+00:00', try_number=1, map_index=-1)
2025-10-23 05:40:32,122 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> to ce8a2be8-54aa-4243-a863-7e5569cf427e
2025-10-23 05:42:28,860 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:47:28,950 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:50:38,979 WARNING - Marking task instance <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> stuck in queued as failed. If the task instance has available retries, it will be retried.
2025-10-23 05:50:40,031 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T05:40:31.792195+00:00', try_number=1, map_index=-1)
2025-10-23 05:50:40,037 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-23T05:40:31.792195+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=CeleryExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-23 05:40:31.968620+00:00, queued_by_job_id=1, pid=None
2025-10-23 05:50:40,038 ERROR - Executor CeleryExecutor(parallelism=32) reported that the task instance <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-10-23 05:50:40,044 ERROR - Executor CeleryExecutor(parallelism=32) reported that the task instance <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-10-23 05:50:40,055 INFO - Marking task as FAILED. dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-23T05:40:31.792195+00:00, execution_date=20251023T054031, start_date=, end_date=20251023T055040
2025-10-23 05:50:42,711 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [scheduled]>
2025-10-23 05:50:42,712 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 05:50:42,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [scheduled]>
2025-10-23 05:50:42,714 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 05:50:42,716 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T05:40:31.792195+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-23 05:50:42,716 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'stop_remote_worker', 'manual__2025-10-23T05:40:31.792195+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 05:50:42,783 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T05:40:31.792195+00:00', try_number=1, map_index=-1)
2025-10-23 05:50:42,789 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> to e8a5662a-c474-4099-858b-993867b94750
2025-10-23 05:52:29,013 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 05:57:29,079 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 06:02:29,163 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 06:02:39,404 WARNING - Marking task instance <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> stuck in queued as failed. If the task instance has available retries, it will be retried.
2025-10-23 06:02:40,437 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T05:40:31.792195+00:00', try_number=1, map_index=-1)
2025-10-23 06:02:40,441 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-23T05:40:31.792195+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=CeleryExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=RemoteWorkerStopOperator, queued_dttm=2025-10-23 05:50:42.713114+00:00, queued_by_job_id=1, pid=None
2025-10-23 06:02:40,442 ERROR - Executor CeleryExecutor(parallelism=32) reported that the task instance <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-10-23 06:02:40,446 ERROR - Executor CeleryExecutor(parallelism=32) reported that the task instance <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T05:40:31.792195+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2025-10-23 06:02:40,452 INFO - Marking task as FAILED. dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-23T05:40:31.792195+00:00, execution_date=20251023T054031, start_date=, end_date=20251023T060240
2025-10-23 06:02:41,154 ERROR - Marking run <DagRun test_ondemand_worker @ 2025-10-23 05:40:31.792195+00:00: manual__2025-10-23T05:40:31.792195+00:00, state:running, queued_at: 2025-10-23 05:40:31.829679+00:00. externally triggered: True> failed
2025-10-23 06:02:41,155 INFO - DagRun Finished: dag_id=test_ondemand_worker, execution_date=2025-10-23 05:40:31.792195+00:00, run_id=manual__2025-10-23T05:40:31.792195+00:00, run_start_date=2025-10-23 05:40:31.915413+00:00, run_end_date=2025-10-23 06:02:41.154937+00:00, run_duration=1329.239524, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-23 05:40:31.792195+00:00, data_interval_end=2025-10-23 05:40:31.792195+00:00, dag_hash=929e78c82e47dfdab76aa5816e4d7647
2025-10-23 06:07:29,196 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 06:12:29,236 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 07:32:49,353 INFO - Loaded executor: CeleryExecutor
2025-10-23 07:32:49,397 INFO - Starting the scheduler
2025-10-23 07:32:49,398 INFO - Processing each file at most -1 times
2025-10-23 07:32:49,403 INFO - Launched DagFileProcessorManager with pid: 54864
2025-10-23 07:32:49,405 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 07:32:49,412 INFO - Configured default timezone UTC
2025-10-23 07:37:49,463 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 07:42:49,497 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 07:45:30,992 INFO - Exiting gracefully upon receiving signal 15
2025-10-23 07:45:31,093 INFO - Sending 15 to group 54864. PIDs of all processes in the group: []
2025-10-23 07:45:31,094 INFO - Sending the signal 15 to group 54864
2025-10-23 07:45:31,094 INFO - Sending the signal 15 to process 54864 as process group is missing.
2025-10-23 07:45:31,095 INFO - Sending 15 to group 54864. PIDs of all processes in the group: []
2025-10-23 07:45:31,095 INFO - Sending the signal 15 to group 54864
2025-10-23 07:45:31,095 INFO - Sending the signal 15 to process 54864 as process group is missing.
2025-10-23 07:45:31,095 INFO - Exited execute loop
2025-10-23 07:45:36,077 INFO - Loaded executor: CeleryExecutor
2025-10-23 07:45:36,112 INFO - Starting the scheduler
2025-10-23 07:45:36,113 INFO - Processing each file at most -1 times
2025-10-23 07:45:36,119 INFO - Launched DagFileProcessorManager with pid: 55507
2025-10-23 07:45:36,121 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 07:45:36,129 INFO - Configured default timezone UTC
2025-10-23 07:47:10,387 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T07:33:50+00:00 [scheduled]>
2025-10-23 07:47:10,388 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 07:47:10,388 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T07:33:50+00:00 [scheduled]>
2025-10-23 07:47:10,391 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T07:33:50+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 07:47:10,391 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T07:33:50+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-23 07:47:10,392 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-23T07:33:50+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 07:47:10,540 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T07:33:50+00:00', try_number=1, map_index=-1)
2025-10-23 07:47:10,555 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T07:33:50+00:00 [queued]> to 5f4a815f-521b-4914-b38b-93112f6f6baa
2025-10-23 07:47:19,531 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T07:33:50+00:00', try_number=1, map_index=-1)
2025-10-23 07:47:19,536 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-23T07:33:50+00:00, map_index=-1, run_start_date=2025-10-23 07:47:10.907503+00:00, run_end_date=2025-10-23 07:47:18.557904+00:00, run_duration=7.650401, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-23 07:47:10.389098+00:00, queued_by_job_id=3, pid=55626
2025-10-23 07:50:36,179 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 07:55:36,213 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:00:36,261 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:05:36,301 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:10:36,338 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:15:36,402 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:20:36,461 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:25:36,503 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:30:36,542 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:35:36,582 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:40:36,625 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:45:36,684 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:50:36,735 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 08:55:36,787 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:00:36,837 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:05:36,880 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:10:36,934 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:15:36,997 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:20:37,034 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:25:37,067 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:30:37,114 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:35:37,156 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:40:37,195 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:45:37,249 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:50:37,291 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 09:55:37,331 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:00:37,374 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:05:37,418 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:10:37,466 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:15:37,513 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:20:37,548 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:25:37,588 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:30:37,634 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:35:37,673 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:40:37,710 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:45:37,772 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:50:37,813 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 10:55:37,855 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:00:37,903 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:05:37,955 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:10:37,995 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:15:38,047 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:20:38,085 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:25:38,127 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:30:38,170 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:35:38,224 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:40:38,265 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:45:38,304 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:50:38,352 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 11:55:38,392 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:00:38,438 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:05:38,481 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:10:38,525 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:15:38,561 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:20:38,605 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:25:38,655 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:30:38,701 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:35:38,744 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:40:38,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:45:38,819 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:50:38,867 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 12:55:38,874 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:00:38,921 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:05:38,964 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:10:39,006 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:15:39,049 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:20:39,088 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:25:39,127 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:30:39,185 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:35:39,227 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:40:39,268 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:45:39,310 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:50:39,338 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 13:55:39,378 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:00:39,421 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:05:39,466 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:10:39,509 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:15:39,565 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:20:39,617 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:25:39,662 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:30:39,704 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:35:39,749 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:40:39,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:45:39,827 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:50:39,872 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 14:55:39,907 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:00:39,941 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:05:39,977 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:10:40,014 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:15:40,085 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:20:40,128 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:25:40,171 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:30:40,214 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:35:40,248 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:40:40,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:45:40,346 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:50:40,392 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 15:55:40,433 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:00:40,475 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:05:40,518 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:10:40,560 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:15:40,596 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:20:40,637 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:25:40,672 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:29:30,186 INFO - Exiting gracefully upon receiving signal 15
2025-10-23 16:29:30,294 INFO - Sending 15 to group 55507. PIDs of all processes in the group: []
2025-10-23 16:29:30,295 INFO - Sending the signal 15 to group 55507
2025-10-23 16:29:30,295 INFO - Sending the signal 15 to process 55507 as process group is missing.
2025-10-23 16:29:30,296 INFO - Sending 15 to group 55507. PIDs of all processes in the group: []
2025-10-23 16:29:30,296 INFO - Sending the signal 15 to group 55507
2025-10-23 16:29:30,296 INFO - Sending the signal 15 to process 55507 as process group is missing.
2025-10-23 16:29:30,297 INFO - Exited execute loop
2025-10-23 16:29:35,286 INFO - Loaded executor: CeleryExecutor
2025-10-23 16:29:35,318 INFO - Starting the scheduler
2025-10-23 16:29:35,319 INFO - Processing each file at most -1 times
2025-10-23 16:29:35,326 INFO - Launched DagFileProcessorManager with pid: 72151
2025-10-23 16:29:35,327 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:29:35,334 INFO - Configured default timezone UTC
2025-10-23 16:29:49,737 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T08:21:02+00:00 [scheduled]>
2025-10-23 16:29:49,737 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 16:29:49,738 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T08:21:02+00:00 [scheduled]>
2025-10-23 16:29:49,741 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T08:21:02+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 16:29:49,741 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T08:21:02+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-23 16:29:49,742 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-23T08:21:02+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 16:29:49,917 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T08:21:02+00:00', try_number=1, map_index=-1)
2025-10-23 16:29:49,930 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T08:21:02+00:00 [queued]> to 980bbf56-c64e-4909-bf3f-22bcc7f97826
2025-10-23 16:34:35,431 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:34:59,675 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T08:21:02+00:00', try_number=1, map_index=-1)
2025-10-23 16:34:59,681 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-23T08:21:02+00:00, map_index=-1, run_start_date=2025-10-23 16:29:50.373577+00:00, run_end_date=2025-10-23 16:34:59.283354+00:00, run_duration=308.909777, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=6, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-23 16:29:49.739098+00:00, queued_by_job_id=5, pid=72217
2025-10-23 16:35:00,154 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T08:21:02+00:00 [scheduled]>
2025-10-23 16:35:00,155 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 16:35:00,155 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T08:21:02+00:00 [scheduled]>
2025-10-23 16:35:00,157 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T08:21:02+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 16:35:00,158 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T08:21:02+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-23 16:35:00,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'stop_remote_worker', 'manual__2025-10-23T08:21:02+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 16:35:00,214 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T08:21:02+00:00', try_number=1, map_index=-1)
2025-10-23 16:35:00,225 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T08:21:02+00:00 [queued]> to d23c7980-1c13-447a-a621-480b5364c2f3
2025-10-23 16:35:09,702 INFO - Marking run <DagRun test_ondemand_worker @ 2025-10-23 08:21:02+00:00: manual__2025-10-23T08:21:02+00:00, state:running, queued_at: 2025-10-23 08:21:02.963382+00:00. externally triggered: True> successful
2025-10-23 16:35:09,706 INFO - DagRun Finished: dag_id=test_ondemand_worker, execution_date=2025-10-23 08:21:02+00:00, run_id=manual__2025-10-23T08:21:02+00:00, run_start_date=2025-10-23 16:29:49.553117+00:00, run_end_date=2025-10-23 16:35:09.705771+00:00, run_duration=320.152654, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-23 08:21:02+00:00, data_interval_end=2025-10-23 08:21:02+00:00, dag_hash=929e78c82e47dfdab76aa5816e4d7647
2025-10-23 16:35:09,741 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T08:21:02+00:00', try_number=1, map_index=-1)
2025-10-23 16:35:09,747 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-23T08:21:02+00:00, map_index=-1, run_start_date=2025-10-23 16:35:00.586401+00:00, run_end_date=2025-10-23 16:35:09.561934+00:00, run_duration=8.975533, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=1, operator=RemoteWorkerStopOperator, queued_dttm=2025-10-23 16:35:00.156182+00:00, queued_by_job_id=5, pid=72911
2025-10-23 16:39:35,476 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:44:35,511 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:44:51,774 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [scheduled]>
2025-10-23 16:44:51,774 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 16:44:51,774 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [scheduled]>
2025-10-23 16:44:51,777 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 16:44:51,777 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T16:44:51.076713+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-23 16:44:51,778 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-23T16:44:51.076713+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 16:44:51,862 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T16:44:51.076713+00:00', try_number=1, map_index=-1)
2025-10-23 16:44:51,869 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [queued]> to a1c1ba71-4e1b-4923-aef3-6e9ca91dbf5e
2025-10-23 16:49:35,595 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:50:02,242 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [scheduled]>
2025-10-23 16:50:02,243 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 16:50:02,243 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [scheduled]>
2025-10-23 16:50:02,246 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 16:50:02,246 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T16:44:51.076713+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-23 16:50:02,247 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'stop_remote_worker', 'manual__2025-10-23T16:44:51.076713+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 16:50:02,302 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T16:44:51.076713+00:00', try_number=1, map_index=-1)
2025-10-23 16:50:02,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T16:44:51.076713+00:00', try_number=1, map_index=-1)
2025-10-23 16:50:02,317 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-23T16:44:51.076713+00:00, map_index=-1, run_start_date=2025-10-23 16:44:52.280446+00:00, run_end_date=2025-10-23 16:50:01.021644+00:00, run_duration=308.741198, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-23 16:44:51.775493+00:00, queued_by_job_id=5, pid=73234
2025-10-23 16:50:02,318 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T16:44:51.076713+00:00 [queued]> to 618b906b-68cf-4ac6-a65d-15c4845efe4b
2025-10-23 16:50:11,748 INFO - Marking run <DagRun test_ondemand_worker @ 2025-10-23 16:44:51.076713+00:00: manual__2025-10-23T16:44:51.076713+00:00, state:running, queued_at: None. externally triggered: False> successful
2025-10-23 16:50:11,749 INFO - DagRun Finished: dag_id=test_ondemand_worker, execution_date=2025-10-23 16:44:51.076713+00:00, run_id=manual__2025-10-23T16:44:51.076713+00:00, run_start_date=2025-10-23 16:44:51.076713+00:00, run_end_date=2025-10-23 16:50:11.749322+00:00, run_duration=320.672609, state=success, external_trigger=False, run_type=manual, data_interval_start=2025-10-23 16:44:51.076713+00:00, data_interval_end=2025-10-23 16:44:51.076713+00:00, dag_hash=929e78c82e47dfdab76aa5816e4d7647
2025-10-23 16:50:11,783 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T16:44:51.076713+00:00', try_number=1, map_index=-1)
2025-10-23 16:50:11,790 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-23T16:44:51.076713+00:00, map_index=-1, run_start_date=2025-10-23 16:50:02.749439+00:00, run_end_date=2025-10-23 16:50:11.227779+00:00, run_duration=8.47834, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=1, operator=RemoteWorkerStopOperator, queued_dttm=2025-10-23 16:50:02.244344+00:00, queued_by_job_id=5, pid=74029
2025-10-23 16:54:35,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 16:59:35,690 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:04:35,729 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:09:35,770 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:14:35,778 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:19:35,814 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:24:35,852 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:29:35,911 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:34:35,950 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:39:35,993 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:44:36,027 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:49:36,060 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:54:36,093 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 17:56:59,248 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [scheduled]>
2025-10-23 17:56:59,248 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 17:56:59,248 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [scheduled]>
2025-10-23 17:56:59,251 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 17:56:59,251 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T17:56:58.729673+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-23 17:56:59,252 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-23T17:56:58.729673+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 17:56:59,367 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T17:56:58.729673+00:00', try_number=1, map_index=-1)
2025-10-23 17:56:59,379 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [queued]> to 4e4fab7b-38db-47cf-8119-830373b14d6d
2025-10-23 17:59:36,185 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:02:08,028 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-23T17:56:58.729673+00:00', try_number=1, map_index=-1)
2025-10-23 18:02:08,038 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-23T17:56:58.729673+00:00, map_index=-1, run_start_date=2025-10-23 17:56:59.696793+00:00, run_end_date=2025-10-23 18:02:07.432351+00:00, run_duration=307.735558, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-23 17:56:59.249637+00:00, queued_by_job_id=5, pid=75431
2025-10-23 18:02:08,653 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [scheduled]>
2025-10-23 18:02:08,653 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-23 18:02:08,653 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [scheduled]>
2025-10-23 18:02:08,655 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-23 18:02:08,656 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T17:56:58.729673+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-23 18:02:08,656 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'stop_remote_worker', 'manual__2025-10-23T17:56:58.729673+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-23 18:02:08,722 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T17:56:58.729673+00:00', try_number=1, map_index=-1)
2025-10-23 18:02:08,727 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-23T17:56:58.729673+00:00 [queued]> to 32404229-e1e1-47e8-bf08-850bfe688d53
2025-10-23 18:02:18,014 INFO - Marking run <DagRun test_ondemand_worker @ 2025-10-23 17:56:58.729673+00:00: manual__2025-10-23T17:56:58.729673+00:00, state:running, queued_at: 2025-10-23 17:56:58.749627+00:00. externally triggered: True> successful
2025-10-23 18:02:18,015 INFO - DagRun Finished: dag_id=test_ondemand_worker, execution_date=2025-10-23 17:56:58.729673+00:00, run_id=manual__2025-10-23T17:56:58.729673+00:00, run_start_date=2025-10-23 17:56:59.221093+00:00, run_end_date=2025-10-23 18:02:18.015231+00:00, run_duration=318.794138, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-23 17:56:58.729673+00:00, data_interval_end=2025-10-23 17:56:58.729673+00:00, dag_hash=929e78c82e47dfdab76aa5816e4d7647
2025-10-23 18:02:18,050 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-23T17:56:58.729673+00:00', try_number=1, map_index=-1)
2025-10-23 18:02:18,055 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-23T17:56:58.729673+00:00, map_index=-1, run_start_date=2025-10-23 18:02:09.112351+00:00, run_end_date=2025-10-23 18:02:17.712575+00:00, run_duration=8.600224, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=default, priority_weight=1, operator=RemoteWorkerStopOperator, queued_dttm=2025-10-23 18:02:08.654473+00:00, queued_by_job_id=5, pid=76288
2025-10-23 18:04:36,216 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:09:36,255 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:14:36,293 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:19:36,328 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:24:36,364 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:29:36,403 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:34:36,439 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:39:36,474 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:44:36,512 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:49:36,546 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:54:36,579 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 18:59:36,619 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:04:36,659 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:09:36,692 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:14:36,731 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:19:36,776 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:24:36,818 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:29:36,859 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:34:36,903 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:39:36,944 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:44:36,984 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:49:37,025 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:54:37,065 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 19:59:37,073 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:04:37,106 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:09:37,137 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:14:37,175 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:19:37,211 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:24:37,252 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:29:37,305 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:34:37,339 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:39:37,352 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:44:37,388 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:49:37,419 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:54:37,451 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 20:59:37,503 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:04:37,544 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:09:37,582 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:14:38,322 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:19:38,354 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:24:38,387 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:29:38,422 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:34:38,462 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:39:38,498 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:44:38,538 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:49:38,572 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:54:38,610 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 21:59:38,643 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:04:38,680 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:09:38,713 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:14:38,756 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:19:38,794 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:24:38,840 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:29:38,889 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:34:38,926 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:39:38,965 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:44:39,002 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:49:39,014 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:54:39,060 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 22:59:39,102 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:04:39,142 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:09:39,179 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:14:39,215 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:19:39,253 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:24:39,293 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:29:39,343 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:34:39,384 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:39:39,427 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:44:39,471 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:49:39,508 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:54:39,542 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-23 23:59:39,580 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:04:39,615 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:09:39,652 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:14:39,690 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:19:39,728 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:24:39,764 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:29:39,814 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:34:39,848 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:39:39,883 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:44:39,918 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:49:39,953 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:54:39,986 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 00:59:40,029 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:04:40,069 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:09:40,103 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:14:40,136 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:19:40,170 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:24:40,202 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:29:40,255 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:34:40,291 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:39:40,330 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:44:40,370 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:49:40,404 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:54:40,437 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 01:59:40,471 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:04:40,507 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:09:40,545 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:14:40,584 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:19:40,616 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:24:40,653 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:29:40,708 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:34:40,740 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:39:40,774 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:44:40,804 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:49:40,834 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:54:40,867 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 02:59:40,925 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:04:40,968 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:09:41,008 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:14:41,056 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:19:41,094 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:24:41,139 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:29:41,276 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:34:41,314 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:39:41,349 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:39:56,342 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [scheduled]>
2025-10-24 03:39:56,342 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-24 03:39:56,343 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [scheduled]>
2025-10-24 03:39:56,344 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 03:39:56,345 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-24T03:39:55.825276+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-24 03:39:56,345 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-24T03:39:55.825276+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-24 03:39:56,402 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-24T03:39:55.825276+00:00', try_number=1, map_index=-1)
2025-10-24 03:39:56,409 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [queued]> to b97c7a37-a117-41e4-af91-e85474bf3277
2025-10-24 03:40:08,017 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [scheduled]>
2025-10-24 03:40:08,017 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-24 03:40:08,017 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [scheduled]>
2025-10-24 03:40:08,019 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 03:40:08,020 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-24T03:39:55.825276+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 03:40:08,020 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'stop_remote_worker', 'manual__2025-10-24T03:39:55.825276+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-24 03:40:08,074 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-24T03:39:55.825276+00:00', try_number=1, map_index=-1)
2025-10-24 03:40:08,082 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T03:39:55.825276+00:00 [queued]> to f89b505a-7e43-4bfe-b28a-1f0cb103446b
2025-10-24 03:40:13,111 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-24T03:39:55.825276+00:00', try_number=1, map_index=-1)
2025-10-24 03:40:13,115 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-24T03:39:55.825276+00:00, map_index=-1, run_start_date=2025-10-24 03:39:56.726232+00:00, run_end_date=2025-10-24 03:40:05.617978+00:00, run_duration=8.891746, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=12, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-24 03:39:56.343541+00:00, queued_by_job_id=5, pid=86969
2025-10-24 03:40:17,081 INFO - Marking run <DagRun test_ondemand_worker @ 2025-10-24 03:39:55.825276+00:00: manual__2025-10-24T03:39:55.825276+00:00, state:running, queued_at: None. externally triggered: False> successful
2025-10-24 03:40:17,082 INFO - DagRun Finished: dag_id=test_ondemand_worker, execution_date=2025-10-24 03:39:55.825276+00:00, run_id=manual__2025-10-24T03:39:55.825276+00:00, run_start_date=2025-10-24 03:39:55.825276+00:00, run_end_date=2025-10-24 03:40:17.082076+00:00, run_duration=21.2568, state=success, external_trigger=False, run_type=manual, data_interval_start=2025-10-24 03:39:55.825276+00:00, data_interval_end=2025-10-24 03:39:55.825276+00:00, dag_hash=929e78c82e47dfdab76aa5816e4d7647
2025-10-24 03:40:17,108 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-24T03:39:55.825276+00:00', try_number=1, map_index=-1)
2025-10-24 03:40:17,113 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-24T03:39:55.825276+00:00, map_index=-1, run_start_date=2025-10-24 03:40:08.477204+00:00, run_end_date=2025-10-24 03:40:16.671221+00:00, run_duration=8.194017, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=13, pool=default_pool, queue=default, priority_weight=1, operator=RemoteWorkerStopOperator, queued_dttm=2025-10-24 03:40:08.018292+00:00, queued_by_job_id=5, pid=87020
2025-10-24 03:44:41,398 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:49:41,439 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:54:41,477 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 03:59:41,542 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:04:41,595 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:09:41,638 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:14:41,680 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:19:41,720 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:24:41,742 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:28:46,167 INFO - 1 tasks up for execution:
	<TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [scheduled]>
2025-10-24 04:28:46,167 INFO - DAG clean_complex_pipeline has 0/16 running and queued tasks
2025-10-24 04:28:46,168 INFO - Setting the following tasks to queued state:
	<TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [scheduled]>
2025-10-24 04:28:46,170 INFO - Trying to enqueue tasks: [<TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 04:28:46,171 INFO - Sending TaskInstanceKey(dag_id='clean_complex_pipeline', task_id='fetch_data', run_id='manual__2025-10-24T04:28:44.961789+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-24 04:28:46,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'clean_complex_pipeline', 'fetch_data', 'manual__2025-10-24T04:28:44.961789+00:00', '--local', '--subdir', 'DAGS_FOLDER/clean_example_dag.py']
2025-10-24 04:28:46,250 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='clean_complex_pipeline', task_id='fetch_data', run_id='manual__2025-10-24T04:28:44.961789+00:00', try_number=1, map_index=-1)
2025-10-24 04:28:46,259 INFO - Setting external_id for <TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [queued]> to 28bb61ce-9c5a-421e-8ae9-ca0ee5188987
2025-10-24 04:28:47,437 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='clean_complex_pipeline', task_id='fetch_data', run_id='manual__2025-10-24T04:28:44.961789+00:00', try_number=1, map_index=-1)
2025-10-24 04:28:47,443 INFO - TaskInstance Finished: dag_id=clean_complex_pipeline, task_id=fetch_data, run_id=manual__2025-10-24T04:28:44.961789+00:00, map_index=-1, run_start_date=2025-10-24 04:28:46.623283+00:00, run_end_date=2025-10-24 04:28:46.852519+00:00, run_duration=0.229236, state=up_for_retry, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=6, operator=OnDemandWorkerV2, queued_dttm=2025-10-24 04:28:46.168861+00:00, queued_by_job_id=5, pid=90248
2025-10-24 04:29:41,795 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:33:47,454 INFO - 1 tasks up for execution:
	<TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [scheduled]>
2025-10-24 04:33:47,454 INFO - DAG clean_complex_pipeline has 0/16 running and queued tasks
2025-10-24 04:33:47,455 INFO - Setting the following tasks to queued state:
	<TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [scheduled]>
2025-10-24 04:33:47,456 INFO - Trying to enqueue tasks: [<TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 04:33:47,457 INFO - Sending TaskInstanceKey(dag_id='clean_complex_pipeline', task_id='fetch_data', run_id='manual__2025-10-24T04:28:44.961789+00:00', try_number=2, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-24 04:33:47,457 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'clean_complex_pipeline', 'fetch_data', 'manual__2025-10-24T04:28:44.961789+00:00', '--local', '--subdir', 'DAGS_FOLDER/clean_example_dag.py']
2025-10-24 04:33:47,508 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='clean_complex_pipeline', task_id='fetch_data', run_id='manual__2025-10-24T04:28:44.961789+00:00', try_number=2, map_index=-1)
2025-10-24 04:33:47,513 INFO - Setting external_id for <TaskInstance: clean_complex_pipeline.fetch_data manual__2025-10-24T04:28:44.961789+00:00 [queued]> to 38f05d36-771e-41aa-b585-a113fb64eb4d
2025-10-24 04:33:48,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='clean_complex_pipeline', task_id='fetch_data', run_id='manual__2025-10-24T04:28:44.961789+00:00', try_number=2, map_index=-1)
2025-10-24 04:33:48,404 INFO - TaskInstance Finished: dag_id=clean_complex_pipeline, task_id=fetch_data, run_id=manual__2025-10-24T04:28:44.961789+00:00, map_index=-1, run_start_date=2025-10-24 04:33:47.825962+00:00, run_end_date=2025-10-24 04:33:48.052985+00:00, run_duration=0.227023, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=6, operator=OnDemandWorkerV2, queued_dttm=2025-10-24 04:33:47.455513+00:00, queued_by_job_id=5, pid=90668
2025-10-24 04:33:51,428 ERROR - Marking run <DagRun clean_complex_pipeline @ 2025-10-24 04:28:44.961789+00:00: manual__2025-10-24T04:28:44.961789+00:00, state:running, queued_at: 2025-10-24 04:28:45.003962+00:00. externally triggered: True> failed
2025-10-24 04:33:51,428 INFO - DagRun Finished: dag_id=clean_complex_pipeline, execution_date=2025-10-24 04:28:44.961789+00:00, run_id=manual__2025-10-24T04:28:44.961789+00:00, run_start_date=2025-10-24 04:28:45.885072+00:00, run_end_date=2025-10-24 04:33:51.428876+00:00, run_duration=305.543804, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 04:28:44.961789+00:00, data_interval_end=2025-10-24 04:28:44.961789+00:00, dag_hash=b5649a73edd55df4999f8590961e59b3
2025-10-24 04:34:41,828 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:39:41,867 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:44:41,905 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:48:08,114 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [scheduled]>
2025-10-24 04:48:08,115 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-24 04:48:08,115 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [scheduled]>
2025-10-24 04:48:08,117 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 04:48:08,118 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-24T04:48:07.055582+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-24 04:48:08,118 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'start_remote_worker', 'manual__2025-10-24T04:48:07.055582+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-24 04:48:08,190 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-24T04:48:07.055582+00:00', try_number=1, map_index=-1)
2025-10-24 04:48:08,201 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.start_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [queued]> to c512c1ba-00de-46e4-b896-a1b1883a1eb1
2025-10-24 04:49:09,230 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [scheduled]>
2025-10-24 04:49:09,231 INFO - DAG test_ondemand_worker has 0/16 running and queued tasks
2025-10-24 04:49:09,231 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [scheduled]>
2025-10-24 04:49:09,235 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 04:49:09,236 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-24T04:48:07.055582+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 04:49:09,237 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker', 'stop_remote_worker', 'manual__2025-10-24T04:48:07.055582+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker.py']
2025-10-24 04:49:09,289 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-24T04:48:07.055582+00:00', try_number=1, map_index=-1)
2025-10-24 04:49:09,296 INFO - Setting external_id for <TaskInstance: test_ondemand_worker.stop_remote_worker manual__2025-10-24T04:48:07.055582+00:00 [queued]> to 35882ada-89d2-4950-9515-2fcb57128e37
2025-10-24 04:49:15,012 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='start_remote_worker', run_id='manual__2025-10-24T04:48:07.055582+00:00', try_number=1, map_index=-1)
2025-10-24 04:49:15,018 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=start_remote_worker, run_id=manual__2025-10-24T04:48:07.055582+00:00, map_index=-1, run_start_date=2025-10-24 04:48:08.630409+00:00, run_end_date=2025-10-24 04:49:07.740032+00:00, run_duration=59.109623, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=16, pool=default_pool, queue=default, priority_weight=4, operator=RemoteWorkerStartOperator, queued_dttm=2025-10-24 04:48:08.116354+00:00, queued_by_job_id=5, pid=91299
2025-10-24 04:49:19,296 INFO - Marking run <DagRun test_ondemand_worker @ 2025-10-24 04:48:07.055582+00:00: manual__2025-10-24T04:48:07.055582+00:00, state:running, queued_at: None. externally triggered: False> successful
2025-10-24 04:49:19,297 INFO - DagRun Finished: dag_id=test_ondemand_worker, execution_date=2025-10-24 04:48:07.055582+00:00, run_id=manual__2025-10-24T04:48:07.055582+00:00, run_start_date=2025-10-24 04:48:07.055582+00:00, run_end_date=2025-10-24 04:49:19.297225+00:00, run_duration=72.241643, state=success, external_trigger=False, run_type=manual, data_interval_start=2025-10-24 04:48:07.055582+00:00, data_interval_end=2025-10-24 04:48:07.055582+00:00, dag_hash=929e78c82e47dfdab76aa5816e4d7647
2025-10-24 04:49:19,331 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker', task_id='stop_remote_worker', run_id='manual__2025-10-24T04:48:07.055582+00:00', try_number=1, map_index=-1)
2025-10-24 04:49:19,336 INFO - TaskInstance Finished: dag_id=test_ondemand_worker, task_id=stop_remote_worker, run_id=manual__2025-10-24T04:48:07.055582+00:00, map_index=-1, run_start_date=2025-10-24 04:49:09.701417+00:00, run_end_date=2025-10-24 04:49:18.419993+00:00, run_duration=8.718576, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=17, pool=default_pool, queue=default, priority_weight=1, operator=RemoteWorkerStopOperator, queued_dttm=2025-10-24 04:49:09.232453+00:00, queued_by_job_id=5, pid=91454
2025-10-24 04:49:41,944 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:54:41,982 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 04:59:42,015 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:00:38,274 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:38,275 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 05:00:38,275 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:38,278 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 05:00:38,278 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='setup_ssh_connection', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-24 05:00:38,279 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'setup_ssh_connection', 'manual__2025-10-24T05:00:36.571887+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 05:00:38,343 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='setup_ssh_connection', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:38,355 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T05:00:36.571887+00:00 [queued]> to 5a78cb0b-f0cc-41d4-b658-b198a4071632
2025-10-24 05:00:39,459 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:39,460 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 05:00:39,460 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:39,462 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 05:00:39,462 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='start_remote_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 05:00:39,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'start_remote_worker', 'manual__2025-10-24T05:00:36.571887+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 05:00:39,526 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='start_remote_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:39,527 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='setup_ssh_connection', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:39,532 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [queued]> to c13d0ec4-d92a-4786-a234-0186e78d34af
2025-10-24 05:00:39,533 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=setup_ssh_connection, run_id=manual__2025-10-24T05:00:36.571887+00:00, map_index=-1, run_start_date=2025-10-24 05:00:38.617318+00:00, run_end_date=2025-10-24 05:00:38.897183+00:00, run_duration=0.279865, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-10-24 05:00:38.276543+00:00, queued_by_job_id=5, pid=91762
2025-10-24 05:00:40,635 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:40,635 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 05:00:40,636 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:40,637 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 05:00:40,638 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='execute_on_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-24 05:00:40,638 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'execute_on_worker', 'manual__2025-10-24T05:00:36.571887+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 05:00:40,692 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='execute_on_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:40,693 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='start_remote_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:40,697 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=start_remote_worker, run_id=manual__2025-10-24T05:00:36.571887+00:00, map_index=-1, run_start_date=2025-10-24 05:00:39.806815+00:00, run_end_date=2025-10-24 05:00:40.080141+00:00, run_duration=0.273326, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 05:00:39.460898+00:00, queued_by_job_id=5, pid=91789
2025-10-24 05:00:40,698 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T05:00:36.571887+00:00 [queued]> to 697c76ec-f47a-4fa0-bac4-81733dd24444
2025-10-24 05:00:42,279 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:42,280 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 05:00:42,280 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:42,282 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 05:00:42,282 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='stop_remote_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-24 05:00:42,282 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'stop_remote_worker', 'manual__2025-10-24T05:00:36.571887+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 05:00:42,339 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='stop_remote_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:42,339 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='execute_on_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:42,346 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=execute_on_worker, run_id=manual__2025-10-24T05:00:36.571887+00:00, map_index=-1, run_start_date=2025-10-24 05:00:40.980092+00:00, run_end_date=2025-10-24 05:00:41.273727+00:00, run_duration=0.293635, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-10-24 05:00:40.636658+00:00, queued_by_job_id=5, pid=91815
2025-10-24 05:00:42,347 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T05:00:36.571887+00:00 [queued]> to 467cf1b3-6db0-438f-86f5-641026f76816
2025-10-24 05:00:43,474 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:43,474 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 05:00:43,475 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>
2025-10-24 05:00:43,477 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T05:00:36.571887+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 05:00:43,478 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='check_results', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 05:00:43,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'check_results', 'manual__2025-10-24T05:00:36.571887+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 05:00:43,544 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='check_results', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:43,545 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='stop_remote_worker', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:43,556 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T05:00:36.571887+00:00 [queued]> to d4885111-46b5-42ce-b4a8-5d4610609a8b
2025-10-24 05:00:43,556 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=stop_remote_worker, run_id=manual__2025-10-24T05:00:36.571887+00:00, map_index=-1, run_start_date=2025-10-24 05:00:42.665834+00:00, run_end_date=2025-10-24 05:00:42.988544+00:00, run_duration=0.32271, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-24 05:00:42.280782+00:00, queued_by_job_id=5, pid=91843
2025-10-24 05:00:44,627 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='check_results', run_id='manual__2025-10-24T05:00:36.571887+00:00', try_number=1, map_index=-1)
2025-10-24 05:00:44,632 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=check_results, run_id=manual__2025-10-24T05:00:36.571887+00:00, map_index=-1, run_start_date=2025-10-24 05:00:43.854748+00:00, run_end_date=2025-10-24 05:00:44.174504+00:00, run_duration=0.319756, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 05:00:43.475857+00:00, queued_by_job_id=5, pid=91869
2025-10-24 05:00:45,677 INFO - Marking run <DagRun test_ondemand_worker_fixed @ 2025-10-24 05:00:36.571887+00:00: manual__2025-10-24T05:00:36.571887+00:00, state:running, queued_at: 2025-10-24 05:00:36.598891+00:00. externally triggered: True> successful
2025-10-24 05:00:45,677 INFO - DagRun Finished: dag_id=test_ondemand_worker_fixed, execution_date=2025-10-24 05:00:36.571887+00:00, run_id=manual__2025-10-24T05:00:36.571887+00:00, run_start_date=2025-10-24 05:00:37.195966+00:00, run_end_date=2025-10-24 05:00:45.677786+00:00, run_duration=8.48182, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 05:00:36.571887+00:00, data_interval_end=2025-10-24 05:00:36.571887+00:00, dag_hash=21dc989860162e2ffbc1cd2d8cf59f13
2025-10-24 05:04:42,063 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:09:42,101 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:14:42,139 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:19:42,169 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:24:42,213 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:29:42,263 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:34:42,300 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:39:42,343 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:44:42,386 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:49:42,419 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:54:42,459 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 05:59:42,508 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:04:42,541 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:09:42,576 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:14:42,611 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:19:42,643 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:24:42,677 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:29:42,736 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:34:42,774 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:39:42,808 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:44:42,842 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:49:42,877 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:54:42,916 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 06:59:42,973 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:04:43,011 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:09:43,045 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:14:43,079 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:19:43,111 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:24:43,143 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:29:43,200 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:34:43,236 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:39:43,272 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:44:43,306 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:49:43,347 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:54:43,385 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 07:59:43,442 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:04:43,479 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:09:43,511 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:14:43,548 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:19:43,591 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:24:43,628 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:29:43,681 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:34:43,719 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:39:43,755 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:44:43,787 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:49:43,827 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:54:43,868 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 08:59:43,925 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:04:43,961 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:09:43,995 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:14:44,029 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:19:44,062 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:24:44,103 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:29:44,147 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:34:44,179 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:39:44,209 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:44:44,240 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:49:44,279 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:54:44,313 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 09:59:44,352 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:04:44,386 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:09:44,421 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:14:44,454 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:19:44,491 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:24:44,532 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:29:44,580 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:34:44,617 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:39:44,652 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:44:44,690 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:49:44,725 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:54:44,765 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 10:59:44,811 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:04:44,843 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:09:44,878 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:14:44,910 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:19:44,947 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:24:44,980 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:29:45,031 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:34:45,065 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:39:45,097 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:44:45,136 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:49:45,176 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:54:45,216 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 11:59:45,263 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:04:45,308 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:09:45,351 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:14:45,394 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:19:45,434 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:24:45,472 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:29:45,526 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:34:45,560 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:39:45,598 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:44:45,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:49:45,673 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:54:45,713 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 12:59:45,751 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:04:45,790 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:09:45,829 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:14:45,861 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:19:45,897 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:24:45,988 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:29:46,020 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:34:46,064 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:39:46,099 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:44:46,137 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:49:46,175 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:54:46,211 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 13:59:46,258 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:04:46,296 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:09:46,334 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:14:46,375 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:19:46,415 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:24:46,461 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:29:46,502 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:34:46,539 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:39:46,577 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:44:46,616 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:49:46,649 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:54:46,684 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 14:59:46,734 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:04:46,770 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:09:46,777 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:14:46,816 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:19:46,853 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:24:46,889 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:29:46,938 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:34:46,973 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:39:47,004 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:44:47,039 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:49:47,073 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:54:47,105 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 15:59:47,157 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:04:47,195 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:09:47,229 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:14:47,260 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:19:47,299 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:24:47,332 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:29:47,379 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:34:47,411 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:39:47,445 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:44:47,482 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:49:47,496 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:54:47,534 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 16:59:47,587 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:04:47,622 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:09:47,654 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:14:47,668 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:19:47,709 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:24:47,748 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:29:47,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:34:47,828 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:39:47,864 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:44:47,896 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:49:47,933 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:54:47,964 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 17:59:47,996 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:04:48,034 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:09:48,070 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:14:48,105 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:19:48,150 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:24:48,190 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:29:48,234 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:34:48,266 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:39:48,298 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:44:48,335 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:49:48,365 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:54:48,401 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 18:59:48,440 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:04:48,472 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:09:48,506 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:14:48,545 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:19:48,581 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:24:48,620 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:29:48,653 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:34:48,685 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:39:48,715 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:44:48,748 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:49:48,778 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:54:48,808 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 19:59:48,860 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:04:48,893 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:09:48,926 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:14:48,956 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:19:48,996 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:24:49,034 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:29:49,065 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:34:49,086 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:39:49,125 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:44:49,163 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:49:49,207 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:54:49,241 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 20:59:49,285 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:04:49,320 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:09:49,352 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:14:49,385 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:19:49,416 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:24:49,451 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:29:49,503 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:34:49,536 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:39:49,567 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:44:49,601 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:45:33,409 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:33,409 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 21:45:33,410 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:33,411 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 21:45:33,412 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='setup_ssh_connection', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-24 21:45:33,412 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'setup_ssh_connection', 'manual__2025-10-24T21:45:31.913381+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 21:45:33,460 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='setup_ssh_connection', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:33,466 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.setup_ssh_connection manual__2025-10-24T21:45:31.913381+00:00 [queued]> to c4cef500-a161-4708-b3b9-2bbd1b2d2a26
2025-10-24 21:45:34,301 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:34,301 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 21:45:34,301 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:34,303 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 21:45:34,303 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='start_remote_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 21:45:34,303 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'start_remote_worker', 'manual__2025-10-24T21:45:31.913381+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 21:45:34,355 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='start_remote_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:34,356 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='setup_ssh_connection', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:34,360 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=setup_ssh_connection, run_id=manual__2025-10-24T21:45:31.913381+00:00, map_index=-1, run_start_date=2025-10-24 21:45:33.742339+00:00, run_end_date=2025-10-24 21:45:34.004329+00:00, run_duration=0.26199, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-10-24 21:45:33.410490+00:00, queued_by_job_id=5, pid=113678
2025-10-24 21:45:34,361 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.start_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [queued]> to 3a202524-6de8-42de-943f-f0f6c179a767
2025-10-24 21:45:35,467 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:35,468 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 21:45:35,468 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:35,470 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 21:45:35,470 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='execute_on_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-24 21:45:35,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'execute_on_worker', 'manual__2025-10-24T21:45:31.913381+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 21:45:35,521 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='execute_on_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:35,521 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='start_remote_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:35,528 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.execute_on_worker manual__2025-10-24T21:45:31.913381+00:00 [queued]> to 7291c52d-ef25-484c-85f2-ad4ccb8c0b44
2025-10-24 21:45:35,528 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=start_remote_worker, run_id=manual__2025-10-24T21:45:31.913381+00:00, map_index=-1, run_start_date=2025-10-24 21:45:34.637028+00:00, run_end_date=2025-10-24 21:45:34.915098+00:00, run_duration=0.27807, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 21:45:34.302180+00:00, queued_by_job_id=5, pid=113704
2025-10-24 21:45:36,628 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:36,628 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 21:45:36,629 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:36,630 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 21:45:36,631 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='stop_remote_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-24 21:45:36,631 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'stop_remote_worker', 'manual__2025-10-24T21:45:31.913381+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 21:45:36,690 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='stop_remote_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:36,690 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='execute_on_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:36,694 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=execute_on_worker, run_id=manual__2025-10-24T21:45:31.913381+00:00, map_index=-1, run_start_date=2025-10-24 21:45:35.787781+00:00, run_end_date=2025-10-24 21:45:36.027801+00:00, run_duration=0.24002, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-10-24 21:45:35.468935+00:00, queued_by_job_id=5, pid=113730
2025-10-24 21:45:36,695 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.stop_remote_worker manual__2025-10-24T21:45:31.913381+00:00 [queued]> to db909777-3cbb-4696-806b-da6d0b84be23
2025-10-24 21:45:37,732 INFO - 1 tasks up for execution:
	<TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:37,732 INFO - DAG test_ondemand_worker_fixed has 0/16 running and queued tasks
2025-10-24 21:45:37,732 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>
2025-10-24 21:45:37,734 INFO - Trying to enqueue tasks: [<TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T21:45:31.913381+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 21:45:37,734 INFO - Sending TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='check_results', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 21:45:37,735 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_ondemand_worker_fixed', 'check_results', 'manual__2025-10-24T21:45:31.913381+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 21:45:37,783 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='check_results', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:37,784 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='stop_remote_worker', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:37,791 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=stop_remote_worker, run_id=manual__2025-10-24T21:45:31.913381+00:00, map_index=-1, run_start_date=2025-10-24 21:45:36.955328+00:00, run_end_date=2025-10-24 21:45:37.220513+00:00, run_duration=0.265185, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-24 21:45:36.629531+00:00, queued_by_job_id=5, pid=113758
2025-10-24 21:45:37,792 INFO - Setting external_id for <TaskInstance: test_ondemand_worker_fixed.check_results manual__2025-10-24T21:45:31.913381+00:00 [queued]> to 37c4deb7-36ab-4d9c-8d9e-65bd461b92b6
2025-10-24 21:45:38,904 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_ondemand_worker_fixed', task_id='check_results', run_id='manual__2025-10-24T21:45:31.913381+00:00', try_number=1, map_index=-1)
2025-10-24 21:45:38,908 INFO - TaskInstance Finished: dag_id=test_ondemand_worker_fixed, task_id=check_results, run_id=manual__2025-10-24T21:45:31.913381+00:00, map_index=-1, run_start_date=2025-10-24 21:45:38.072092+00:00, run_end_date=2025-10-24 21:45:38.342081+00:00, run_duration=0.269989, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 21:45:37.733262+00:00, queued_by_job_id=5, pid=113786
2025-10-24 21:45:39,395 INFO - Marking run <DagRun test_ondemand_worker_fixed @ 2025-10-24 21:45:31.913381+00:00: manual__2025-10-24T21:45:31.913381+00:00, state:running, queued_at: 2025-10-24 21:45:31.939942+00:00. externally triggered: True> successful
2025-10-24 21:45:39,395 INFO - DagRun Finished: dag_id=test_ondemand_worker_fixed, execution_date=2025-10-24 21:45:31.913381+00:00, run_id=manual__2025-10-24T21:45:31.913381+00:00, run_start_date=2025-10-24 21:45:32.345680+00:00, run_end_date=2025-10-24 21:45:39.395634+00:00, run_duration=7.049954, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 21:45:31.913381+00:00, data_interval_end=2025-10-24 21:45:31.913381+00:00, dag_hash=21dc989860162e2ffbc1cd2d8cf59f13
2025-10-24 21:49:49,635 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:54:49,664 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 21:59:49,701 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:04:49,736 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:09:49,768 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:14:49,798 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:19:49,828 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:24:49,859 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:29:49,903 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:34:41,674 INFO - 1 tasks up for execution:
	<TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>
2025-10-24 22:34:41,675 INFO - DAG simple_worker_test has 0/16 running and queued tasks
2025-10-24 22:34:41,675 INFO - Setting the following tasks to queued state:
	<TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>
2025-10-24 22:34:41,677 INFO - Trying to enqueue tasks: [<TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 22:34:41,677 INFO - Sending TaskInstanceKey(dag_id='simple_worker_test', task_id='test_ssh_connection', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-24 22:34:41,677 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'simple_worker_test', 'test_ssh_connection', 'manual__2025-10-24T22:34:40.095552+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 22:34:41,733 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='test_ssh_connection', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=1, map_index=-1)
2025-10-24 22:34:41,739 INFO - Setting external_id for <TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T22:34:40.095552+00:00 [queued]> to e15165c5-0941-48f4-9dfa-0bafe7ecf992
2025-10-24 22:34:42,836 INFO - 1 tasks up for execution:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>
2025-10-24 22:34:42,836 INFO - DAG simple_worker_test has 0/16 running and queued tasks
2025-10-24 22:34:42,836 INFO - Setting the following tasks to queued state:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>
2025-10-24 22:34:42,838 INFO - Trying to enqueue tasks: [<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 22:34:42,838 INFO - Sending TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-24 22:34:42,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'simple_worker_test', 'start_worker_manually', 'manual__2025-10-24T22:34:40.095552+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 22:34:42,892 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=1, map_index=-1)
2025-10-24 22:34:42,892 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='test_ssh_connection', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=1, map_index=-1)
2025-10-24 22:34:42,899 INFO - TaskInstance Finished: dag_id=simple_worker_test, task_id=test_ssh_connection, run_id=manual__2025-10-24T22:34:40.095552+00:00, map_index=-1, run_start_date=2025-10-24 22:34:41.987710+00:00, run_end_date=2025-10-24 22:34:42.249473+00:00, run_duration=0.261763, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-10-24 22:34:41.676078+00:00, queued_by_job_id=5, pid=114428
2025-10-24 22:34:42,900 INFO - Setting external_id for <TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [queued]> to e9f37331-ece1-4bd6-ad9a-5ee2ea590293
2025-10-24 22:34:49,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:36:58,040 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=1, map_index=-1)
2025-10-24 22:36:58,045 INFO - TaskInstance Finished: dag_id=simple_worker_test, task_id=start_worker_manually, run_id=manual__2025-10-24T22:34:40.095552+00:00, map_index=-1, run_start_date=2025-10-24 22:34:43.158595+00:00, run_end_date=2025-10-24 22:36:57.751897+00:00, run_duration=134.593302, state=up_for_retry, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-24 22:34:42.837126+00:00, queued_by_job_id=5, pid=114455
2025-10-24 22:39:49,983 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:41:57,983 INFO - 1 tasks up for execution:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>
2025-10-24 22:41:57,983 INFO - DAG simple_worker_test has 0/16 running and queued tasks
2025-10-24 22:41:57,983 INFO - Setting the following tasks to queued state:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>
2025-10-24 22:41:57,984 INFO - Trying to enqueue tasks: [<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 22:41:57,985 INFO - Sending TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=2, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-24 22:41:57,985 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'simple_worker_test', 'start_worker_manually', 'manual__2025-10-24T22:34:40.095552+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 22:41:58,030 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=2, map_index=-1)
2025-10-24 22:41:58,034 INFO - Setting external_id for <TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T22:34:40.095552+00:00 [queued]> to 3bb815aa-2d7f-4a4d-9636-eb6225d18962
2025-10-24 22:41:59,986 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T22:34:40.095552+00:00', try_number=2, map_index=-1)
2025-10-24 22:41:59,990 INFO - TaskInstance Finished: dag_id=simple_worker_test, task_id=start_worker_manually, run_id=manual__2025-10-24T22:34:40.095552+00:00, map_index=-1, run_start_date=2025-10-24 22:41:58.286392+00:00, run_end_date=2025-10-24 22:41:59.572932+00:00, run_duration=1.28654, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-24 22:41:57.984053+00:00, queued_by_job_id=5, pid=114776
2025-10-24 22:42:01,018 ERROR - Marking run <DagRun simple_worker_test @ 2025-10-24 22:34:40.095552+00:00: manual__2025-10-24T22:34:40.095552+00:00, state:running, queued_at: 2025-10-24 22:34:40.116810+00:00. externally triggered: True> failed
2025-10-24 22:42:01,019 INFO - DagRun Finished: dag_id=simple_worker_test, execution_date=2025-10-24 22:34:40.095552+00:00, run_id=manual__2025-10-24T22:34:40.095552+00:00, run_start_date=2025-10-24 22:34:40.602796+00:00, run_end_date=2025-10-24 22:42:01.018969+00:00, run_duration=440.416173, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 22:34:40.095552+00:00, data_interval_end=2025-10-24 22:34:40.095552+00:00, dag_hash=5b03b16120adcb65c613fb01f3ce2539
2025-10-24 22:44:50,015 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:49:50,047 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:52:36,379 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
2025-10-24 22:52:36,380 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 22:52:36,380 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
2025-10-24 22:52:36,381 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.show_environment manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 22:52:36,382 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 22:52:36,382 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_environment', 'manual__2025-10-24T22:52:35.824567+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 22:52:36,430 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:36,435 INFO - Setting external_id for <TaskInstance: test_connections.show_environment manual__2025-10-24T22:52:35.824567+00:00 [queued]> to c80da12c-aa37-4da5-8536-a9c71d99981d
2025-10-24 22:52:37,523 INFO - 3 tasks up for execution:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
2025-10-24 22:52:37,524 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 22:52:37,524 INFO - DAG test_connections has 1/16 running and queued tasks
2025-10-24 22:52:37,524 INFO - DAG test_connections has 2/16 running and queued tasks
2025-10-24 22:52:37,524 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
2025-10-24 22:52:37,526 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.test_postgresql manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>, <TaskInstance: test_connections.test_redis manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>, <TaskInstance: test_connections.show_worker_info manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 22:52:37,526 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 22:52:37,526 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_postgresql', 'manual__2025-10-24T22:52:35.824567+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 22:52:37,527 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 22:52:37,527 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_redis', 'manual__2025-10-24T22:52:35.824567+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 22:52:37,527 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 22:52:37,527 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_worker_info', 'manual__2025-10-24T22:52:35.824567+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 22:52:37,751 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:37,752 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:37,753 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:37,754 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:37,771 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_environment, run_id=manual__2025-10-24T22:52:35.824567+00:00, map_index=-1, run_start_date=2025-10-24 22:52:36.702181+00:00, run_end_date=2025-10-24 22:52:36.978310+00:00, run_duration=0.276129, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 22:52:36.380690+00:00, queued_by_job_id=5, pid=115040
2025-10-24 22:52:37,774 INFO - Setting external_id for <TaskInstance: test_connections.test_postgresql manual__2025-10-24T22:52:35.824567+00:00 [queued]> to 0647d7cb-a7dd-4bfa-b010-c9db01b89f2e
2025-10-24 22:52:37,774 INFO - Setting external_id for <TaskInstance: test_connections.test_redis manual__2025-10-24T22:52:35.824567+00:00 [queued]> to d5050051-dacb-426b-8cea-2e72a913c798
2025-10-24 22:52:37,775 INFO - Setting external_id for <TaskInstance: test_connections.show_worker_info manual__2025-10-24T22:52:35.824567+00:00 [queued]> to 679e92e1-2eb0-45c9-95d8-8486cc42c411
2025-10-24 22:52:39,428 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
2025-10-24 22:52:39,428 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 22:52:39,428 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>
2025-10-24 22:52:39,430 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.generate_summary manual__2025-10-24T22:52:35.824567+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 22:52:39,430 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 22:52:39,430 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'generate_summary', 'manual__2025-10-24T22:52:35.824567+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 22:52:39,487 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:39,487 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:39,488 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:39,488 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:39,496 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_worker_info, run_id=manual__2025-10-24T22:52:35.824567+00:00, map_index=-1, run_start_date=2025-10-24 22:52:38.238467+00:00, run_end_date=2025-10-24 22:52:38.674461+00:00, run_duration=0.435994, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 22:52:37.524976+00:00, queued_by_job_id=5, pid=115103
2025-10-24 22:52:39,497 INFO - Setting external_id for <TaskInstance: test_connections.generate_summary manual__2025-10-24T22:52:35.824567+00:00 [queued]> to 08f8409b-084a-454c-97df-3e7dec60d456
2025-10-24 22:52:39,497 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_redis, run_id=manual__2025-10-24T22:52:35.824567+00:00, map_index=-1, run_start_date=2025-10-24 22:52:37.991164+00:00, run_end_date=2025-10-24 22:52:38.484691+00:00, run_duration=0.493527, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 22:52:37.524976+00:00, queued_by_job_id=5, pid=115083
2025-10-24 22:52:39,498 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_postgresql, run_id=manual__2025-10-24T22:52:35.824567+00:00, map_index=-1, run_start_date=2025-10-24 22:52:38.231028+00:00, run_end_date=2025-10-24 22:52:38.693153+00:00, run_duration=0.462125, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 22:52:37.524976+00:00, queued_by_job_id=5, pid=115101
2025-10-24 22:52:40,221 INFO - Marking run <DagRun test_connections @ 2025-10-24 22:52:35.824567+00:00: manual__2025-10-24T22:52:35.824567+00:00, state:running, queued_at: 2025-10-24 22:52:35.956380+00:00. externally triggered: True> successful
2025-10-24 22:52:40,222 INFO - DagRun Finished: dag_id=test_connections, execution_date=2025-10-24 22:52:35.824567+00:00, run_id=manual__2025-10-24T22:52:35.824567+00:00, run_start_date=2025-10-24 22:52:36.357230+00:00, run_end_date=2025-10-24 22:52:40.222118+00:00, run_duration=3.864888, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 22:52:35.824567+00:00, data_interval_end=2025-10-24 22:52:35.824567+00:00, dag_hash=892f651915aa3020cc971fd609965a7e
2025-10-24 22:52:40,249 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T22:52:35.824567+00:00', try_number=1, map_index=-1)
2025-10-24 22:52:40,254 INFO - TaskInstance Finished: dag_id=test_connections, task_id=generate_summary, run_id=manual__2025-10-24T22:52:35.824567+00:00, map_index=-1, run_start_date=2025-10-24 22:52:39.783915+00:00, run_end_date=2025-10-24 22:52:40.061147+00:00, run_duration=0.277232, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-24 22:52:39.429154+00:00, queued_by_job_id=5, pid=115158
2025-10-24 22:54:50,078 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 22:59:50,127 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:03:12,915 INFO - 1 tasks up for execution:
	<TaskInstance: quick_connection_test.quick_test_all manual__2025-10-24T23:03:12.374865+00:00 [scheduled]>
2025-10-24 23:03:12,916 INFO - DAG quick_connection_test has 0/16 running and queued tasks
2025-10-24 23:03:12,916 INFO - Setting the following tasks to queued state:
	<TaskInstance: quick_connection_test.quick_test_all manual__2025-10-24T23:03:12.374865+00:00 [scheduled]>
2025-10-24 23:03:12,918 INFO - Trying to enqueue tasks: [<TaskInstance: quick_connection_test.quick_test_all manual__2025-10-24T23:03:12.374865+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:03:12,918 INFO - Sending TaskInstanceKey(dag_id='quick_connection_test', task_id='quick_test_all', run_id='manual__2025-10-24T23:03:12.374865+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 23:03:12,918 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'quick_connection_test', 'quick_test_all', 'manual__2025-10-24T23:03:12.374865+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:03:12,965 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='quick_connection_test', task_id='quick_test_all', run_id='manual__2025-10-24T23:03:12.374865+00:00', try_number=1, map_index=-1)
2025-10-24 23:03:12,974 INFO - Setting external_id for <TaskInstance: quick_connection_test.quick_test_all manual__2025-10-24T23:03:12.374865+00:00 [queued]> to 055d6fc2-d5d3-4e44-927b-e8dbd521b073
2025-10-24 23:03:14,063 INFO - Marking run <DagRun quick_connection_test @ 2025-10-24 23:03:12.374865+00:00: manual__2025-10-24T23:03:12.374865+00:00, state:running, queued_at: 2025-10-24 23:03:12.401723+00:00. externally triggered: True> successful
2025-10-24 23:03:14,064 INFO - DagRun Finished: dag_id=quick_connection_test, execution_date=2025-10-24 23:03:12.374865+00:00, run_id=manual__2025-10-24T23:03:12.374865+00:00, run_start_date=2025-10-24 23:03:12.895725+00:00, run_end_date=2025-10-24 23:03:14.064389+00:00, run_duration=1.168664, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 23:03:12.374865+00:00, data_interval_end=2025-10-24 23:03:12.374865+00:00, dag_hash=fcd110a7016ad2eedd92996bdec5acad
2025-10-24 23:03:14,088 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='quick_connection_test', task_id='quick_test_all', run_id='manual__2025-10-24T23:03:12.374865+00:00', try_number=1, map_index=-1)
2025-10-24 23:03:14,093 INFO - TaskInstance Finished: dag_id=quick_connection_test, task_id=quick_test_all, run_id=manual__2025-10-24T23:03:12.374865+00:00, map_index=-1, run_start_date=2025-10-24 23:03:13.285783+00:00, run_end_date=2025-10-24 23:03:13.634072+00:00, run_duration=0.348289, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-10-24 23:03:12.916954+00:00, queued_by_job_id=5, pid=115484
2025-10-24 23:03:22,419 INFO - 1 tasks up for execution:
	<TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>
2025-10-24 23:03:22,420 INFO - DAG simple_worker_test has 0/16 running and queued tasks
2025-10-24 23:03:22,420 INFO - Setting the following tasks to queued state:
	<TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>
2025-10-24 23:03:22,422 INFO - Trying to enqueue tasks: [<TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:03:22,422 INFO - Sending TaskInstanceKey(dag_id='simple_worker_test', task_id='test_ssh_connection', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-24 23:03:22,423 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'simple_worker_test', 'test_ssh_connection', 'manual__2025-10-24T23:03:21.879828+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 23:03:22,470 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='test_ssh_connection', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=1, map_index=-1)
2025-10-24 23:03:22,476 INFO - Setting external_id for <TaskInstance: simple_worker_test.test_ssh_connection manual__2025-10-24T23:03:21.879828+00:00 [queued]> to 402aa1ef-31f4-44af-a537-f414f96222cc
2025-10-24 23:04:32,043 INFO - 1 tasks up for execution:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>
2025-10-24 23:04:32,043 INFO - DAG simple_worker_test has 0/16 running and queued tasks
2025-10-24 23:04:32,043 INFO - Setting the following tasks to queued state:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>
2025-10-24 23:04:32,045 INFO - Trying to enqueue tasks: [<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:04:32,045 INFO - Sending TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-24 23:04:32,046 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'simple_worker_test', 'start_worker_manually', 'manual__2025-10-24T23:03:21.879828+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 23:04:32,095 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=1, map_index=-1)
2025-10-24 23:04:32,096 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='test_ssh_connection', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=1, map_index=-1)
2025-10-24 23:04:32,101 INFO - TaskInstance Finished: dag_id=simple_worker_test, task_id=test_ssh_connection, run_id=manual__2025-10-24T23:03:21.879828+00:00, map_index=-1, run_start_date=2025-10-24 23:03:22.739425+00:00, run_end_date=2025-10-24 23:04:31.018022+00:00, run_duration=68.278597, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-10-24 23:03:22.420956+00:00, queued_by_job_id=5, pid=115526
2025-10-24 23:04:32,102 INFO - Setting external_id for <TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [queued]> to ad920d2b-be38-4cbb-ad35-38556f3378c9
2025-10-24 23:04:32,861 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=1, map_index=-1)
2025-10-24 23:04:32,865 INFO - TaskInstance Finished: dag_id=simple_worker_test, task_id=start_worker_manually, run_id=manual__2025-10-24T23:03:21.879828+00:00, map_index=-1, run_start_date=2025-10-24 23:04:32.351419+00:00, run_end_date=2025-10-24 23:04:32.594060+00:00, run_duration=0.242641, state=up_for_retry, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-24 23:04:32.044162+00:00, queued_by_job_id=5, pid=115670
2025-10-24 23:04:50,168 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:09:32,814 INFO - 1 tasks up for execution:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>
2025-10-24 23:09:32,814 INFO - DAG simple_worker_test has 0/16 running and queued tasks
2025-10-24 23:09:32,814 INFO - Setting the following tasks to queued state:
	<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>
2025-10-24 23:09:32,816 INFO - Trying to enqueue tasks: [<TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:09:32,816 INFO - Sending TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=2, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-24 23:09:32,817 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'simple_worker_test', 'start_worker_manually', 'manual__2025-10-24T23:03:21.879828+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_ondemand_worker_fixed.py']
2025-10-24 23:09:32,871 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=2, map_index=-1)
2025-10-24 23:09:32,875 INFO - Setting external_id for <TaskInstance: simple_worker_test.start_worker_manually manual__2025-10-24T23:03:21.879828+00:00 [queued]> to 8478052d-4678-4871-9cac-e66a2b445b07
2025-10-24 23:09:36,266 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='simple_worker_test', task_id='start_worker_manually', run_id='manual__2025-10-24T23:03:21.879828+00:00', try_number=2, map_index=-1)
2025-10-24 23:09:36,270 INFO - TaskInstance Finished: dag_id=simple_worker_test, task_id=start_worker_manually, run_id=manual__2025-10-24T23:03:21.879828+00:00, map_index=-1, run_start_date=2025-10-24 23:09:33.121594+00:00, run_end_date=2025-10-24 23:09:35.442524+00:00, run_duration=2.32093, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-10-24 23:09:32.815299+00:00, queued_by_job_id=5, pid=115813
2025-10-24 23:09:36,797 ERROR - Marking run <DagRun simple_worker_test @ 2025-10-24 23:03:21.879828+00:00: manual__2025-10-24T23:03:21.879828+00:00, state:running, queued_at: 2025-10-24 23:03:21.890420+00:00. externally triggered: True> failed
2025-10-24 23:09:36,798 INFO - DagRun Finished: dag_id=simple_worker_test, execution_date=2025-10-24 23:03:21.879828+00:00, run_id=manual__2025-10-24T23:03:21.879828+00:00, run_start_date=2025-10-24 23:03:22.118181+00:00, run_end_date=2025-10-24 23:09:36.798639+00:00, run_duration=374.680458, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 23:03:21.879828+00:00, data_interval_end=2025-10-24 23:03:21.879828+00:00, dag_hash=5b03b16120adcb65c613fb01f3ce2539
2025-10-24 23:09:50,205 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:12:00,849 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
2025-10-24 23:12:00,849 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:12:00,849 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
2025-10-24 23:12:00,851 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:12:00,852 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 23:12:00,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_environment', 'manual__2025-10-24T23:12:00.124929+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:00,916 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:00,923 INFO - Setting external_id for <TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:00.124929+00:00 [queued]> to adde3c7f-ec10-4d58-ab1c-438a46173928
2025-10-24 23:12:02,022 INFO - 3 tasks up for execution:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
2025-10-24 23:12:02,022 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:12:02,023 INFO - DAG test_connections has 1/16 running and queued tasks
2025-10-24 23:12:02,023 INFO - DAG test_connections has 2/16 running and queued tasks
2025-10-24 23:12:02,023 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
2025-10-24 23:12:02,025 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>, <TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>, <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:12:02,026 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:12:02,026 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_postgresql', 'manual__2025-10-24T23:12:00.124929+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:02,026 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:12:02,026 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_redis', 'manual__2025-10-24T23:12:00.124929+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:02,027 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:12:02,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_worker_info', 'manual__2025-10-24T23:12:00.124929+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:02,236 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:02,237 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:02,240 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:02,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:02,248 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_environment, run_id=manual__2025-10-24T23:12:00.124929+00:00, map_index=-1, run_start_date=2025-10-24 23:12:01.192293+00:00, run_end_date=2025-10-24 23:12:01.454069+00:00, run_duration=0.261776, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 23:12:00.850278+00:00, queued_by_job_id=5, pid=115874
2025-10-24 23:12:02,250 INFO - Setting external_id for <TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:00.124929+00:00 [queued]> to e330f8ae-6808-438a-8248-23b6d1b7c9e7
2025-10-24 23:12:02,250 INFO - Setting external_id for <TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:00.124929+00:00 [queued]> to 3813af1d-a497-44f3-90ca-da7724c816c0
2025-10-24 23:12:02,251 INFO - Setting external_id for <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:00.124929+00:00 [queued]> to 2db4478c-83a6-4377-83c8-af78821d566e
2025-10-24 23:12:03,893 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
2025-10-24 23:12:03,893 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:12:03,893 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>
2025-10-24 23:12:03,895 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:00.124929+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:12:03,895 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 23:12:03,895 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'generate_summary', 'manual__2025-10-24T23:12:00.124929+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:03,949 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:03,949 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:03,949 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:03,950 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:03,953 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_worker_info, run_id=manual__2025-10-24T23:12:00.124929+00:00, map_index=-1, run_start_date=2025-10-24 23:12:02.643157+00:00, run_end_date=2025-10-24 23:12:03.106368+00:00, run_duration=0.463211, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:12:02.024137+00:00, queued_by_job_id=5, pid=115927
2025-10-24 23:12:03,954 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_redis, run_id=manual__2025-10-24T23:12:00.124929+00:00, map_index=-1, run_start_date=2025-10-24 23:12:02.689406+00:00, run_end_date=2025-10-24 23:12:03.149996+00:00, run_duration=0.46059, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:12:02.024137+00:00, queued_by_job_id=5, pid=115931
2025-10-24 23:12:03,954 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_postgresql, run_id=manual__2025-10-24T23:12:00.124929+00:00, map_index=-1, run_start_date=2025-10-24 23:12:02.718924+00:00, run_end_date=2025-10-24 23:12:03.298968+00:00, run_duration=0.580044, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:12:02.024137+00:00, queued_by_job_id=5, pid=115935
2025-10-24 23:12:03,954 INFO - Setting external_id for <TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:00.124929+00:00 [queued]> to 140e76be-af57-430b-9429-35b53d9d9e38
2025-10-24 23:12:04,606 INFO - Marking run <DagRun test_connections @ 2025-10-24 23:12:00.124929+00:00: manual__2025-10-24T23:12:00.124929+00:00, state:running, queued_at: 2025-10-24 23:12:00.134034+00:00. externally triggered: True> successful
2025-10-24 23:12:04,606 INFO - DagRun Finished: dag_id=test_connections, execution_date=2025-10-24 23:12:00.124929+00:00, run_id=manual__2025-10-24T23:12:00.124929+00:00, run_start_date=2025-10-24 23:12:00.827635+00:00, run_end_date=2025-10-24 23:12:04.606702+00:00, run_duration=3.779067, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 23:12:00.124929+00:00, data_interval_end=2025-10-24 23:12:00.124929+00:00, dag_hash=892f651915aa3020cc971fd609965a7e
2025-10-24 23:12:05,692 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:12:00.124929+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:05,696 INFO - TaskInstance Finished: dag_id=test_connections, task_id=generate_summary, run_id=manual__2025-10-24T23:12:00.124929+00:00, map_index=-1, run_start_date=2025-10-24 23:12:04.240058+00:00, run_end_date=2025-10-24 23:12:04.550938+00:00, run_duration=0.31088, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-24 23:12:03.894213+00:00, queued_by_job_id=5, pid=115992
2025-10-24 23:12:33,067 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
2025-10-24 23:12:33,067 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:12:33,067 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
2025-10-24 23:12:33,069 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:12:33,069 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 23:12:33,070 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_environment', 'manual__2025-10-24T23:12:32.750757+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:33,126 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:33,135 INFO - Setting external_id for <TaskInstance: test_connections.show_environment manual__2025-10-24T23:12:32.750757+00:00 [queued]> to f6cf484a-6357-435f-8f8b-c2baf32b53fa
2025-10-24 23:12:34,255 INFO - 3 tasks up for execution:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
2025-10-24 23:12:34,255 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:12:34,256 INFO - DAG test_connections has 1/16 running and queued tasks
2025-10-24 23:12:34,256 INFO - DAG test_connections has 2/16 running and queued tasks
2025-10-24 23:12:34,256 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
2025-10-24 23:12:34,257 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>, <TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>, <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:12:34,258 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:12:34,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_postgresql', 'manual__2025-10-24T23:12:32.750757+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:34,259 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:12:34,259 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_redis', 'manual__2025-10-24T23:12:32.750757+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:34,259 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:12:34,259 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_worker_info', 'manual__2025-10-24T23:12:32.750757+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:34,465 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:34,466 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:34,466 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:34,466 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:34,475 INFO - Setting external_id for <TaskInstance: test_connections.test_redis manual__2025-10-24T23:12:32.750757+00:00 [queued]> to c0b1d2c7-4fdf-495f-a317-241595cee941
2025-10-24 23:12:34,476 INFO - Setting external_id for <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:12:32.750757+00:00 [queued]> to eb14532c-f967-4b1e-ba71-8c6e0131b339
2025-10-24 23:12:34,478 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_environment, run_id=manual__2025-10-24T23:12:32.750757+00:00, map_index=-1, run_start_date=2025-10-24 23:12:33.401395+00:00, run_end_date=2025-10-24 23:12:33.680142+00:00, run_duration=0.278747, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 23:12:33.068295+00:00, queued_by_job_id=5, pid=116028
2025-10-24 23:12:34,478 INFO - Setting external_id for <TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:12:32.750757+00:00 [queued]> to 980e0235-45f8-42d3-a9bc-d31adb23160e
2025-10-24 23:12:35,879 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
2025-10-24 23:12:35,879 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:12:35,880 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>
2025-10-24 23:12:35,881 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:32.750757+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:12:35,882 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 23:12:35,882 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'generate_summary', 'manual__2025-10-24T23:12:32.750757+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:12:35,932 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:35,932 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:35,933 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:35,933 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:35,936 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_worker_info, run_id=manual__2025-10-24T23:12:32.750757+00:00, map_index=-1, run_start_date=2025-10-24 23:12:34.952734+00:00, run_end_date=2025-10-24 23:12:35.378784+00:00, run_duration=0.42605, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:12:34.256814+00:00, queued_by_job_id=5, pid=116088
2025-10-24 23:12:35,937 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_redis, run_id=manual__2025-10-24T23:12:32.750757+00:00, map_index=-1, run_start_date=2025-10-24 23:12:34.933911+00:00, run_end_date=2025-10-24 23:12:35.395910+00:00, run_duration=0.461999, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:12:34.256814+00:00, queued_by_job_id=5, pid=116081
2025-10-24 23:12:35,937 INFO - Setting external_id for <TaskInstance: test_connections.generate_summary manual__2025-10-24T23:12:32.750757+00:00 [queued]> to 8769eb05-1e4d-4402-bc8f-d84117a8b6dc
2025-10-24 23:12:35,937 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_postgresql, run_id=manual__2025-10-24T23:12:32.750757+00:00, map_index=-1, run_start_date=2025-10-24 23:12:34.932043+00:00, run_end_date=2025-10-24 23:12:35.429343+00:00, run_duration=0.4973, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:12:34.256814+00:00, queued_by_job_id=5, pid=116084
2025-10-24 23:12:37,013 INFO - Marking run <DagRun test_connections @ 2025-10-24 23:12:32.750757+00:00: manual__2025-10-24T23:12:32.750757+00:00, state:running, queued_at: 2025-10-24 23:12:32.761591+00:00. externally triggered: True> successful
2025-10-24 23:12:37,013 INFO - DagRun Finished: dag_id=test_connections, execution_date=2025-10-24 23:12:32.750757+00:00, run_id=manual__2025-10-24T23:12:32.750757+00:00, run_start_date=2025-10-24 23:12:33.047640+00:00, run_end_date=2025-10-24 23:12:37.013670+00:00, run_duration=3.96603, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 23:12:32.750757+00:00, data_interval_end=2025-10-24 23:12:32.750757+00:00, dag_hash=892f651915aa3020cc971fd609965a7e
2025-10-24 23:12:37,034 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:12:32.750757+00:00', try_number=1, map_index=-1)
2025-10-24 23:12:37,038 INFO - TaskInstance Finished: dag_id=test_connections, task_id=generate_summary, run_id=manual__2025-10-24T23:12:32.750757+00:00, map_index=-1, run_start_date=2025-10-24 23:12:36.200767+00:00, run_end_date=2025-10-24 23:12:36.449630+00:00, run_duration=0.248863, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-24 23:12:35.880749+00:00, queued_by_job_id=5, pid=116145
2025-10-24 23:14:50,236 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:19:50,266 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:24:50,298 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:26:38,587 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
2025-10-24 23:26:38,587 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:26:38,588 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
2025-10-24 23:26:38,589 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.show_environment manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:26:38,590 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 23:26:38,590 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_environment', 'manual__2025-10-24T23:26:37.784954+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:26:38,651 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:38,659 INFO - Setting external_id for <TaskInstance: test_connections.show_environment manual__2025-10-24T23:26:37.784954+00:00 [queued]> to 1939b56c-89cc-4296-899c-9a0895ba3e81
2025-10-24 23:26:40,167 INFO - 3 tasks up for execution:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
2025-10-24 23:26:40,167 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:26:40,167 INFO - DAG test_connections has 1/16 running and queued tasks
2025-10-24 23:26:40,168 INFO - DAG test_connections has 2/16 running and queued tasks
2025-10-24 23:26:40,168 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
2025-10-24 23:26:40,169 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>, <TaskInstance: test_connections.test_redis manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>, <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:26:40,170 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:26:40,170 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_postgresql', 'manual__2025-10-24T23:26:37.784954+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:26:40,170 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:26:40,170 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_redis', 'manual__2025-10-24T23:26:37.784954+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:26:40,171 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:26:40,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_worker_info', 'manual__2025-10-24T23:26:37.784954+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:26:40,354 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:40,355 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:40,357 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:40,357 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:40,368 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_environment, run_id=manual__2025-10-24T23:26:37.784954+00:00, map_index=-1, run_start_date=2025-10-24 23:26:38.903730+00:00, run_end_date=2025-10-24 23:26:39.166055+00:00, run_duration=0.262325, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 23:26:38.588594+00:00, queued_by_job_id=5, pid=116553
2025-10-24 23:26:40,369 INFO - Setting external_id for <TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:26:37.784954+00:00 [queued]> to 36f4a526-67ce-4923-8cd8-42c1920391d4
2025-10-24 23:26:40,369 INFO - Setting external_id for <TaskInstance: test_connections.test_redis manual__2025-10-24T23:26:37.784954+00:00 [queued]> to 2bf8ee0e-e7e8-443e-a3e0-c3da2133175d
2025-10-24 23:26:40,370 INFO - Setting external_id for <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:26:37.784954+00:00 [queued]> to d9cbeca7-0512-4062-9731-f7c0ada835ec
2025-10-24 23:26:42,140 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
2025-10-24 23:26:42,141 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:26:42,141 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>
2025-10-24 23:26:42,144 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:26:37.784954+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:26:42,144 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 23:26:42,145 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'generate_summary', 'manual__2025-10-24T23:26:37.784954+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:26:42,216 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:42,217 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:42,217 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:42,217 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:42,222 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_worker_info, run_id=manual__2025-10-24T23:26:37.784954+00:00, map_index=-1, run_start_date=2025-10-24 23:26:40.795195+00:00, run_end_date=2025-10-24 23:26:41.294897+00:00, run_duration=0.499702, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:26:40.168724+00:00, queued_by_job_id=5, pid=116610
2025-10-24 23:26:42,222 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_postgresql, run_id=manual__2025-10-24T23:26:37.784954+00:00, map_index=-1, run_start_date=2025-10-24 23:26:40.775064+00:00, run_end_date=2025-10-24 23:26:41.322809+00:00, run_duration=0.547745, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:26:40.168724+00:00, queued_by_job_id=5, pid=116605
2025-10-24 23:26:42,223 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_redis, run_id=manual__2025-10-24T23:26:37.784954+00:00, map_index=-1, run_start_date=2025-10-24 23:26:40.833572+00:00, run_end_date=2025-10-24 23:26:41.378673+00:00, run_duration=0.545101, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=53, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:26:40.168724+00:00, queued_by_job_id=5, pid=116614
2025-10-24 23:26:42,223 INFO - Setting external_id for <TaskInstance: test_connections.generate_summary manual__2025-10-24T23:26:37.784954+00:00 [queued]> to d13ef21b-9e54-4c76-b74a-400a1fb8eb60
2025-10-24 23:26:43,314 INFO - Marking run <DagRun test_connections @ 2025-10-24 23:26:37.784954+00:00: manual__2025-10-24T23:26:37.784954+00:00, state:running, queued_at: 2025-10-24 23:26:37.796854+00:00. externally triggered: True> successful
2025-10-24 23:26:43,314 INFO - DagRun Finished: dag_id=test_connections, execution_date=2025-10-24 23:26:37.784954+00:00, run_id=manual__2025-10-24T23:26:37.784954+00:00, run_start_date=2025-10-24 23:26:38.562030+00:00, run_end_date=2025-10-24 23:26:43.314779+00:00, run_duration=4.752749, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 23:26:37.784954+00:00, data_interval_end=2025-10-24 23:26:37.784954+00:00, dag_hash=892f651915aa3020cc971fd609965a7e
2025-10-24 23:26:43,347 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:26:37.784954+00:00', try_number=1, map_index=-1)
2025-10-24 23:26:43,352 INFO - TaskInstance Finished: dag_id=test_connections, task_id=generate_summary, run_id=manual__2025-10-24T23:26:37.784954+00:00, map_index=-1, run_start_date=2025-10-24 23:26:42.514980+00:00, run_end_date=2025-10-24 23:26:42.786399+00:00, run_duration=0.271419, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=54, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-24 23:26:42.142502+00:00, queued_by_job_id=5, pid=116671
2025-10-24 23:29:50,337 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:34:50,375 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:38:23,972 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
2025-10-24 23:38:23,972 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:38:23,973 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.show_environment manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
2025-10-24 23:38:23,974 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.show_environment manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:38:23,975 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-24 23:38:23,975 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_environment', 'manual__2025-10-24T23:38:22.898266+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:38:24,023 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:24,030 INFO - Setting external_id for <TaskInstance: test_connections.show_environment manual__2025-10-24T23:38:22.898266+00:00 [queued]> to b6962926-7f72-4b27-96e5-7f906ebc2ba7
2025-10-24 23:38:25,348 INFO - 3 tasks up for execution:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
2025-10-24 23:38:25,349 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:38:25,349 INFO - DAG test_connections has 1/16 running and queued tasks
2025-10-24 23:38:25,349 INFO - DAG test_connections has 2/16 running and queued tasks
2025-10-24 23:38:25,349 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
	<TaskInstance: test_connections.test_redis manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
	<TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
2025-10-24 23:38:25,351 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>, <TaskInstance: test_connections.test_redis manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>, <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:38:25,352 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:38:25,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_postgresql', 'manual__2025-10-24T23:38:22.898266+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:38:25,352 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:38:25,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'test_redis', 'manual__2025-10-24T23:38:22.898266+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:38:25,353 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-24 23:38:25,353 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'show_worker_info', 'manual__2025-10-24T23:38:22.898266+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:38:25,589 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:25,590 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:25,590 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:25,590 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_environment', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:25,608 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_environment, run_id=manual__2025-10-24T23:38:22.898266+00:00, map_index=-1, run_start_date=2025-10-24 23:38:24.356187+00:00, run_end_date=2025-10-24 23:38:24.646131+00:00, run_duration=0.289944, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=55, pool=default_pool, queue=default, priority_weight=5, operator=BashOperator, queued_dttm=2025-10-24 23:38:23.973566+00:00, queued_by_job_id=5, pid=117041
2025-10-24 23:38:25,608 INFO - Setting external_id for <TaskInstance: test_connections.test_postgresql manual__2025-10-24T23:38:22.898266+00:00 [queued]> to 9ed9c323-4a7d-4be2-8541-a74283438904
2025-10-24 23:38:25,609 INFO - Setting external_id for <TaskInstance: test_connections.test_redis manual__2025-10-24T23:38:22.898266+00:00 [queued]> to 2d963ced-8c52-4ef0-9538-1066309f16f3
2025-10-24 23:38:25,609 INFO - Setting external_id for <TaskInstance: test_connections.show_worker_info manual__2025-10-24T23:38:22.898266+00:00 [queued]> to b7815eee-c9c1-4d5b-95ba-6a7391cad5c9
2025-10-24 23:38:26,751 INFO - 1 tasks up for execution:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
2025-10-24 23:38:26,752 INFO - DAG test_connections has 0/16 running and queued tasks
2025-10-24 23:38:26,752 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>
2025-10-24 23:38:26,754 INFO - Trying to enqueue tasks: [<TaskInstance: test_connections.generate_summary manual__2025-10-24T23:38:22.898266+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-24 23:38:26,754 INFO - Sending TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-24 23:38:26,754 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connections', 'generate_summary', 'manual__2025-10-24T23:38:22.898266+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_connections_dag.py']
2025-10-24 23:38:26,825 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:26,826 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_postgresql', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:26,827 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='test_redis', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:26,827 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='show_worker_info', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:26,831 INFO - TaskInstance Finished: dag_id=test_connections, task_id=show_worker_info, run_id=manual__2025-10-24T23:38:22.898266+00:00, map_index=-1, run_start_date=2025-10-24 23:38:25.845922+00:00, run_end_date=2025-10-24 23:38:26.235532+00:00, run_duration=0.38961, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=56, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:38:25.350379+00:00, queued_by_job_id=5, pid=117087
2025-10-24 23:38:26,832 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_redis, run_id=manual__2025-10-24T23:38:22.898266+00:00, map_index=-1, run_start_date=2025-10-24 23:38:26.008394+00:00, run_end_date=2025-10-24 23:38:26.468540+00:00, run_duration=0.460146, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=57, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:38:25.350379+00:00, queued_by_job_id=5, pid=117100
2025-10-24 23:38:26,833 INFO - TaskInstance Finished: dag_id=test_connections, task_id=test_postgresql, run_id=manual__2025-10-24T23:38:22.898266+00:00, map_index=-1, run_start_date=2025-10-24 23:38:26.031332+00:00, run_end_date=2025-10-24 23:38:26.490261+00:00, run_duration=0.458929, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=58, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-24 23:38:25.350379+00:00, queued_by_job_id=5, pid=117102
2025-10-24 23:38:26,833 INFO - Setting external_id for <TaskInstance: test_connections.generate_summary manual__2025-10-24T23:38:22.898266+00:00 [queued]> to e97fd646-ad0f-44bf-a655-abe0a4fef677
2025-10-24 23:38:27,913 INFO - Marking run <DagRun test_connections @ 2025-10-24 23:38:22.898266+00:00: manual__2025-10-24T23:38:22.898266+00:00, state:running, queued_at: 2025-10-24 23:38:22.910466+00:00. externally triggered: True> successful
2025-10-24 23:38:27,914 INFO - DagRun Finished: dag_id=test_connections, execution_date=2025-10-24 23:38:22.898266+00:00, run_id=manual__2025-10-24T23:38:22.898266+00:00, run_start_date=2025-10-24 23:38:23.947664+00:00, run_end_date=2025-10-24 23:38:27.914197+00:00, run_duration=3.966533, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-24 23:38:22.898266+00:00, data_interval_end=2025-10-24 23:38:22.898266+00:00, dag_hash=892f651915aa3020cc971fd609965a7e
2025-10-24 23:38:27,939 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connections', task_id='generate_summary', run_id='manual__2025-10-24T23:38:22.898266+00:00', try_number=1, map_index=-1)
2025-10-24 23:38:27,944 INFO - TaskInstance Finished: dag_id=test_connections, task_id=generate_summary, run_id=manual__2025-10-24T23:38:22.898266+00:00, map_index=-1, run_start_date=2025-10-24 23:38:27.129688+00:00, run_end_date=2025-10-24 23:38:27.399679+00:00, run_duration=0.269991, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=59, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-24 23:38:26.752786+00:00, queued_by_job_id=5, pid=117157
2025-10-24 23:39:50,407 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:44:50,441 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:49:50,473 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:54:50,504 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-24 23:59:50,554 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:04:50,587 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:09:50,617 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:14:50,655 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:19:50,688 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:24:50,719 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:29:50,763 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:34:50,774 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:39:50,805 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:44:50,840 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:49:50,877 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:54:50,914 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 00:59:50,966 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:04:50,994 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:09:51,024 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:14:51,055 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:19:51,087 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:24:51,120 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:29:51,167 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:34:51,199 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:39:51,241 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:44:51,273 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:49:51,305 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:54:51,342 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 01:59:51,395 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:04:51,429 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:09:51,459 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:14:51,493 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:19:51,529 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:24:15,568 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:20:00+00:00, run_after=2025-10-25 02:25:00+00:00
2025-10-25 02:24:15,604 INFO - 2 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:15:00+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T02:24:14.843309+00:00 [scheduled]>
2025-10-25 02:24:15,604 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:24:15,605 INFO - DAG worker_health_monitor has 1/16 running and queued tasks
2025-10-25 02:24:15,605 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:15:00+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T02:24:14.843309+00:00 [scheduled]>
2025-10-25 02:24:15,607 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:15:00+00:00 [scheduled]>, <TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T02:24:14.843309+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:24:15,607 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:15:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:24:15,607 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:24:15,608 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T02:24:14.843309+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:24:15,608 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'manual__2025-10-25T02:24:14.843309+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:24:15,712 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:15,713 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T02:24:14.843309+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:15,724 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:15:00+00:00 [queued]> to 02c1e423-d7ce-4d49-ab0f-b96737638c53
2025-10-25 02:24:15,724 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T02:24:14.843309+00:00 [queued]> to bba42691-7869-40cb-8768-a79282e7e64a
2025-10-25 02:24:16,898 INFO - 2 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:15:00+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T02:24:14.843309+00:00 [scheduled]>
2025-10-25 02:24:16,898 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:24:16,898 INFO - DAG worker_health_monitor has 1/16 running and queued tasks
2025-10-25 02:24:16,898 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:15:00+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T02:24:14.843309+00:00 [scheduled]>
2025-10-25 02:24:16,900 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:15:00+00:00 [scheduled]>, <TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T02:24:14.843309+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:24:16,901 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:15:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:24:16,901 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:24:16,901 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T02:24:14.843309+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:24:16,901 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'manual__2025-10-25T02:24:14.843309+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:24:17,062 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:17,063 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T02:24:14.843309+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:17,063 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:17,063 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T02:24:14.843309+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:17,087 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:15:00+00:00 [queued]> to 59568136-8d37-4083-b4e3-4c4a7646e7c4
2025-10-25 02:24:17,087 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:15:00+00:00, map_index=-1, run_start_date=2025-10-25 02:24:16.051503+00:00, run_end_date=2025-10-25 02:24:16.441627+00:00, run_duration=0.390124, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=60, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:24:15.605715+00:00, queued_by_job_id=5, pid=120250
2025-10-25 02:24:17,090 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=manual__2025-10-25T02:24:14.843309+00:00, map_index=-1, run_start_date=2025-10-25 02:24:16.165500+00:00, run_end_date=2025-10-25 02:24:16.503179+00:00, run_duration=0.337679, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=61, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:24:15.605715+00:00, queued_by_job_id=5, pid=120259
2025-10-25 02:24:17,091 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T02:24:14.843309+00:00 [queued]> to 120377db-ae2a-40dc-9acf-55287754adfe
2025-10-25 02:24:18,225 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:15:00+00:00: scheduled__2025-10-25T02:15:00+00:00, state:running, queued_at: 2025-10-25 02:24:15.557451+00:00. externally triggered: False> successful
2025-10-25 02:24:18,226 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:15:00+00:00, run_id=scheduled__2025-10-25T02:15:00+00:00, run_start_date=2025-10-25 02:24:15.575262+00:00, run_end_date=2025-10-25 02:24:18.225978+00:00, run_duration=2.650716, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:15:00+00:00, data_interval_end=2025-10-25 02:20:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:24:18,230 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:20:00+00:00, run_after=2025-10-25 02:25:00+00:00
2025-10-25 02:24:18,234 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:24:14.843309+00:00: manual__2025-10-25T02:24:14.843309+00:00, state:running, queued_at: 2025-10-25 02:24:14.864992+00:00. externally triggered: True> successful
2025-10-25 02:24:18,234 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:24:14.843309+00:00, run_id=manual__2025-10-25T02:24:14.843309+00:00, run_start_date=2025-10-25 02:24:15.575623+00:00, run_end_date=2025-10-25 02:24:18.234672+00:00, run_duration=2.659049, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 02:15:00+00:00, data_interval_end=2025-10-25 02:20:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:24:18,258 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:18,258 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T02:24:14.843309+00:00', try_number=1, map_index=-1)
2025-10-25 02:24:18,262 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:15:00+00:00, map_index=-1, run_start_date=2025-10-25 02:24:17.403973+00:00, run_end_date=2025-10-25 02:24:17.667669+00:00, run_duration=0.263696, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=62, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:24:16.899322+00:00, queued_by_job_id=5, pid=120303
2025-10-25 02:24:18,263 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=manual__2025-10-25T02:24:14.843309+00:00, map_index=-1, run_start_date=2025-10-25 02:24:17.426341+00:00, run_end_date=2025-10-25 02:24:17.709631+00:00, run_duration=0.28329, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=63, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:24:16.899322+00:00, queued_by_job_id=5, pid=120307
2025-10-25 02:24:51,562 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:25:00,880 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:25:00+00:00, run_after=2025-10-25 02:30:00+00:00
2025-10-25 02:25:00,909 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:20:00+00:00 [scheduled]>
2025-10-25 02:25:00,910 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:25:00,910 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:20:00+00:00 [scheduled]>
2025-10-25 02:25:00,912 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:20:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:25:00,912 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:20:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:25:00,912 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:25:00,975 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:25:00,980 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:20:00+00:00 [queued]> to fd86777e-afe2-47bb-adf8-a9a90251fa89
2025-10-25 02:25:02,022 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:20:00+00:00 [scheduled]>
2025-10-25 02:25:02,023 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:25:02,023 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:20:00+00:00 [scheduled]>
2025-10-25 02:25:02,025 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:20:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:25:02,025 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:20:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:25:02,026 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:25:02,118 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:25:02,119 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:25:02,125 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:20:00+00:00 [queued]> to d7cc373d-cd8e-41c9-8b9a-e9172e3cb2f1
2025-10-25 02:25:02,125 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:20:00+00:00, map_index=-1, run_start_date=2025-10-25 02:25:01.317004+00:00, run_end_date=2025-10-25 02:25:01.605840+00:00, run_duration=0.288836, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=64, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:25:00.910751+00:00, queued_by_job_id=5, pid=120357
2025-10-25 02:25:03,229 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:20:00+00:00: scheduled__2025-10-25T02:20:00+00:00, state:running, queued_at: 2025-10-25 02:25:00.873192+00:00. externally triggered: False> successful
2025-10-25 02:25:03,230 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:20:00+00:00, run_id=scheduled__2025-10-25T02:20:00+00:00, run_start_date=2025-10-25 02:25:00.888293+00:00, run_end_date=2025-10-25 02:25:03.230373+00:00, run_duration=2.34208, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:20:00+00:00, data_interval_end=2025-10-25 02:25:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:25:03,236 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:25:00+00:00, run_after=2025-10-25 02:30:00+00:00
2025-10-25 02:25:03,264 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:25:03,270 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:20:00+00:00, map_index=-1, run_start_date=2025-10-25 02:25:02.477068+00:00, run_end_date=2025-10-25 02:25:02.751672+00:00, run_duration=0.274604, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=65, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:25:02.023780+00:00, queued_by_job_id=5, pid=120388
2025-10-25 02:29:51,613 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:30:00,100 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:30:00+00:00, run_after=2025-10-25 02:35:00+00:00
2025-10-25 02:30:00,134 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:25:00+00:00 [scheduled]>
2025-10-25 02:30:00,135 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:30:00,135 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:25:00+00:00 [scheduled]>
2025-10-25 02:30:00,137 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:25:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:30:00,138 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:25:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:30:00,139 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:30:00,194 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:30:00,203 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:25:00+00:00 [queued]> to f766db1a-5db3-4cbd-8ecb-13a0cf809003
2025-10-25 02:30:01,305 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:25:00+00:00 [scheduled]>
2025-10-25 02:30:01,305 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:30:01,306 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:25:00+00:00 [scheduled]>
2025-10-25 02:30:01,307 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:25:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:30:01,308 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:25:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:30:01,308 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:30:01,365 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:30:01,366 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:30:01,374 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:25:00+00:00, map_index=-1, run_start_date=2025-10-25 02:30:00.522703+00:00, run_end_date=2025-10-25 02:30:00.800669+00:00, run_duration=0.277966, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=66, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:30:00.136008+00:00, queued_by_job_id=5, pid=120604
2025-10-25 02:30:01,375 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:25:00+00:00 [queued]> to c58b6c17-5729-448b-956e-fa28f252e305
2025-10-25 02:30:03,105 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:25:00+00:00: scheduled__2025-10-25T02:25:00+00:00, state:running, queued_at: 2025-10-25 02:30:00.091899+00:00. externally triggered: False> successful
2025-10-25 02:30:03,106 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:25:00+00:00, run_id=scheduled__2025-10-25T02:25:00+00:00, run_start_date=2025-10-25 02:30:00.109024+00:00, run_end_date=2025-10-25 02:30:03.106139+00:00, run_duration=2.997115, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:25:00+00:00, data_interval_end=2025-10-25 02:30:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:30:03,112 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:30:00+00:00, run_after=2025-10-25 02:35:00+00:00
2025-10-25 02:30:03,146 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:30:03,152 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:25:00+00:00, map_index=-1, run_start_date=2025-10-25 02:30:01.711522+00:00, run_end_date=2025-10-25 02:30:01.969942+00:00, run_duration=0.25842, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=67, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:30:01.306530+00:00, queued_by_job_id=5, pid=120630
2025-10-25 02:34:51,645 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:35:00,248 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:35:00+00:00, run_after=2025-10-25 02:40:00+00:00
2025-10-25 02:35:00,283 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:30:00+00:00 [scheduled]>
2025-10-25 02:35:00,283 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:35:00,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:30:00+00:00 [scheduled]>
2025-10-25 02:35:00,286 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:30:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:35:00,287 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:30:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:35:00,287 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:35:00,348 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:35:00,356 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:30:00+00:00 [queued]> to 9da830e7-ca4f-4825-928e-8b99a0bbe72b
2025-10-25 02:35:01,465 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:30:00+00:00 [scheduled]>
2025-10-25 02:35:01,466 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:35:01,466 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:30:00+00:00 [scheduled]>
2025-10-25 02:35:01,468 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:30:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:35:01,469 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:30:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:35:01,469 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:35:01,530 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:35:01,531 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:35:01,535 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:30:00+00:00, map_index=-1, run_start_date=2025-10-25 02:35:00.670542+00:00, run_end_date=2025-10-25 02:35:00.936538+00:00, run_duration=0.265996, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=68, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:35:00.284812+00:00, queued_by_job_id=5, pid=120751
2025-10-25 02:35:01,536 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:30:00+00:00 [queued]> to 0f9e8315-0f19-488a-a337-7f879c22eaae
2025-10-25 02:35:02,625 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:30:00+00:00: scheduled__2025-10-25T02:30:00+00:00, state:running, queued_at: 2025-10-25 02:35:00.240989+00:00. externally triggered: False> successful
2025-10-25 02:35:02,625 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:30:00+00:00, run_id=scheduled__2025-10-25T02:30:00+00:00, run_start_date=2025-10-25 02:35:00.257315+00:00, run_end_date=2025-10-25 02:35:02.625678+00:00, run_duration=2.368363, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:30:00+00:00, data_interval_end=2025-10-25 02:35:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:35:02,630 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:35:00+00:00, run_after=2025-10-25 02:40:00+00:00
2025-10-25 02:35:02,656 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:35:02,661 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:30:00+00:00, map_index=-1, run_start_date=2025-10-25 02:35:01.847929+00:00, run_end_date=2025-10-25 02:35:02.121766+00:00, run_duration=0.273837, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=69, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:35:01.467483+00:00, queued_by_job_id=5, pid=120781
2025-10-25 02:39:51,682 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:40:00,457 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:40:00+00:00, run_after=2025-10-25 02:45:00+00:00
2025-10-25 02:40:00,484 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:35:00+00:00 [scheduled]>
2025-10-25 02:40:00,484 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:40:00,485 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:35:00+00:00 [scheduled]>
2025-10-25 02:40:00,487 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:35:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:40:00,487 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:35:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:40:00,487 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:40:00,544 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:40:00,550 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:35:00+00:00 [queued]> to df9a57ba-7d10-44fc-9df1-d83025b9f69f
2025-10-25 02:40:01,388 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:35:00+00:00 [scheduled]>
2025-10-25 02:40:01,389 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:40:01,389 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:35:00+00:00 [scheduled]>
2025-10-25 02:40:01,390 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:35:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:40:01,391 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:35:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:40:01,391 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:40:01,441 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:40:01,442 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:40:01,446 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:35:00+00:00 [queued]> to 4a590d8a-f6fc-41c8-b565-a6faf37a7c96
2025-10-25 02:40:01,446 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:35:00+00:00, map_index=-1, run_start_date=2025-10-25 02:40:00.880541+00:00, run_end_date=2025-10-25 02:40:01.141095+00:00, run_duration=0.260554, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=70, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:40:00.485797+00:00, queued_by_job_id=5, pid=120959
2025-10-25 02:40:02,533 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:35:00+00:00: scheduled__2025-10-25T02:35:00+00:00, state:running, queued_at: 2025-10-25 02:40:00.451086+00:00. externally triggered: False> successful
2025-10-25 02:40:02,533 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:35:00+00:00, run_id=scheduled__2025-10-25T02:35:00+00:00, run_start_date=2025-10-25 02:40:00.464261+00:00, run_end_date=2025-10-25 02:40:02.533832+00:00, run_duration=2.069571, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:35:00+00:00, data_interval_end=2025-10-25 02:40:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:40:02,538 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:40:00+00:00, run_after=2025-10-25 02:45:00+00:00
2025-10-25 02:40:02,559 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:40:02,566 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:35:00+00:00, map_index=-1, run_start_date=2025-10-25 02:40:01.776209+00:00, run_end_date=2025-10-25 02:40:02.024909+00:00, run_duration=0.2487, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=71, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:40:01.389795+00:00, queued_by_job_id=5, pid=120985
2025-10-25 02:44:51,705 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:45:00,523 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:45:00+00:00, run_after=2025-10-25 02:50:00+00:00
2025-10-25 02:45:00,551 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:40:00+00:00 [scheduled]>
2025-10-25 02:45:00,551 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:45:00,552 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:40:00+00:00 [scheduled]>
2025-10-25 02:45:00,553 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:40:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:45:00,554 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:40:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:45:00,554 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:45:00,607 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:45:00,612 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:40:00+00:00 [queued]> to 3c79ef7d-ef45-4bce-a039-2d2ad379457e
2025-10-25 02:45:01,714 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:40:00+00:00 [scheduled]>
2025-10-25 02:45:01,715 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:45:01,715 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:40:00+00:00 [scheduled]>
2025-10-25 02:45:01,717 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:40:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:45:01,718 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:40:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:45:01,718 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:45:01,777 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:45:01,779 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:45:01,786 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:40:00+00:00, map_index=-1, run_start_date=2025-10-25 02:45:00.937122+00:00, run_end_date=2025-10-25 02:45:01.207480+00:00, run_duration=0.270358, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=72, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:45:00.552518+00:00, queued_by_job_id=5, pid=121100
2025-10-25 02:45:01,787 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:40:00+00:00 [queued]> to 8809d13d-d09f-495c-bf39-5f8af7b34b4a
2025-10-25 02:45:02,871 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:40:00+00:00: scheduled__2025-10-25T02:40:00+00:00, state:running, queued_at: 2025-10-25 02:45:00.516390+00:00. externally triggered: False> successful
2025-10-25 02:45:02,872 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:40:00+00:00, run_id=scheduled__2025-10-25T02:40:00+00:00, run_start_date=2025-10-25 02:45:00.530859+00:00, run_end_date=2025-10-25 02:45:02.872129+00:00, run_duration=2.34127, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:40:00+00:00, data_interval_end=2025-10-25 02:45:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:45:02,877 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:45:00+00:00, run_after=2025-10-25 02:50:00+00:00
2025-10-25 02:45:02,909 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:45:02,915 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:40:00+00:00, map_index=-1, run_start_date=2025-10-25 02:45:02.120831+00:00, run_end_date=2025-10-25 02:45:02.384911+00:00, run_duration=0.26408, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=73, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:45:01.716322+00:00, queued_by_job_id=5, pid=121129
2025-10-25 02:49:51,736 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:50:00,117 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:50:00+00:00, run_after=2025-10-25 02:55:00+00:00
2025-10-25 02:50:00,145 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:45:00+00:00 [scheduled]>
2025-10-25 02:50:00,146 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:50:00,146 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:45:00+00:00 [scheduled]>
2025-10-25 02:50:00,148 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:45:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:50:00,148 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:45:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:50:00,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:50:00,207 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:50:00,212 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:45:00+00:00 [queued]> to 0dffa3cd-83b9-4864-b086-3372697728c6
2025-10-25 02:50:01,628 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:45:00+00:00 [scheduled]>
2025-10-25 02:50:01,629 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:50:01,629 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:45:00+00:00 [scheduled]>
2025-10-25 02:50:01,631 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:45:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:50:01,632 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:45:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:50:01,632 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:50:01,698 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:50:01,699 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:50:01,704 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:45:00+00:00 [queued]> to 69b0e1f1-bc20-46d9-b984-05ab5f5b1fa0
2025-10-25 02:50:01,705 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:45:00+00:00, map_index=-1, run_start_date=2025-10-25 02:50:00.508306+00:00, run_end_date=2025-10-25 02:50:00.762737+00:00, run_duration=0.254431, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=74, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:50:00.147023+00:00, queued_by_job_id=5, pid=121238
2025-10-25 02:50:02,783 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:45:00+00:00: scheduled__2025-10-25T02:45:00+00:00, state:running, queued_at: 2025-10-25 02:50:00.111623+00:00. externally triggered: False> successful
2025-10-25 02:50:02,784 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:45:00+00:00, run_id=scheduled__2025-10-25T02:45:00+00:00, run_start_date=2025-10-25 02:50:00.124508+00:00, run_end_date=2025-10-25 02:50:02.784349+00:00, run_duration=2.659841, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:45:00+00:00, data_interval_end=2025-10-25 02:50:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:50:02,788 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:50:00+00:00, run_after=2025-10-25 02:55:00+00:00
2025-10-25 02:50:02,808 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:50:02,812 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:45:00+00:00, map_index=-1, run_start_date=2025-10-25 02:50:02.039625+00:00, run_end_date=2025-10-25 02:50:02.318387+00:00, run_duration=0.278762, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=75, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:50:01.630096+00:00, queued_by_job_id=5, pid=121265
2025-10-25 02:54:51,767 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 02:55:01,024 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:55:00+00:00, run_after=2025-10-25 03:00:00+00:00
2025-10-25 02:55:01,057 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:50:00+00:00 [scheduled]>
2025-10-25 02:55:01,057 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:55:01,058 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:50:00+00:00 [scheduled]>
2025-10-25 02:55:01,059 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:50:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:55:01,060 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:50:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 02:55:01,060 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:55:01,113 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:50:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:55:01,117 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:50:00+00:00 [queued]> to ac06e6f9-6195-4a15-945a-b1396074b46d
2025-10-25 02:55:02,208 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:50:00+00:00 [scheduled]>
2025-10-25 02:55:02,208 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 02:55:02,209 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:50:00+00:00 [scheduled]>
2025-10-25 02:55:02,210 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:50:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 02:55:02,211 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:50:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 02:55:02,211 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 02:55:02,275 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:50:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:55:02,278 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:50:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:55:02,283 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:50:00+00:00, map_index=-1, run_start_date=2025-10-25 02:55:01.430423+00:00, run_end_date=2025-10-25 02:55:01.744914+00:00, run_duration=0.314491, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=76, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 02:55:01.058496+00:00, queued_by_job_id=5, pid=121370
2025-10-25 02:55:02,284 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:50:00+00:00 [queued]> to 2718afef-e4f3-4728-b3c0-80f7fa7e905d
2025-10-25 02:55:03,709 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:50:00+00:00: scheduled__2025-10-25T02:50:00+00:00, state:running, queued_at: 2025-10-25 02:55:01.019367+00:00. externally triggered: False> successful
2025-10-25 02:55:03,710 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:50:00+00:00, run_id=scheduled__2025-10-25T02:50:00+00:00, run_start_date=2025-10-25 02:55:01.033612+00:00, run_end_date=2025-10-25 02:55:03.710221+00:00, run_duration=2.676609, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:50:00+00:00, data_interval_end=2025-10-25 02:55:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 02:55:03,714 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 02:55:00+00:00, run_after=2025-10-25 03:00:00+00:00
2025-10-25 02:55:03,738 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:50:00+00:00', try_number=1, map_index=-1)
2025-10-25 02:55:03,743 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:50:00+00:00, map_index=-1, run_start_date=2025-10-25 02:55:02.586364+00:00, run_end_date=2025-10-25 02:55:02.825292+00:00, run_duration=0.238928, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=77, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 02:55:02.209631+00:00, queued_by_job_id=5, pid=121399
2025-10-25 02:59:51,803 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:00:00,745 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:00:00+00:00, run_after=2025-10-25 03:05:00+00:00
2025-10-25 03:00:00,774 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:55:00+00:00 [scheduled]>
2025-10-25 03:00:00,774 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:00:00,774 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:55:00+00:00 [scheduled]>
2025-10-25 03:00:00,776 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:55:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:00:00,777 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:55:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:00:00,777 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T02:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:00:00,850 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:55:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:00:00,855 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T02:55:00+00:00 [queued]> to 4b1e3337-7bf6-4774-85ae-407b08deeac7
2025-10-25 03:00:01,950 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:55:00+00:00 [scheduled]>
2025-10-25 03:00:01,951 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:00:01,951 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:55:00+00:00 [scheduled]>
2025-10-25 03:00:01,953 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:55:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:00:01,954 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:55:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:00:01,954 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T02:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:00:02,018 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:55:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:00:02,019 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T02:55:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:00:02,025 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T02:55:00+00:00 [queued]> to 3b66f8ee-c1d4-4ce0-9312-bf753fc7757e
2025-10-25 03:00:02,025 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T02:55:00+00:00, map_index=-1, run_start_date=2025-10-25 03:00:01.191774+00:00, run_end_date=2025-10-25 03:00:01.480476+00:00, run_duration=0.288702, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=78, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:00:00.775297+00:00, queued_by_job_id=5, pid=121509
2025-10-25 03:00:03,111 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 02:55:00+00:00: scheduled__2025-10-25T02:55:00+00:00, state:running, queued_at: 2025-10-25 03:00:00.738958+00:00. externally triggered: False> successful
2025-10-25 03:00:03,111 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 02:55:00+00:00, run_id=scheduled__2025-10-25T02:55:00+00:00, run_start_date=2025-10-25 03:00:00.753100+00:00, run_end_date=2025-10-25 03:00:03.111487+00:00, run_duration=2.358387, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 02:55:00+00:00, data_interval_end=2025-10-25 03:00:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:00:03,115 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:00:00+00:00, run_after=2025-10-25 03:05:00+00:00
2025-10-25 03:00:03,140 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T02:55:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:00:03,144 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T02:55:00+00:00, map_index=-1, run_start_date=2025-10-25 03:00:02.386783+00:00, run_end_date=2025-10-25 03:00:02.655837+00:00, run_duration=0.269054, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=79, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:00:01.952068+00:00, queued_by_job_id=5, pid=121538
2025-10-25 03:04:51,837 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:05:00,901 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:05:00+00:00, run_after=2025-10-25 03:10:00+00:00
2025-10-25 03:05:00,929 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:00:00+00:00 [scheduled]>
2025-10-25 03:05:00,930 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:05:00,930 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:00:00+00:00 [scheduled]>
2025-10-25 03:05:00,932 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:00:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:05:00,933 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:00:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:05:00,933 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:05:00,981 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:00:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:05:00,988 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:00:00+00:00 [queued]> to 7166a868-4fdb-48b7-86eb-c95b8cd7f3e7
2025-10-25 03:05:01,958 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:00:00+00:00 [scheduled]>
2025-10-25 03:05:01,959 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:05:01,959 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:00:00+00:00 [scheduled]>
2025-10-25 03:05:01,961 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:00:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:05:01,962 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:00:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:05:01,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:05:02,018 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:00:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:05:02,019 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:00:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:05:02,025 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:00:00+00:00 [queued]> to 54457adb-ddd4-436f-989c-478d207d0e49
2025-10-25 03:05:02,026 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:00:00+00:00, map_index=-1, run_start_date=2025-10-25 03:05:01.296063+00:00, run_end_date=2025-10-25 03:05:01.653420+00:00, run_duration=0.357357, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=80, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:05:00.931118+00:00, queued_by_job_id=5, pid=121722
2025-10-25 03:05:03,114 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:00:00+00:00: scheduled__2025-10-25T03:00:00+00:00, state:running, queued_at: 2025-10-25 03:05:00.895224+00:00. externally triggered: False> successful
2025-10-25 03:05:03,115 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:00:00+00:00, run_id=scheduled__2025-10-25T03:00:00+00:00, run_start_date=2025-10-25 03:05:00.908116+00:00, run_end_date=2025-10-25 03:05:03.115110+00:00, run_duration=2.206994, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:00:00+00:00, data_interval_end=2025-10-25 03:05:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:05:03,119 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:05:00+00:00, run_after=2025-10-25 03:10:00+00:00
2025-10-25 03:05:03,140 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:00:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:05:03,144 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:00:00+00:00, map_index=-1, run_start_date=2025-10-25 03:05:02.343696+00:00, run_end_date=2025-10-25 03:05:02.595120+00:00, run_duration=0.251424, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=81, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:05:01.960045+00:00, queued_by_job_id=5, pid=121754
2025-10-25 03:09:26,772 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:09:26+00:00 [scheduled]>
2025-10-25 03:09:26,772 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:09:26,772 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:09:26+00:00 [scheduled]>
2025-10-25 03:09:26,774 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:09:26+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:09:26,775 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:09:26+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:09:26,775 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'manual__2025-10-25T03:09:26+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:09:26,858 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:09:26+00:00', try_number=1, map_index=-1)
2025-10-25 03:09:26,865 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:09:26+00:00 [queued]> to c020ca67-0378-4fe7-a59d-ba15a5f0eb41
2025-10-25 03:09:27,994 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:09:26+00:00 [scheduled]>
2025-10-25 03:09:27,995 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:09:27,995 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:09:26+00:00 [scheduled]>
2025-10-25 03:09:27,996 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:09:26+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:09:27,997 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:09:26+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:09:27,997 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'manual__2025-10-25T03:09:26+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:09:28,044 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:09:26+00:00', try_number=1, map_index=-1)
2025-10-25 03:09:28,045 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:09:26+00:00', try_number=1, map_index=-1)
2025-10-25 03:09:28,050 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=manual__2025-10-25T03:09:26+00:00, map_index=-1, run_start_date=2025-10-25 03:09:27.212971+00:00, run_end_date=2025-10-25 03:09:27.532672+00:00, run_duration=0.319701, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=82, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:09:26.773414+00:00, queued_by_job_id=5, pid=121847
2025-10-25 03:09:28,051 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:09:26+00:00 [queued]> to c704323f-6204-4513-8d7f-4a61bbbf6a0d
2025-10-25 03:09:28,815 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:09:26+00:00: manual__2025-10-25T03:09:26+00:00, state:running, queued_at: 2025-10-25 03:09:26.503419+00:00. externally triggered: True> successful
2025-10-25 03:09:28,815 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:09:26+00:00, run_id=manual__2025-10-25T03:09:26+00:00, run_start_date=2025-10-25 03:09:26.750260+00:00, run_end_date=2025-10-25 03:09:28.815616+00:00, run_duration=2.065356, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:00:00+00:00, data_interval_end=2025-10-25 03:05:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:09:28,835 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:09:26+00:00', try_number=1, map_index=-1)
2025-10-25 03:09:28,841 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=manual__2025-10-25T03:09:26+00:00, map_index=-1, run_start_date=2025-10-25 03:09:28.366946+00:00, run_end_date=2025-10-25 03:09:28.610478+00:00, run_duration=0.243532, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=83, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:09:27.995985+00:00, queued_by_job_id=5, pid=121875
2025-10-25 03:09:51,869 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:10:00,076 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:10:00+00:00, run_after=2025-10-25 03:15:00+00:00
2025-10-25 03:10:00,104 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:05:00+00:00 [scheduled]>
2025-10-25 03:10:00,104 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:10:00,105 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:05:00+00:00 [scheduled]>
2025-10-25 03:10:00,106 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:05:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:10:00,107 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:05:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:10:00,107 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:10:00,155 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:05:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:10:00,162 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:05:00+00:00 [queued]> to 11245805-2306-42d4-92e9-3d18afb7364f
2025-10-25 03:10:00,827 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:05:00+00:00 [scheduled]>
2025-10-25 03:10:00,827 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:10:00,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:05:00+00:00 [scheduled]>
2025-10-25 03:10:00,829 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:05:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:10:00,829 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:05:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:10:00,830 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:10:00,901 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:05:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:10:00,912 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:05:00+00:00 [queued]> to b734bfe4-3628-42fb-8bc2-04d02e30c82c
2025-10-25 03:10:00,973 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:05:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:10:00,978 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:05:00+00:00, map_index=-1, run_start_date=2025-10-25 03:10:00.476858+00:00, run_end_date=2025-10-25 03:10:00.792306+00:00, run_duration=0.315448, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=84, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:10:00.105586+00:00, queued_by_job_id=5, pid=121922
2025-10-25 03:10:02,010 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:05:00+00:00: scheduled__2025-10-25T03:05:00+00:00, state:running, queued_at: 2025-10-25 03:10:00.069628+00:00. externally triggered: False> successful
2025-10-25 03:10:02,011 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:05:00+00:00, run_id=scheduled__2025-10-25T03:05:00+00:00, run_start_date=2025-10-25 03:10:00.083536+00:00, run_end_date=2025-10-25 03:10:02.011077+00:00, run_duration=1.927541, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:05:00+00:00, data_interval_end=2025-10-25 03:10:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:10:02,015 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:10:00+00:00, run_after=2025-10-25 03:15:00+00:00
2025-10-25 03:10:02,042 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:05:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:10:02,047 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:05:00+00:00, map_index=-1, run_start_date=2025-10-25 03:10:01.236257+00:00, run_end_date=2025-10-25 03:10:01.507044+00:00, run_duration=0.270787, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=85, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:10:00.828386+00:00, queued_by_job_id=5, pid=121950
2025-10-25 03:14:51,901 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:15:00,174 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:15:00+00:00, run_after=2025-10-25 03:20:00+00:00
2025-10-25 03:15:00,209 INFO - 2 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:10:00+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:15:00+00:00 [scheduled]>
2025-10-25 03:15:00,209 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:15:00,209 INFO - DAG worker_health_monitor has 1/16 running and queued tasks
2025-10-25 03:15:00,209 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:10:00+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:15:00+00:00 [scheduled]>
2025-10-25 03:15:00,211 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:10:00+00:00 [scheduled]>, <TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:15:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:15:00,212 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:10:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:15:00,213 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:15:00,213 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:15:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:15:00,213 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'manual__2025-10-25T03:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:15:00,385 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:10:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:00,385 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:00,393 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:10:00+00:00 [queued]> to 5b59f294-2f4b-413d-bb2b-a738839535c0
2025-10-25 03:15:00,394 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:15:00+00:00 [queued]> to 70f7ef14-d6da-43b7-a689-b088bea002b2
2025-10-25 03:15:01,888 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:10:00+00:00 [scheduled]>
2025-10-25 03:15:01,888 INFO - DAG worker_health_monitor has 1/16 running and queued tasks
2025-10-25 03:15:01,889 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:10:00+00:00 [scheduled]>
2025-10-25 03:15:01,891 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:10:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:15:01,892 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:10:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:15:01,892 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:15:01,980 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:10:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:01,984 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:10:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:01,993 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:10:00+00:00, map_index=-1, run_start_date=2025-10-25 03:15:00.824201+00:00, run_end_date=2025-10-25 03:15:01.736595+00:00, run_duration=0.912394, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=86, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:15:00.210358+00:00, queued_by_job_id=5, pid=122099
2025-10-25 03:15:01,996 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:10:00+00:00 [queued]> to d550cc82-ada1-4eef-b6a3-81e11f842ca8
2025-10-25 03:15:02,067 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:15:00+00:00 [scheduled]>
2025-10-25 03:15:02,067 INFO - DAG worker_health_monitor has 1/16 running and queued tasks
2025-10-25 03:15:02,068 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:15:00+00:00 [scheduled]>
2025-10-25 03:15:02,070 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:15:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:15:02,070 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:15:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:15:02,071 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'manual__2025-10-25T03:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:15:02,143 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:02,145 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:02,150 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=manual__2025-10-25T03:15:00+00:00, map_index=-1, run_start_date=2025-10-25 03:15:00.945847+00:00, run_end_date=2025-10-25 03:15:01.867645+00:00, run_duration=0.921798, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=87, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:15:00.210358+00:00, queued_by_job_id=5, pid=122109
2025-10-25 03:15:02,151 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:15:00+00:00 [queued]> to ec561b0b-8895-4e05-8921-e5448ff24ee0
2025-10-25 03:15:03,326 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:15:00+00:00: manual__2025-10-25T03:15:00+00:00, state:running, queued_at: 2025-10-25 03:15:00.066265+00:00. externally triggered: True> successful
2025-10-25 03:15:03,326 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:15:00+00:00, run_id=manual__2025-10-25T03:15:00+00:00, run_start_date=2025-10-25 03:15:00.181439+00:00, run_end_date=2025-10-25 03:15:03.326694+00:00, run_duration=3.145255, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:10:00+00:00, data_interval_end=2025-10-25 03:15:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:15:03,335 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:10:00+00:00: scheduled__2025-10-25T03:10:00+00:00, state:running, queued_at: 2025-10-25 03:15:00.167877+00:00. externally triggered: False> successful
2025-10-25 03:15:03,336 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:10:00+00:00, run_id=scheduled__2025-10-25T03:10:00+00:00, run_start_date=2025-10-25 03:15:00.181201+00:00, run_end_date=2025-10-25 03:15:03.336377+00:00, run_duration=3.155176, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:10:00+00:00, data_interval_end=2025-10-25 03:15:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:15:03,341 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:15:00+00:00, run_after=2025-10-25 03:20:00+00:00
2025-10-25 03:15:03,370 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:10:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:03,370 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:15:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:15:03,375 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:10:00+00:00, map_index=-1, run_start_date=2025-10-25 03:15:02.430270+00:00, run_end_date=2025-10-25 03:15:02.730537+00:00, run_duration=0.300267, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=88, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:15:01.889788+00:00, queued_by_job_id=5, pid=122158
2025-10-25 03:15:03,376 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=manual__2025-10-25T03:15:00+00:00, map_index=-1, run_start_date=2025-10-25 03:15:02.650185+00:00, run_end_date=2025-10-25 03:15:02.925182+00:00, run_duration=0.274997, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=89, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:15:02.068664+00:00, queued_by_job_id=5, pid=122171
2025-10-25 03:16:52,393 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:16:52.042860+00:00 [scheduled]>
2025-10-25 03:16:52,393 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:16:52,394 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:16:52.042860+00:00 [scheduled]>
2025-10-25 03:16:52,396 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:16:52.042860+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:16:52,397 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:16:52.042860+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:16:52,397 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'manual__2025-10-25T03:16:52.042860+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:16:52,450 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:16:52.042860+00:00', try_number=1, map_index=-1)
2025-10-25 03:16:52,466 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health manual__2025-10-25T03:16:52.042860+00:00 [queued]> to 8ed2c3d6-4be3-449e-b2cc-56b77a892852
2025-10-25 03:16:53,614 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:16:52.042860+00:00 [scheduled]>
2025-10-25 03:16:53,614 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:16:53,615 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:16:52.042860+00:00 [scheduled]>
2025-10-25 03:16:53,616 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:16:52.042860+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:16:53,617 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:16:52.042860+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:16:53,617 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'manual__2025-10-25T03:16:52.042860+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:16:53,702 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:16:52.042860+00:00', try_number=1, map_index=-1)
2025-10-25 03:16:53,713 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed manual__2025-10-25T03:16:52.042860+00:00 [queued]> to 00e3ac14-db65-4f35-92fb-146fd8225b1b
2025-10-25 03:16:53,765 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='manual__2025-10-25T03:16:52.042860+00:00', try_number=1, map_index=-1)
2025-10-25 03:16:53,771 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=manual__2025-10-25T03:16:52.042860+00:00, map_index=-1, run_start_date=2025-10-25 03:16:52.829516+00:00, run_end_date=2025-10-25 03:16:53.576253+00:00, run_duration=0.746737, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=90, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:16:52.394756+00:00, queued_by_job_id=5, pid=122233
2025-10-25 03:16:54,802 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:16:52.042860+00:00: manual__2025-10-25T03:16:52.042860+00:00, state:running, queued_at: 2025-10-25 03:16:52.064051+00:00. externally triggered: True> successful
2025-10-25 03:16:54,803 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:16:52.042860+00:00, run_id=manual__2025-10-25T03:16:52.042860+00:00, run_start_date=2025-10-25 03:16:52.362264+00:00, run_end_date=2025-10-25 03:16:54.803035+00:00, run_duration=2.440771, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:10:00+00:00, data_interval_end=2025-10-25 03:15:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:16:54,828 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='manual__2025-10-25T03:16:52.042860+00:00', try_number=1, map_index=-1)
2025-10-25 03:16:54,832 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=manual__2025-10-25T03:16:52.042860+00:00, map_index=-1, run_start_date=2025-10-25 03:16:54.022188+00:00, run_end_date=2025-10-25 03:16:54.268586+00:00, run_duration=0.246398, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=91, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:16:53.615489+00:00, queued_by_job_id=5, pid=122263
2025-10-25 03:19:11,923 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:18:43+00:00 [scheduled]>
2025-10-25 03:19:11,923 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:19:11,924 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:18:43+00:00 [scheduled]>
2025-10-25 03:19:11,925 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:18:43+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:19:11,926 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:18:43+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 03:19:11,926 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T03:18:43+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:19:11,984 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:18:43+00:00', try_number=1, map_index=-1)
2025-10-25 03:19:11,990 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:18:43+00:00 [queued]> to b02ddcf5-d62f-47b3-95a1-63b6198c1dc0
2025-10-25 03:19:12,903 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:18:43+00:00 [scheduled]>
2025-10-25 03:19:12,904 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:19:12,904 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:18:43+00:00 [scheduled]>
2025-10-25 03:19:12,906 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:18:43+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:19:12,906 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:18:43+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 03:19:12,906 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T03:18:43+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:19:12,963 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:18:43+00:00', try_number=1, map_index=-1)
2025-10-25 03:19:12,964 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:18:43+00:00', try_number=1, map_index=-1)
2025-10-25 03:19:12,970 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:18:43+00:00 [queued]> to d0aa7ff6-2d2d-4c5e-9c2f-ac5ce32c62cd
2025-10-25 03:19:12,971 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T03:18:43+00:00, map_index=-1, run_start_date=2025-10-25 03:19:12.324417+00:00, run_end_date=2025-10-25 03:19:12.603750+00:00, run_duration=0.279333, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 03:19:11.924825+00:00, queued_by_job_id=5, pid=122324
2025-10-25 03:19:14,086 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:18:43+00:00', try_number=1, map_index=-1)
2025-10-25 03:19:14,091 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T03:18:43+00:00, map_index=-1, run_start_date=2025-10-25 03:19:13.328868+00:00, run_end_date=2025-10-25 03:19:13.610984+00:00, run_duration=0.282116, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=93, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 03:19:12.904873+00:00, queued_by_job_id=5, pid=122350
2025-10-25 03:19:16,157 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 03:18:43+00:00: manual__2025-10-25T03:18:43+00:00, state:running, queued_at: 2025-10-25 03:19:11.792739+00:00. externally triggered: True> failed
2025-10-25 03:19:16,158 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 03:18:43+00:00, run_id=manual__2025-10-25T03:18:43+00:00, run_start_date=2025-10-25 03:19:11.902570+00:00, run_end_date=2025-10-25 03:19:16.158219+00:00, run_duration=4.255649, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:18:43+00:00, data_interval_end=2025-10-25 03:18:43+00:00, dag_hash=d11bab07c2b0e5d85a58e5768b00bc33
2025-10-25 03:19:51,940 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:20:00,364 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:20:12,224 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:20:43,140 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:21:13,201 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:21:43,260 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:22:13,276 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:22:43,334 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:23:13,742 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:23:25,826 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:23:24+00:00 [scheduled]>
2025-10-25 03:23:25,826 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:23:25,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:23:24+00:00 [scheduled]>
2025-10-25 03:23:25,828 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:23:24+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:23:25,829 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:23:24+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 03:23:25,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T03:23:24+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:23:25,877 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:23:24+00:00', try_number=1, map_index=-1)
2025-10-25 03:23:25,881 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:23:24+00:00 [queued]> to 62e0da42-1883-415a-bcbb-2d14ffe4f914
2025-10-25 03:23:27,458 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:23:24+00:00 [scheduled]>
2025-10-25 03:23:27,459 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:23:27,459 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:23:24+00:00 [scheduled]>
2025-10-25 03:23:27,461 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:23:24+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:23:27,462 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:23:24+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 03:23:27,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T03:23:24+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:23:27,525 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:23:24+00:00', try_number=1, map_index=-1)
2025-10-25 03:23:27,526 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:23:24+00:00', try_number=1, map_index=-1)
2025-10-25 03:23:27,530 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:23:24+00:00 [queued]> to d66d815d-5e98-49db-8d25-784c9f032018
2025-10-25 03:23:27,530 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T03:23:24+00:00, map_index=-1, run_start_date=2025-10-25 03:23:26.163485+00:00, run_end_date=2025-10-25 03:23:26.424477+00:00, run_duration=0.260992, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 03:23:25.827437+00:00, queued_by_job_id=5, pid=122451
2025-10-25 03:23:28,643 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:23:24+00:00', try_number=1, map_index=-1)
2025-10-25 03:23:28,649 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T03:23:24+00:00, map_index=-1, run_start_date=2025-10-25 03:23:27.816658+00:00, run_end_date=2025-10-25 03:23:28.050773+00:00, run_duration=0.234115, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 03:23:27.460154+00:00, queued_by_job_id=5, pid=122477
2025-10-25 03:23:29,810 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 03:23:24+00:00: manual__2025-10-25T03:23:24+00:00, state:running, queued_at: 2025-10-25 03:23:24.918853+00:00. externally triggered: True> failed
2025-10-25 03:23:29,811 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 03:23:24+00:00, run_id=manual__2025-10-25T03:23:24+00:00, run_start_date=2025-10-25 03:23:25.804218+00:00, run_end_date=2025-10-25 03:23:29.811075+00:00, run_duration=4.006857, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:23:24+00:00, data_interval_end=2025-10-25 03:23:24+00:00, dag_hash=d11bab07c2b0e5d85a58e5768b00bc33
2025-10-25 03:23:43,848 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:24:14,976 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:24:45,079 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:20:00+00:00, run_after=2025-10-25 03:25:00+00:00
2025-10-25 03:24:51,977 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:25:00,432 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:25:00+00:00, run_after=2025-10-25 03:30:00+00:00
2025-10-25 03:25:00,465 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:20:00+00:00 [scheduled]>
2025-10-25 03:25:00,466 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:25:00,466 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:20:00+00:00 [scheduled]>
2025-10-25 03:25:00,468 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:20:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:25:00,469 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:20:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:25:00,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:25:00,517 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:25:00,523 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:20:00+00:00 [queued]> to cb4c48d7-591e-4a34-b178-b5d921029bb8
2025-10-25 03:25:02,679 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:20:00+00:00 [scheduled]>
2025-10-25 03:25:02,679 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:25:02,680 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:20:00+00:00 [scheduled]>
2025-10-25 03:25:02,682 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:20:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:25:02,683 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:20:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:25:02,683 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:25:02,745 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:25:02,745 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:25:02,754 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:20:00+00:00 [queued]> to 14924601-862c-4d3e-824d-53a36822d367
2025-10-25 03:25:02,754 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:20:00+00:00, map_index=-1, run_start_date=2025-10-25 03:25:00.871230+00:00, run_end_date=2025-10-25 03:25:01.685580+00:00, run_duration=0.81435, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=96, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:25:00.467437+00:00, queued_by_job_id=5, pid=122523
2025-10-25 03:25:03,844 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:20:00+00:00: scheduled__2025-10-25T03:20:00+00:00, state:running, queued_at: 2025-10-25 03:25:00.424943+00:00. externally triggered: False> successful
2025-10-25 03:25:03,845 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:20:00+00:00, run_id=scheduled__2025-10-25T03:20:00+00:00, run_start_date=2025-10-25 03:25:00.441216+00:00, run_end_date=2025-10-25 03:25:03.845224+00:00, run_duration=3.404008, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:20:00+00:00, data_interval_end=2025-10-25 03:25:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:25:03,848 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:25:00+00:00, run_after=2025-10-25 03:30:00+00:00
2025-10-25 03:25:03,872 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:20:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:25:03,881 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:20:00+00:00, map_index=-1, run_start_date=2025-10-25 03:25:03.075412+00:00, run_end_date=2025-10-25 03:25:03.343537+00:00, run_duration=0.268125, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:25:02.680903+00:00, queued_by_job_id=5, pid=122556
2025-10-25 03:29:52,028 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:30:00,748 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:30:00+00:00, run_after=2025-10-25 03:35:00+00:00
2025-10-25 03:30:00,780 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:25:00+00:00 [scheduled]>
2025-10-25 03:30:00,780 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:30:00,780 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:25:00+00:00 [scheduled]>
2025-10-25 03:30:00,782 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:25:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:30:00,783 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:25:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:30:00,783 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:30:00,833 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:30:00,839 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:25:00+00:00 [queued]> to 06681190-4812-41a3-81a1-3b26c31e9e9f
2025-10-25 03:30:02,696 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:25:00+00:00 [scheduled]>
2025-10-25 03:30:02,697 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:30:02,697 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:25:00+00:00 [scheduled]>
2025-10-25 03:30:02,699 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:25:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:30:02,700 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:25:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:30:02,700 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:30:02,770 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:30:02,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:30:02,778 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:25:00+00:00 [queued]> to e49249c4-0b04-408b-b46e-e899cb4d03a5
2025-10-25 03:30:02,778 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:25:00+00:00, map_index=-1, run_start_date=2025-10-25 03:30:01.165151+00:00, run_end_date=2025-10-25 03:30:02.048415+00:00, run_duration=0.883264, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=98, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:30:00.781263+00:00, queued_by_job_id=5, pid=122706
2025-10-25 03:30:03,893 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:25:00+00:00: scheduled__2025-10-25T03:25:00+00:00, state:running, queued_at: 2025-10-25 03:30:00.740837+00:00. externally triggered: False> successful
2025-10-25 03:30:03,893 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:25:00+00:00, run_id=scheduled__2025-10-25T03:25:00+00:00, run_start_date=2025-10-25 03:30:00.756650+00:00, run_end_date=2025-10-25 03:30:03.893745+00:00, run_duration=3.137095, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:25:00+00:00, data_interval_end=2025-10-25 03:30:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:30:03,899 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:30:00+00:00, run_after=2025-10-25 03:35:00+00:00
2025-10-25 03:30:03,928 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:25:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:30:03,934 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:25:00+00:00, map_index=-1, run_start_date=2025-10-25 03:30:03.150878+00:00, run_end_date=2025-10-25 03:30:03.409083+00:00, run_duration=0.258205, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=99, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:30:02.698021+00:00, queued_by_job_id=5, pid=122735
2025-10-25 03:34:52,041 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:35:00,035 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:35:00+00:00, run_after=2025-10-25 03:40:00+00:00
2025-10-25 03:35:00,064 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:30:00+00:00 [scheduled]>
2025-10-25 03:35:00,064 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:35:00,064 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:30:00+00:00 [scheduled]>
2025-10-25 03:35:00,066 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:30:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:35:00,067 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:30:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:35:00,067 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:35:00,119 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:35:00,126 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:30:00+00:00 [queued]> to 30e77849-b56b-4ae8-b0a8-45bd4f662732
2025-10-25 03:35:02,282 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:30:00+00:00 [scheduled]>
2025-10-25 03:35:02,283 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:35:02,283 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:30:00+00:00 [scheduled]>
2025-10-25 03:35:02,285 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:30:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:35:02,285 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:30:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:35:02,285 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:35:02,345 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:35:02,346 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:35:02,352 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:30:00+00:00, map_index=-1, run_start_date=2025-10-25 03:35:00.437006+00:00, run_end_date=2025-10-25 03:35:01.348740+00:00, run_duration=0.911734, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=100, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:35:00.065347+00:00, queued_by_job_id=5, pid=122831
2025-10-25 03:35:02,353 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:30:00+00:00 [queued]> to 64c0d07f-3628-4da5-a853-1692f5eec945
2025-10-25 03:35:03,455 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:30:00+00:00: scheduled__2025-10-25T03:30:00+00:00, state:running, queued_at: 2025-10-25 03:35:00.027106+00:00. externally triggered: False> successful
2025-10-25 03:35:03,456 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:30:00+00:00, run_id=scheduled__2025-10-25T03:30:00+00:00, run_start_date=2025-10-25 03:35:00.042817+00:00, run_end_date=2025-10-25 03:35:03.456318+00:00, run_duration=3.413501, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:30:00+00:00, data_interval_end=2025-10-25 03:35:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:35:03,460 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:35:00+00:00, run_after=2025-10-25 03:40:00+00:00
2025-10-25 03:35:03,485 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:30:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:35:03,489 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:30:00+00:00, map_index=-1, run_start_date=2025-10-25 03:35:02.729751+00:00, run_end_date=2025-10-25 03:35:03.003562+00:00, run_duration=0.273811, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:35:02.283778+00:00, queued_by_job_id=5, pid=122863
2025-10-25 03:39:52,072 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:40:00,527 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:40:00+00:00, run_after=2025-10-25 03:45:00+00:00
2025-10-25 03:40:00,562 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:35:00+00:00 [scheduled]>
2025-10-25 03:40:00,563 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:40:00,564 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:35:00+00:00 [scheduled]>
2025-10-25 03:40:00,566 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:35:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:40:00,566 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:35:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:40:00,567 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:40:00,641 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:40:00,646 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:35:00+00:00 [queued]> to dd75b5d6-5bc6-402c-b42e-c25d926cf3da
2025-10-25 03:40:02,209 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:35:00+00:00 [scheduled]>
2025-10-25 03:40:02,210 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:40:02,210 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:35:00+00:00 [scheduled]>
2025-10-25 03:40:02,212 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:35:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:40:02,212 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:35:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:40:02,213 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:40:02,282 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:40:02,283 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:40:02,291 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:35:00+00:00 [queued]> to f07395db-abaf-4431-9384-06cf142edbc8
2025-10-25 03:40:02,292 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:35:00+00:00, map_index=-1, run_start_date=2025-10-25 03:40:00.953815+00:00, run_end_date=2025-10-25 03:40:01.760642+00:00, run_duration=0.806827, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=102, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:40:00.564641+00:00, queued_by_job_id=5, pid=122964
2025-10-25 03:40:03,383 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:35:00+00:00: scheduled__2025-10-25T03:35:00+00:00, state:running, queued_at: 2025-10-25 03:40:00.519533+00:00. externally triggered: False> successful
2025-10-25 03:40:03,383 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:35:00+00:00, run_id=scheduled__2025-10-25T03:35:00+00:00, run_start_date=2025-10-25 03:40:00.536923+00:00, run_end_date=2025-10-25 03:40:03.383837+00:00, run_duration=2.846914, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:35:00+00:00, data_interval_end=2025-10-25 03:40:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:40:03,389 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:40:00+00:00, run_after=2025-10-25 03:45:00+00:00
2025-10-25 03:40:03,419 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:35:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:40:03,426 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:35:00+00:00, map_index=-1, run_start_date=2025-10-25 03:40:02.612659+00:00, run_end_date=2025-10-25 03:40:02.858867+00:00, run_duration=0.246208, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=103, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:40:02.210949+00:00, queued_by_job_id=5, pid=122993
2025-10-25 03:44:52,107 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:45:00,452 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:45:00+00:00, run_after=2025-10-25 03:50:00+00:00
2025-10-25 03:45:00,482 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:40:00+00:00 [scheduled]>
2025-10-25 03:45:00,482 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:45:00,482 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:40:00+00:00 [scheduled]>
2025-10-25 03:45:00,484 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:40:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:45:00,485 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:40:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:45:00,485 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:45:00,570 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:00,581 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:40:00+00:00 [queued]> to 87c610ed-7cd3-4446-9327-15262d594bd3
2025-10-25 03:45:02,832 INFO - 2 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:45:02+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:40:00+00:00 [scheduled]>
2025-10-25 03:45:02,833 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:45:02,833 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:45:02,833 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:45:02+00:00 [scheduled]>
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:40:00+00:00 [scheduled]>
2025-10-25 03:45:02,835 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:45:02+00:00 [scheduled]>, <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:40:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:45:02,836 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:45:02+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 03:45:02,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T03:45:02+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:45:02,836 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:40:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:45:02,837 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:45:02,961 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:45:02+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:02,961 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:02,967 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:02,976 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:40:00+00:00 [queued]> to 6b956f04-1b42-4441-bda9-a4c7b2eb686b
2025-10-25 03:45:02,977 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:40:00+00:00, map_index=-1, run_start_date=2025-10-25 03:45:00.953999+00:00, run_end_date=2025-10-25 03:45:01.803545+00:00, run_duration=0.849546, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=104, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:45:00.483299+00:00, queued_by_job_id=5, pid=123244
2025-10-25 03:45:02,978 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:45:02+00:00 [queued]> to efd5834d-d302-44c7-a87d-d1a19df9effa
2025-10-25 03:45:04,153 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:40:00+00:00: scheduled__2025-10-25T03:40:00+00:00, state:running, queued_at: 2025-10-25 03:45:00.446209+00:00. externally triggered: False> successful
2025-10-25 03:45:04,153 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:40:00+00:00, run_id=scheduled__2025-10-25T03:40:00+00:00, run_start_date=2025-10-25 03:45:00.459688+00:00, run_end_date=2025-10-25 03:45:04.153672+00:00, run_duration=3.693984, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:40:00+00:00, data_interval_end=2025-10-25 03:45:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:45:04,159 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:45:00+00:00, run_after=2025-10-25 03:50:00+00:00
2025-10-25 03:45:04,169 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:45:02+00:00 [scheduled]>
2025-10-25 03:45:04,169 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:45:04,169 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:45:02+00:00 [scheduled]>
2025-10-25 03:45:04,171 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:45:02+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:45:04,172 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:45:02+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 03:45:04,172 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T03:45:02+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:45:04,256 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:45:02+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:04,257 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:45:02+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:04,257 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:40:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:45:04,266 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:45:02+00:00 [queued]> to 02449894-7f12-432b-9d08-beab1e52ee4e
2025-10-25 03:45:04,267 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T03:45:02+00:00, map_index=-1, run_start_date=2025-10-25 03:45:03.543858+00:00, run_end_date=2025-10-25 03:45:03.828940+00:00, run_duration=0.285082, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 03:45:02.834117+00:00, queued_by_job_id=5, pid=123291
2025-10-25 03:45:04,267 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:40:00+00:00, map_index=-1, run_start_date=2025-10-25 03:45:03.517875+00:00, run_end_date=2025-10-25 03:45:03.808411+00:00, run_duration=0.290536, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=105, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:45:02.834117+00:00, queued_by_job_id=5, pid=123288
2025-10-25 03:49:52,171 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:50:00,162 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:50:00+00:00, run_after=2025-10-25 03:55:00+00:00
2025-10-25 03:50:00,201 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:45:00+00:00 [scheduled]>
2025-10-25 03:50:00,201 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:50:00,201 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:45:00+00:00 [scheduled]>
2025-10-25 03:50:00,203 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:45:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:50:00,203 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:45:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 03:50:00,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'check_worker_health', 'scheduled__2025-10-25T03:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:50:00,255 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:50:00,263 INFO - Setting external_id for <TaskInstance: worker_health_monitor.check_worker_health scheduled__2025-10-25T03:45:00+00:00 [queued]> to 167fc11c-9d26-4282-8209-84375a119653
2025-10-25 03:50:02,466 INFO - 1 tasks up for execution:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:45:00+00:00 [scheduled]>
2025-10-25 03:50:02,466 INFO - DAG worker_health_monitor has 0/16 running and queued tasks
2025-10-25 03:50:02,466 INFO - Setting the following tasks to queued state:
	<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:45:00+00:00 [scheduled]>
2025-10-25 03:50:02,468 INFO - Trying to enqueue tasks: [<TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:45:00+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:50:02,469 INFO - Sending TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:45:00+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 1 and queue default
2025-10-25 03:50:02,469 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'worker_health_monitor', 'send_alert_if_needed', 'scheduled__2025-10-25T03:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/worker_health_monitor.py']
2025-10-25 03:50:02,532 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:50:02,532 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='check_worker_health', run_id='scheduled__2025-10-25T03:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:50:02,541 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=check_worker_health, run_id=scheduled__2025-10-25T03:45:00+00:00, map_index=-1, run_start_date=2025-10-25 03:50:00.597142+00:00, run_end_date=2025-10-25 03:50:01.436494+00:00, run_duration=0.839352, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=108, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 03:50:00.202173+00:00, queued_by_job_id=5, pid=123859
2025-10-25 03:50:02,542 INFO - Setting external_id for <TaskInstance: worker_health_monitor.send_alert_if_needed scheduled__2025-10-25T03:45:00+00:00 [queued]> to e0c14c6c-9b6a-43ce-aa5a-1defaaac6388
2025-10-25 03:50:03,167 INFO - Marking run <DagRun worker_health_monitor @ 2025-10-25 03:45:00+00:00: scheduled__2025-10-25T03:45:00+00:00, state:running, queued_at: 2025-10-25 03:50:00.156052+00:00. externally triggered: False> successful
2025-10-25 03:50:03,168 INFO - DagRun Finished: dag_id=worker_health_monitor, execution_date=2025-10-25 03:45:00+00:00, run_id=scheduled__2025-10-25T03:45:00+00:00, run_start_date=2025-10-25 03:50:00.170196+00:00, run_end_date=2025-10-25 03:50:03.168293+00:00, run_duration=2.998097, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-10-25 03:45:00+00:00, data_interval_end=2025-10-25 03:50:00+00:00, dag_hash=00ba98b4faff651fb5f4e3d31fbe7bb8
2025-10-25 03:50:03,172 INFO - Setting next_dagrun for worker_health_monitor to 2025-10-25 03:50:00+00:00, run_after=2025-10-25 03:55:00+00:00
2025-10-25 03:50:04,264 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='worker_health_monitor', task_id='send_alert_if_needed', run_id='scheduled__2025-10-25T03:45:00+00:00', try_number=1, map_index=-1)
2025-10-25 03:50:04,268 INFO - TaskInstance Finished: dag_id=worker_health_monitor, task_id=send_alert_if_needed, run_id=scheduled__2025-10-25T03:45:00+00:00, map_index=-1, run_start_date=2025-10-25 03:50:02.880987+00:00, run_end_date=2025-10-25 03:50:03.144690+00:00, run_duration=0.263703, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-10-25 03:50:02.467416+00:00, queued_by_job_id=5, pid=123889
2025-10-25 03:50:05,323 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:45:02+00:00', try_number=1, map_index=-1)
2025-10-25 03:50:05,327 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T03:45:02+00:00, map_index=-1, run_start_date=2025-10-25 03:45:04.581802+00:00, run_end_date=2025-10-25 03:50:04.958589+00:00, run_duration=300.376787, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 03:45:04.170303+00:00, queued_by_job_id=5, pid=123327
2025-10-25 03:50:07,403 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 03:45:02+00:00: manual__2025-10-25T03:45:02+00:00, state:running, queued_at: 2025-10-25 03:45:02.563765+00:00. externally triggered: True> failed
2025-10-25 03:50:07,404 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 03:45:02+00:00, run_id=manual__2025-10-25T03:45:02+00:00, run_start_date=2025-10-25 03:45:02.798795+00:00, run_end_date=2025-10-25 03:50:07.404486+00:00, run_duration=304.605691, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:45:02+00:00, data_interval_end=2025-10-25 03:45:02+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 03:51:26,861 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:51:18+00:00 [scheduled]>
2025-10-25 03:51:26,862 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:51:26,862 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:51:18+00:00 [scheduled]>
2025-10-25 03:51:26,864 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:51:18+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:51:26,864 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:51:18+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 03:51:26,864 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T03:51:18+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:51:26,917 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:51:18+00:00', try_number=1, map_index=-1)
2025-10-25 03:51:26,924 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T03:51:18+00:00 [queued]> to 48da312e-9fc6-4964-a13c-5e77bcb9817a
2025-10-25 03:51:28,063 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:51:18+00:00 [scheduled]>
2025-10-25 03:51:28,063 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 03:51:28,064 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:51:18+00:00 [scheduled]>
2025-10-25 03:51:28,065 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:51:18+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 03:51:28,066 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:51:18+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 03:51:28,066 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T03:51:18+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 03:51:28,120 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:51:18+00:00', try_number=1, map_index=-1)
2025-10-25 03:51:28,121 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T03:51:18+00:00', try_number=1, map_index=-1)
2025-10-25 03:51:28,129 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T03:51:18+00:00, map_index=-1, run_start_date=2025-10-25 03:51:27.306370+00:00, run_end_date=2025-10-25 03:51:27.554037+00:00, run_duration=0.247667, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 03:51:26.862941+00:00, queued_by_job_id=5, pid=123956
2025-10-25 03:51:28,132 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T03:51:18+00:00 [queued]> to e4906bd9-d5ab-4aca-88c1-3205c0372d37
2025-10-25 03:54:52,228 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 03:56:29,341 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T03:51:18+00:00', try_number=1, map_index=-1)
2025-10-25 03:56:29,347 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T03:51:18+00:00, map_index=-1, run_start_date=2025-10-25 03:51:28.465063+00:00, run_end_date=2025-10-25 03:56:28.826260+00:00, run_duration=300.361197, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 03:51:28.064612+00:00, queued_by_job_id=5, pid=123981
2025-10-25 03:58:50,286 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 03:51:18+00:00: manual__2025-10-25T03:51:18+00:00, state:running, queued_at: 2025-10-25 03:51:26.603961+00:00. externally triggered: True> failed
2025-10-25 03:58:50,287 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 03:51:18+00:00, run_id=manual__2025-10-25T03:51:18+00:00, run_start_date=2025-10-25 03:51:26.840385+00:00, run_end_date=2025-10-25 03:58:50.287194+00:00, run_duration=443.446809, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 03:51:18+00:00, data_interval_end=2025-10-25 03:51:18+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 03:59:52,277 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:00:53,539 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:00:44+00:00 [scheduled]>
2025-10-25 04:00:53,540 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 04:00:53,540 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:00:44+00:00 [scheduled]>
2025-10-25 04:00:53,542 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:00:44+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:00:53,542 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:00:44+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 04:00:53,542 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T04:00:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:00:53,596 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:00:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:00:53,603 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:00:44+00:00 [queued]> to 87e93cce-3ebf-4e22-80e5-b40061d1e02b
2025-10-25 04:00:54,204 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:00:44+00:00 [scheduled]>
2025-10-25 04:00:54,205 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 04:00:54,205 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:00:44+00:00 [scheduled]>
2025-10-25 04:00:54,207 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:00:44+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:00:54,207 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:00:44+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 04:00:54,207 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T04:00:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:00:54,265 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:00:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:00:54,270 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:00:44+00:00 [queued]> to 0da19bec-658a-4ec7-9eeb-430c5530ccfa
2025-10-25 04:00:54,331 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:00:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:00:54,338 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T04:00:44+00:00, map_index=-1, run_start_date=2025-10-25 04:00:53.896086+00:00, run_end_date=2025-10-25 04:00:54.136953+00:00, run_duration=0.240867, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 04:00:53.541049+00:00, queued_by_job_id=5, pid=124699
2025-10-25 04:04:52,335 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:05:55,423 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:00:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:05:55,426 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T04:00:44+00:00, map_index=-1, run_start_date=2025-10-25 04:00:54.601690+00:00, run_end_date=2025-10-25 04:05:54.966942+00:00, run_duration=300.365252, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 04:00:54.205964+00:00, queued_by_job_id=5, pid=124724
2025-10-25 04:05:57,491 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 04:00:44+00:00: manual__2025-10-25T04:00:44+00:00, state:running, queued_at: 2025-10-25 04:00:53.349007+00:00. externally triggered: True> failed
2025-10-25 04:05:57,491 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 04:00:44+00:00, run_id=manual__2025-10-25T04:00:44+00:00, run_start_date=2025-10-25 04:00:53.517012+00:00, run_end_date=2025-10-25 04:05:57.491550+00:00, run_duration=303.974538, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 04:00:44+00:00, data_interval_end=2025-10-25 04:00:44+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 04:09:52,365 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:14:52,397 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:19:52,428 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:24:52,460 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:29:47,003 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:29:43+00:00 [scheduled]>
2025-10-25 04:29:47,004 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 04:29:47,004 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:29:43+00:00 [scheduled]>
2025-10-25 04:29:47,006 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:29:43+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:29:47,006 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:29:43+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 04:29:47,006 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T04:29:43+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:29:47,056 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:29:43+00:00', try_number=1, map_index=-1)
2025-10-25 04:29:47,064 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:29:43+00:00 [queued]> to a7390833-ed14-4098-8204-399e42bed922
2025-10-25 04:29:47,916 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:29:43+00:00 [scheduled]>
2025-10-25 04:29:47,916 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 04:29:47,916 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:29:43+00:00 [scheduled]>
2025-10-25 04:29:47,918 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:29:43+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:29:47,918 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:29:43+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 04:29:47,918 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T04:29:43+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:29:47,968 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:29:43+00:00', try_number=1, map_index=-1)
2025-10-25 04:29:47,969 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:29:43+00:00', try_number=1, map_index=-1)
2025-10-25 04:29:47,976 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T04:29:43+00:00, map_index=-1, run_start_date=2025-10-25 04:29:47.365861+00:00, run_end_date=2025-10-25 04:29:47.593903+00:00, run_duration=0.228042, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 04:29:47.005093+00:00, queued_by_job_id=5, pid=125931
2025-10-25 04:29:47,976 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:29:43+00:00 [queued]> to 787129bf-041f-4f40-9f8c-01b8762c517b
2025-10-25 04:29:52,471 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:34:50,537 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:29:43+00:00', try_number=1, map_index=-1)
2025-10-25 04:34:50,543 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T04:29:43+00:00, map_index=-1, run_start_date=2025-10-25 04:29:48.308429+00:00, run_end_date=2025-10-25 04:34:49.999786+00:00, run_duration=301.691357, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 04:29:47.917222+00:00, queued_by_job_id=5, pid=125961
2025-10-25 04:34:51,693 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 04:29:43+00:00: manual__2025-10-25T04:29:43+00:00, state:running, queued_at: 2025-10-25 04:29:46.423927+00:00. externally triggered: True> failed
2025-10-25 04:34:51,694 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 04:29:43+00:00, run_id=manual__2025-10-25T04:29:43+00:00, run_start_date=2025-10-25 04:29:46.983058+00:00, run_end_date=2025-10-25 04:34:51.694286+00:00, run_duration=304.711228, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 04:29:43+00:00, data_interval_end=2025-10-25 04:29:43+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 04:34:52,505 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:39:52,536 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:44:52,570 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:49:52,603 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:54:52,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 04:57:50,795 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:57:44+00:00 [scheduled]>
2025-10-25 04:57:50,795 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 04:57:50,796 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:57:44+00:00 [scheduled]>
2025-10-25 04:57:50,797 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:57:44+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:57:50,798 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:57:44+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 04:57:50,799 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T04:57:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:57:50,855 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:57:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:57:50,864 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:57:44+00:00 [queued]> to a905c9a4-99e6-4f10-a63c-70780beb2683
2025-10-25 04:57:51,701 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:57:44+00:00 [scheduled]>
2025-10-25 04:57:51,702 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 04:57:51,702 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:57:44+00:00 [scheduled]>
2025-10-25 04:57:51,704 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:57:44+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:57:51,704 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:57:44+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 04:57:51,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T04:57:44+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:57:51,752 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:57:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:57:51,753 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:57:44+00:00', try_number=1, map_index=-1)
2025-10-25 04:57:51,762 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T04:57:44+00:00, map_index=-1, run_start_date=2025-10-25 04:57:51.147064+00:00, run_end_date=2025-10-25 04:57:51.396473+00:00, run_duration=0.249409, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 04:57:50.796406+00:00, queued_by_job_id=5, pid=127139
2025-10-25 04:57:51,763 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:57:44+00:00 [queued]> to 00e40970-324b-4880-9a01-962bd1ee2080
2025-10-25 04:58:50,611 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:58:45+00:00 [scheduled]>
2025-10-25 04:58:50,611 INFO - DAG example_dag_with_workers has 1/16 running and queued tasks
2025-10-25 04:58:50,612 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:58:45+00:00 [scheduled]>
2025-10-25 04:58:50,613 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:58:45+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:58:50,614 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:58:45+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 04:58:50,614 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T04:58:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:58:50,661 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:58:45+00:00', try_number=1, map_index=-1)
2025-10-25 04:58:50,666 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T04:58:45+00:00 [queued]> to 2917d892-e027-4700-8acd-6c346b91102c
2025-10-25 04:58:51,772 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:58:45+00:00 [scheduled]>
2025-10-25 04:58:51,772 INFO - DAG example_dag_with_workers has 1/16 running and queued tasks
2025-10-25 04:58:51,773 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:58:45+00:00 [scheduled]>
2025-10-25 04:58:51,774 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:58:45+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 04:58:51,775 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:58:45+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 04:58:51,775 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T04:58:45+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 04:58:51,822 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:58:45+00:00', try_number=1, map_index=-1)
2025-10-25 04:58:51,822 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T04:58:45+00:00', try_number=1, map_index=-1)
2025-10-25 04:58:51,825 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T04:58:45+00:00, map_index=-1, run_start_date=2025-10-25 04:58:50.959399+00:00, run_end_date=2025-10-25 04:58:51.210894+00:00, run_duration=0.251495, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 04:58:50.612420+00:00, queued_by_job_id=5, pid=127328
2025-10-25 04:58:51,826 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T04:58:45+00:00 [queued]> to 8ec10e70-319f-48b9-a5ff-4314935c77ad
2025-10-25 04:59:52,711 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:02:53,799 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:57:44+00:00', try_number=1, map_index=-1)
2025-10-25 05:02:53,803 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T04:57:44+00:00, map_index=-1, run_start_date=2025-10-25 04:57:52.055892+00:00, run_end_date=2025-10-25 05:02:53.444976+00:00, run_duration=301.389084, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 04:57:51.702991+00:00, queued_by_job_id=5, pid=127164
2025-10-25 05:02:55,891 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 04:57:44+00:00: manual__2025-10-25T04:57:44+00:00, state:running, queued_at: 2025-10-25 04:57:50.666266+00:00. externally triggered: True> failed
2025-10-25 05:02:55,891 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 04:57:44+00:00, run_id=manual__2025-10-25T04:57:44+00:00, run_start_date=2025-10-25 04:57:50.772908+00:00, run_end_date=2025-10-25 05:02:55.891538+00:00, run_duration=305.11863, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 04:57:44+00:00, data_interval_end=2025-10-25 04:57:44+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 05:03:54,914 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T04:58:45+00:00', try_number=1, map_index=-1)
2025-10-25 05:03:54,918 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T04:58:45+00:00, map_index=-1, run_start_date=2025-10-25 04:58:52.146904+00:00, run_end_date=2025-10-25 05:03:53.969306+00:00, run_duration=301.822402, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 04:58:51.773674+00:00, queued_by_job_id=5, pid=127354
2025-10-25 05:03:56,699 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 04:58:45+00:00: manual__2025-10-25T04:58:45+00:00, state:running, queued_at: 2025-10-25 04:58:50.069263+00:00. externally triggered: True> failed
2025-10-25 05:03:56,700 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 04:58:45+00:00, run_id=manual__2025-10-25T04:58:45+00:00, run_start_date=2025-10-25 04:58:50.575895+00:00, run_end_date=2025-10-25 05:03:56.700146+00:00, run_duration=306.124251, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 04:58:45+00:00, data_interval_end=2025-10-25 04:58:45+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 05:04:52,742 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:09:33,415 INFO - Exiting gracefully upon receiving signal 15
2025-10-25 05:09:33,505 INFO - Sending 15 to group 72151. PIDs of all processes in the group: []
2025-10-25 05:09:33,505 INFO - Sending the signal 15 to group 72151
2025-10-25 05:09:33,506 INFO - Sending the signal 15 to process 72151 as process group is missing.
2025-10-25 05:09:33,506 INFO - Sending 15 to group 72151. PIDs of all processes in the group: []
2025-10-25 05:09:33,507 INFO - Sending the signal 15 to group 72151
2025-10-25 05:09:33,507 INFO - Sending the signal 15 to process 72151 as process group is missing.
2025-10-25 05:09:33,507 INFO - Exited execute loop
2025-10-25 05:09:38,220 INFO - Loaded executor: CeleryExecutor
2025-10-25 05:09:38,247 INFO - Starting the scheduler
2025-10-25 05:09:38,248 INFO - Processing each file at most -1 times
2025-10-25 05:09:38,254 INFO - Launched DagFileProcessorManager with pid: 128374
2025-10-25 05:09:38,255 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:09:38,261 INFO - Configured default timezone UTC
2025-10-25 05:09:57,648 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:09:52+00:00 [scheduled]>
2025-10-25 05:09:57,648 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 05:09:57,648 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:09:52+00:00 [scheduled]>
2025-10-25 05:09:57,650 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:09:52+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:09:57,651 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T05:09:52+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 05:09:57,651 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T05:09:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 05:09:57,782 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T05:09:52+00:00', try_number=1, map_index=-1)
2025-10-25 05:09:57,792 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:09:52+00:00 [queued]> to a0f978e8-e936-42f4-8dc6-f7466bda67e4
2025-10-25 05:09:59,473 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:09:52+00:00 [scheduled]>
2025-10-25 05:09:59,473 INFO - DAG example_dag_with_workers has 0/16 running and queued tasks
2025-10-25 05:09:59,474 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:09:52+00:00 [scheduled]>
2025-10-25 05:09:59,475 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:09:52+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:09:59,476 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T05:09:52+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 05:09:59,476 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T05:09:52+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 05:09:59,542 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T05:09:52+00:00', try_number=1, map_index=-1)
2025-10-25 05:09:59,543 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T05:09:52+00:00', try_number=1, map_index=-1)
2025-10-25 05:09:59,549 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T05:09:52+00:00, map_index=-1, run_start_date=2025-10-25 05:09:58.065115+00:00, run_end_date=2025-10-25 05:09:58.337005+00:00, run_duration=0.27189, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 05:09:57.649313+00:00, queued_by_job_id=120, pid=128414
2025-10-25 05:09:59,550 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:09:52+00:00 [queued]> to 1fcee1c9-89da-43da-ab81-7287f6b4f6da
2025-10-25 05:10:50,020 INFO - Exiting gracefully upon receiving signal 15
2025-10-25 05:10:50,108 INFO - Sending 15 to group 128374. PIDs of all processes in the group: []
2025-10-25 05:10:50,108 INFO - Sending the signal 15 to group 128374
2025-10-25 05:10:50,108 INFO - Sending the signal 15 to process 128374 as process group is missing.
2025-10-25 05:10:50,124 INFO - Sending 15 to group 128374. PIDs of all processes in the group: []
2025-10-25 05:10:50,124 INFO - Sending the signal 15 to group 128374
2025-10-25 05:10:50,124 INFO - Sending the signal 15 to process 128374 as process group is missing.
2025-10-25 05:10:50,124 INFO - Exited execute loop
2025-10-25 05:10:54,738 INFO - Loaded executor: CeleryExecutor
2025-10-25 05:10:54,762 INFO - Starting the scheduler
2025-10-25 05:10:54,762 INFO - Processing each file at most -1 times
2025-10-25 05:10:54,767 INFO - Launched DagFileProcessorManager with pid: 128609
2025-10-25 05:10:54,768 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:10:54,774 INFO - Configured default timezone UTC
2025-10-25 05:10:54,867 INFO - Adopted the following 1 tasks from a dead executor
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:09:52+00:00 [running]> in state STARTED
2025-10-25 05:11:42,472 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:11:34+00:00 [scheduled]>
2025-10-25 05:11:42,473 INFO - DAG example_dag_with_workers has 1/16 running and queued tasks
2025-10-25 05:11:42,473 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:11:34+00:00 [scheduled]>
2025-10-25 05:11:42,476 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:11:34+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:11:42,477 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T05:11:34+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 05:11:42,477 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'start', 'manual__2025-10-25T05:11:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 05:11:42,595 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T05:11:34+00:00', try_number=1, map_index=-1)
2025-10-25 05:11:42,604 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.start manual__2025-10-25T05:11:34+00:00 [queued]> to ec01235a-3828-4640-a2ea-5117c45b3158
2025-10-25 05:11:43,718 INFO - 1 tasks up for execution:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:11:34+00:00 [scheduled]>
2025-10-25 05:11:43,719 INFO - DAG example_dag_with_workers has 1/16 running and queued tasks
2025-10-25 05:11:43,719 INFO - Setting the following tasks to queued state:
	<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:11:34+00:00 [scheduled]>
2025-10-25 05:11:43,721 INFO - Trying to enqueue tasks: [<TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:11:34+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:11:43,721 INFO - Sending TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T05:11:34+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 05:11:43,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'example_dag_with_workers', 'remote_task_1', 'manual__2025-10-25T05:11:34+00:00', '--local', '--subdir', 'DAGS_FOLDER/example_dag_with_workers.py']
2025-10-25 05:11:43,767 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T05:11:34+00:00', try_number=1, map_index=-1)
2025-10-25 05:11:43,767 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='start', run_id='manual__2025-10-25T05:11:34+00:00', try_number=1, map_index=-1)
2025-10-25 05:11:43,772 INFO - Setting external_id for <TaskInstance: example_dag_with_workers.remote_task_1 manual__2025-10-25T05:11:34+00:00 [queued]> to ad2eef0b-2b7b-4a18-9fe5-f6156987065c
2025-10-25 05:11:43,773 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=start, run_id=manual__2025-10-25T05:11:34+00:00, map_index=-1, run_start_date=2025-10-25 05:11:42.980119+00:00, run_end_date=2025-10-25 05:11:43.255051+00:00, run_duration=0.274932, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-10-25 05:11:42.474608+00:00, queued_by_job_id=123, pid=128754
2025-10-25 05:15:02,346 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T05:09:52+00:00', try_number=1, map_index=-1)
2025-10-25 05:15:02,352 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T05:09:52+00:00, map_index=-1, run_start_date=2025-10-25 05:09:59.823947+00:00, run_end_date=2025-10-25 05:15:01.543909+00:00, run_duration=301.719962, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 05:09:59.474537+00:00, queued_by_job_id=123, pid=128441
2025-10-25 05:15:04,172 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 05:09:52+00:00: manual__2025-10-25T05:09:52+00:00, state:running, queued_at: 2025-10-25 05:09:56.745460+00:00. externally triggered: True> failed
2025-10-25 05:15:04,173 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 05:09:52+00:00, run_id=manual__2025-10-25T05:09:52+00:00, run_start_date=2025-10-25 05:09:57.487826+00:00, run_end_date=2025-10-25 05:15:04.173740+00:00, run_duration=306.685914, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 05:09:52+00:00, data_interval_end=2025-10-25 05:09:52+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 05:15:54,932 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:16:46,575 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='example_dag_with_workers', task_id='remote_task_1', run_id='manual__2025-10-25T05:11:34+00:00', try_number=1, map_index=-1)
2025-10-25 05:16:46,580 INFO - TaskInstance Finished: dag_id=example_dag_with_workers, task_id=remote_task_1, run_id=manual__2025-10-25T05:11:34+00:00, map_index=-1, run_start_date=2025-10-25 05:11:44.082060+00:00, run_end_date=2025-10-25 05:16:45.736576+00:00, run_duration=301.654516, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperator, queued_dttm=2025-10-25 05:11:43.719839+00:00, queued_by_job_id=123, pid=128779
2025-10-25 05:16:48,382 ERROR - Marking run <DagRun example_dag_with_workers @ 2025-10-25 05:11:34+00:00: manual__2025-10-25T05:11:34+00:00, state:running, queued_at: 2025-10-25 05:11:41.601380+00:00. externally triggered: True> failed
2025-10-25 05:16:48,383 INFO - DagRun Finished: dag_id=example_dag_with_workers, execution_date=2025-10-25 05:11:34+00:00, run_id=manual__2025-10-25T05:11:34+00:00, run_start_date=2025-10-25 05:11:42.435060+00:00, run_end_date=2025-10-25 05:16:48.383465+00:00, run_duration=305.948405, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 05:11:34+00:00, data_interval_end=2025-10-25 05:11:34+00:00, dag_hash=00f83e27c80c43b17eb9c896bc1f93da
2025-10-25 05:20:54,971 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:25:55,005 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:30:55,043 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:35:55,076 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:37:16,180 INFO - 1 tasks up for execution:
	<TaskInstance: test_smart_v2.print_info manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:16,180 INFO - DAG test_smart_v2 has 0/16 running and queued tasks
2025-10-25 05:37:16,181 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_smart_v2.print_info manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:16,183 INFO - Trying to enqueue tasks: [<TaskInstance: test_smart_v2.print_info manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:37:16,183 INFO - Sending TaskInstanceKey(dag_id='test_smart_v2', task_id='print_info', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 7 and queue default
2025-10-25 05:37:16,183 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_smart_v2', 'print_info', 'manual__2025-10-25T05:37:14.593992+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_smart_v2.py']
2025-10-25 05:37:16,232 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='print_info', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:16,239 INFO - Setting external_id for <TaskInstance: test_smart_v2.print_info manual__2025-10-25T05:37:14.593992+00:00 [queued]> to cdeed9db-b17d-43ee-9952-d0d868cdb9fc
2025-10-25 05:37:17,352 INFO - 1 tasks up for execution:
	<TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:17,353 INFO - DAG test_smart_v2 has 0/16 running and queued tasks
2025-10-25 05:37:17,353 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:17,355 INFO - Trying to enqueue tasks: [<TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:37:17,356 INFO - Sending TaskInstanceKey(dag_id='test_smart_v2', task_id='test_simple_command', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-25 05:37:17,356 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_smart_v2', 'test_simple_command', 'manual__2025-10-25T05:37:14.593992+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_smart_v2.py']
2025-10-25 05:37:17,414 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_simple_command', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:17,414 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='print_info', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:17,419 INFO - Setting external_id for <TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [queued]> to b47d949b-1bf8-4ecf-b020-b820595d0977
2025-10-25 05:37:17,419 INFO - TaskInstance Finished: dag_id=test_smart_v2, task_id=print_info, run_id=manual__2025-10-25T05:37:14.593992+00:00, map_index=-1, run_start_date=2025-10-25 05:37:16.545590+00:00, run_end_date=2025-10-25 05:37:16.764324+00:00, run_duration=0.218734, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2025-10-25 05:37:16.181538+00:00, queued_by_job_id=123, pid=130025
2025-10-25 05:37:19,122 INFO - 1 tasks up for execution:
	<TaskInstance: test_smart_v2.test_directory_structure manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:19,122 INFO - DAG test_smart_v2 has 0/16 running and queued tasks
2025-10-25 05:37:19,123 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_smart_v2.test_directory_structure manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:19,124 INFO - Trying to enqueue tasks: [<TaskInstance: test_smart_v2.test_directory_structure manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:37:19,124 INFO - Sending TaskInstanceKey(dag_id='test_smart_v2', task_id='test_directory_structure', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 05:37:19,125 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_smart_v2', 'test_directory_structure', 'manual__2025-10-25T05:37:14.593992+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_smart_v2.py']
2025-10-25 05:37:19,192 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_directory_structure', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:19,194 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_simple_command', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:19,202 INFO - Setting external_id for <TaskInstance: test_smart_v2.test_directory_structure manual__2025-10-25T05:37:14.593992+00:00 [queued]> to 0d067395-e16f-4599-8bfe-3b9c911f1a6c
2025-10-25 05:37:19,203 INFO - TaskInstance Finished: dag_id=test_smart_v2, task_id=test_simple_command, run_id=manual__2025-10-25T05:37:14.593992+00:00, map_index=-1, run_start_date=2025-10-25 05:37:17.728774+00:00, run_end_date=2025-10-25 05:37:18.615567+00:00, run_duration=0.886793, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=6, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 05:37:17.353882+00:00, queued_by_job_id=123, pid=130049
2025-10-25 05:37:20,320 INFO - 1 tasks up for execution:
	<TaskInstance: test_smart_v2.test_singularity manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:20,321 INFO - DAG test_smart_v2 has 0/16 running and queued tasks
2025-10-25 05:37:20,321 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_smart_v2.test_singularity manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:20,324 INFO - Trying to enqueue tasks: [<TaskInstance: test_smart_v2.test_singularity manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:37:20,325 INFO - Sending TaskInstanceKey(dag_id='test_smart_v2', task_id='test_singularity', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 05:37:20,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_smart_v2', 'test_singularity', 'manual__2025-10-25T05:37:14.593992+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_smart_v2.py']
2025-10-25 05:37:20,373 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_singularity', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:20,373 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_directory_structure', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:20,382 INFO - Setting external_id for <TaskInstance: test_smart_v2.test_singularity manual__2025-10-25T05:37:14.593992+00:00 [queued]> to d8a6e849-f94c-411a-a755-c109d5ba2ba0
2025-10-25 05:37:20,383 INFO - TaskInstance Finished: dag_id=test_smart_v2, task_id=test_directory_structure, run_id=manual__2025-10-25T05:37:14.593992+00:00, map_index=-1, run_start_date=2025-10-25 05:37:19.490272+00:00, run_end_date=2025-10-25 05:37:20.087844+00:00, run_duration=0.597572, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=5, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 05:37:19.123389+00:00, queued_by_job_id=123, pid=130082
2025-10-25 05:37:21,494 INFO - 1 tasks up for execution:
	<TaskInstance: test_smart_v2.test_python_in_singularity manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:21,495 INFO - DAG test_smart_v2 has 0/16 running and queued tasks
2025-10-25 05:37:21,495 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_smart_v2.test_python_in_singularity manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:21,497 INFO - Trying to enqueue tasks: [<TaskInstance: test_smart_v2.test_python_in_singularity manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:37:21,498 INFO - Sending TaskInstanceKey(dag_id='test_smart_v2', task_id='test_python_in_singularity', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-25 05:37:21,498 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_smart_v2', 'test_python_in_singularity', 'manual__2025-10-25T05:37:14.593992+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_smart_v2.py']
2025-10-25 05:37:21,545 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_python_in_singularity', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:21,546 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_singularity', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:21,551 INFO - Setting external_id for <TaskInstance: test_smart_v2.test_python_in_singularity manual__2025-10-25T05:37:14.593992+00:00 [queued]> to 52b56e4a-416c-46df-bc79-4ba9c7988de2
2025-10-25 05:37:21,552 INFO - TaskInstance Finished: dag_id=test_smart_v2, task_id=test_singularity, run_id=manual__2025-10-25T05:37:14.593992+00:00, map_index=-1, run_start_date=2025-10-25 05:37:20.730091+00:00, run_end_date=2025-10-25 05:37:21.342817+00:00, run_duration=0.612726, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 05:37:20.322095+00:00, queued_by_job_id=123, pid=130112
2025-10-25 05:37:23,738 INFO - 1 tasks up for execution:
	<TaskInstance: test_smart_v2.print_results manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:23,738 INFO - DAG test_smart_v2 has 0/16 running and queued tasks
2025-10-25 05:37:23,738 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_smart_v2.print_results manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>
2025-10-25 05:37:23,740 INFO - Trying to enqueue tasks: [<TaskInstance: test_smart_v2.print_results manual__2025-10-25T05:37:14.593992+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 05:37:23,740 INFO - Sending TaskInstanceKey(dag_id='test_smart_v2', task_id='print_results', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 05:37:23,741 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_smart_v2', 'print_results', 'manual__2025-10-25T05:37:14.593992+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_smart_v2.py']
2025-10-25 05:37:23,799 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='print_results', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:23,799 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='test_python_in_singularity', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:23,805 INFO - Setting external_id for <TaskInstance: test_smart_v2.print_results manual__2025-10-25T05:37:14.593992+00:00 [queued]> to 9053ce2f-4b94-40e1-bd1e-adfd18bc0234
2025-10-25 05:37:23,806 INFO - TaskInstance Finished: dag_id=test_smart_v2, task_id=test_python_in_singularity, run_id=manual__2025-10-25T05:37:14.593992+00:00, map_index=-1, run_start_date=2025-10-25 05:37:21.853734+00:00, run_end_date=2025-10-25 05:37:22.593994+00:00, run_duration=0.74026, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=3, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 05:37:21.496214+00:00, queued_by_job_id=123, pid=130142
2025-10-25 05:37:25,372 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_smart_v2', task_id='print_results', run_id='manual__2025-10-25T05:37:14.593992+00:00', try_number=1, map_index=-1)
2025-10-25 05:37:25,376 INFO - TaskInstance Finished: dag_id=test_smart_v2, task_id=print_results, run_id=manual__2025-10-25T05:37:14.593992+00:00, map_index=-1, run_start_date=2025-10-25 05:37:24.110985+00:00, run_end_date=2025-10-25 05:37:24.412591+00:00, run_duration=0.301606, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 05:37:23.739167+00:00, queued_by_job_id=123, pid=130173
2025-10-25 05:37:26,409 INFO - Marking run <DagRun test_smart_v2 @ 2025-10-25 05:37:14.593992+00:00: manual__2025-10-25T05:37:14.593992+00:00, state:running, queued_at: 2025-10-25 05:37:14.610702+00:00. externally triggered: True> successful
2025-10-25 05:37:26,409 INFO - DagRun Finished: dag_id=test_smart_v2, execution_date=2025-10-25 05:37:14.593992+00:00, run_id=manual__2025-10-25T05:37:14.593992+00:00, run_start_date=2025-10-25 05:37:15.109082+00:00, run_end_date=2025-10-25 05:37:26.409926+00:00, run_duration=11.300844, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 05:37:14.593992+00:00, data_interval_end=2025-10-25 05:37:14.593992+00:00, dag_hash=12a70d192902c8bcd79ab10402abf2a7
2025-10-25 05:40:55,121 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:45:55,152 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:50:55,184 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 05:55:55,216 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:00:55,247 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:05:55,302 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:10:55,355 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:15:55,396 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:20:55,431 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:25:55,467 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:30:55,505 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:32:44,523 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:44,524 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:32:44,524 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:44,526 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:32:44,526 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='print_banner', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 9 and queue default
2025-10-25 06:32:44,526 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'print_banner', 'manual__2025-10-25T06:32:43.058270+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:32:44,586 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='print_banner', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:44,592 INFO - Setting external_id for <TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:32:43.058270+00:00 [queued]> to 11c96181-378c-460d-b610-852c58f4d6e7
2025-10-25 06:32:45,702 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:45,702 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:32:45,703 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:45,704 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:32:45,705 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='get_connection_info', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 8 and queue default
2025-10-25 06:32:45,705 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'get_connection_info', 'manual__2025-10-25T06:32:43.058270+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:32:45,779 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='get_connection_info', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:45,779 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='print_banner', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:45,786 INFO - Setting external_id for <TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:32:43.058270+00:00 [queued]> to bd97cd87-720a-4d17-ac70-95f5ef27fe49
2025-10-25 06:32:45,786 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=print_banner, run_id=manual__2025-10-25T06:32:43.058270+00:00, map_index=-1, run_start_date=2025-10-25 06:32:44.931552+00:00, run_end_date=2025-10-25 06:32:45.176050+00:00, run_duration=0.244498, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=132, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2025-10-25 06:32:44.524889+00:00, queued_by_job_id=123, pid=131732
2025-10-25 06:32:46,876 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:46,876 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:32:46,877 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:46,878 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:32:46,879 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_ssh_connection', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 7 and queue default
2025-10-25 06:32:46,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_ssh_connection', 'manual__2025-10-25T06:32:43.058270+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:32:46,937 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_ssh_connection', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:46,938 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='get_connection_info', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:46,943 INFO - Setting external_id for <TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:32:43.058270+00:00 [queued]> to 318d6896-a1aa-4151-b435-1c896af8653e
2025-10-25 06:32:46,944 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=get_connection_info, run_id=manual__2025-10-25T06:32:43.058270+00:00, map_index=-1, run_start_date=2025-10-25 06:32:46.097961+00:00, run_end_date=2025-10-25 06:32:46.349574+00:00, run_duration=0.251613, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=133, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2025-10-25 06:32:45.703593+00:00, queued_by_job_id=123, pid=131756
2025-10-25 06:32:48,528 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:48,528 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:32:48,529 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:48,531 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:32:48,531 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_basic_execution', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-25 06:32:48,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_basic_execution', 'manual__2025-10-25T06:32:43.058270+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:32:48,580 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_basic_execution', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:48,581 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_ssh_connection', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:48,585 INFO - Setting external_id for <TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:32:43.058270+00:00 [queued]> to 3091e8dd-1994-4620-9531-3e06d3ce0317
2025-10-25 06:32:48,586 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_ssh_connection, run_id=manual__2025-10-25T06:32:43.058270+00:00, map_index=-1, run_start_date=2025-10-25 06:32:47.225845+00:00, run_end_date=2025-10-25 06:32:48.165165+00:00, run_duration=0.93932, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=134, pool=default_pool, queue=default, priority_weight=7, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:32:46.877698+00:00, queued_by_job_id=123, pid=131782
2025-10-25 06:32:49,707 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:49,708 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:32:49,708 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:32:49,713 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:32:49,713 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 06:32:49,714 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_complex_task', 'manual__2025-10-25T06:32:43.058270+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:32:49,781 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:49,782 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_basic_execution', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:32:49,791 INFO - Setting external_id for <TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [queued]> to cc129cc7-0a34-4ef9-a836-845d6c399cec
2025-10-25 06:32:49,792 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_basic_execution, run_id=manual__2025-10-25T06:32:43.058270+00:00, map_index=-1, run_start_date=2025-10-25 06:32:48.878063+00:00, run_end_date=2025-10-25 06:32:49.574771+00:00, run_duration=0.696708, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=135, pool=default_pool, queue=default, priority_weight=6, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:32:48.529816+00:00, queued_by_job_id=123, pid=131813
2025-10-25 06:35:55,573 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:37:51,730 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=1, map_index=-1)
2025-10-25 06:37:51,735 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_complex_task, run_id=manual__2025-10-25T06:32:43.058270+00:00, map_index=-1, run_start_date=2025-10-25 06:32:50.136768+00:00, run_end_date=2025-10-25 06:37:51.142807+00:00, run_duration=301.006039, state=up_for_retry, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=136, pool=default_pool, queue=default, priority_weight=5, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:32:49.708966+00:00, queued_by_job_id=123, pid=131843
2025-10-25 06:38:51,180 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:38:51,180 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:38:51,180 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>
2025-10-25 06:38:51,183 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:38:51,183 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=2, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 06:38:51,184 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_complex_task', 'manual__2025-10-25T06:32:43.058270+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:38:51,244 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=2, map_index=-1)
2025-10-25 06:38:51,252 INFO - Setting external_id for <TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:32:43.058270+00:00 [queued]> to f2e6adf8-0443-4c0c-a436-7d97618eb00c
2025-10-25 06:40:55,590 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:43:53,880 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:32:43.058270+00:00', try_number=2, map_index=-1)
2025-10-25 06:43:53,884 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_complex_task, run_id=manual__2025-10-25T06:32:43.058270+00:00, map_index=-1, run_start_date=2025-10-25 06:38:51.553664+00:00, run_end_date=2025-10-25 06:43:52.865358+00:00, run_duration=301.311694, state=failed, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=137, pool=default_pool, queue=default, priority_weight=5, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:38:51.181593+00:00, queued_by_job_id=123, pid=132487
2025-10-25 06:43:55,950 ERROR - Marking run <DagRun full_integration_test @ 2025-10-25 06:32:43.058270+00:00: manual__2025-10-25T06:32:43.058270+00:00, state:running, queued_at: 2025-10-25 06:32:43.073430+00:00. externally triggered: True> failed
2025-10-25 06:43:55,950 INFO - DagRun Finished: dag_id=full_integration_test, execution_date=2025-10-25 06:32:43.058270+00:00, run_id=manual__2025-10-25T06:32:43.058270+00:00, run_start_date=2025-10-25 06:32:43.456471+00:00, run_end_date=2025-10-25 06:43:55.950648+00:00, run_duration=672.494177, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 06:32:43.058270+00:00, data_interval_end=2025-10-25 06:32:43.058270+00:00, dag_hash=91342a19b5ad9d09c36ee8434bf3def1
2025-10-25 06:45:55,621 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:50:30,691 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:30,691 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:30,692 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:30,694 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:30,694 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='print_banner', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 9 and queue default
2025-10-25 06:50:30,695 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'print_banner', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:30,753 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='print_banner', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:30,758 INFO - Setting external_id for <TaskInstance: full_integration_test.print_banner manual__2025-10-25T06:50:29.396716+00:00 [queued]> to 2acc9d8b-1601-4ef1-bc91-2d968de38bfd
2025-10-25 06:50:31,846 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:31,847 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:31,847 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:31,849 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:31,849 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='get_connection_info', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 8 and queue default
2025-10-25 06:50:31,849 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'get_connection_info', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:31,908 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='get_connection_info', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:31,908 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='print_banner', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:31,914 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=print_banner, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:31.085390+00:00, run_end_date=2025-10-25 06:50:31.320457+00:00, run_duration=0.235067, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=138, pool=default_pool, queue=default, priority_weight=9, operator=PythonOperator, queued_dttm=2025-10-25 06:50:30.692634+00:00, queued_by_job_id=123, pid=133371
2025-10-25 06:50:31,915 INFO - Setting external_id for <TaskInstance: full_integration_test.get_connection_info manual__2025-10-25T06:50:29.396716+00:00 [queued]> to 306adfce-b79c-40b8-9660-7958dc7a3eaf
2025-10-25 06:50:33,008 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:33,008 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:33,008 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:33,010 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:33,010 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_ssh_connection', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 7 and queue default
2025-10-25 06:50:33,011 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_ssh_connection', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:33,060 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_ssh_connection', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:33,061 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='get_connection_info', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:33,067 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=get_connection_info, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:32.224956+00:00, run_end_date=2025-10-25 06:50:32.481984+00:00, run_duration=0.257028, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=139, pool=default_pool, queue=default, priority_weight=8, operator=PythonOperator, queued_dttm=2025-10-25 06:50:31.847965+00:00, queued_by_job_id=123, pid=133395
2025-10-25 06:50:33,068 INFO - Setting external_id for <TaskInstance: full_integration_test.test_ssh_connection manual__2025-10-25T06:50:29.396716+00:00 [queued]> to 6d2f7ab8-3ea9-4a97-8f89-b8f258917ad0
2025-10-25 06:50:34,683 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:34,684 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:34,684 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:34,686 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:34,686 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_basic_execution', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 6 and queue default
2025-10-25 06:50:34,686 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_basic_execution', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:34,741 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_basic_execution', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:34,741 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_ssh_connection', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:34,746 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_ssh_connection, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:33.359503+00:00, run_end_date=2025-10-25 06:50:34.304735+00:00, run_duration=0.945232, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=140, pool=default_pool, queue=default, priority_weight=7, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:50:33.009226+00:00, queued_by_job_id=123, pid=133421
2025-10-25 06:50:34,747 INFO - Setting external_id for <TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [queued]> to 0ed91494-ca6b-47e8-813b-1083674deeb6
2025-10-25 06:50:35,858 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:35,858 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:35,859 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:35,861 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:35,861 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 5 and queue default
2025-10-25 06:50:35,862 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_complex_task', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:35,923 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:35,923 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_basic_execution', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:35,929 INFO - Setting external_id for <TaskInstance: full_integration_test.test_complex_task manual__2025-10-25T06:50:29.396716+00:00 [queued]> to fe28932c-c287-4397-95c1-96d74f9742e3
2025-10-25 06:50:35,930 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_basic_execution, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:35.033900+00:00, run_end_date=2025-10-25 06:50:35.715556+00:00, run_duration=0.681656, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=141, pool=default_pool, queue=default, priority_weight=6, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:50:34.685090+00:00, queued_by_job_id=123, pid=133452
2025-10-25 06:50:41,909 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.test_singularity_execution manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:41,910 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:41,910 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.test_singularity_execution manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:41,912 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.test_singularity_execution manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:41,913 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='test_singularity_execution', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 4 and queue default
2025-10-25 06:50:41,913 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_singularity_execution', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:41,963 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_singularity_execution', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:41,963 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_complex_task', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:41,970 INFO - Setting external_id for <TaskInstance: full_integration_test.test_singularity_execution manual__2025-10-25T06:50:29.396716+00:00 [queued]> to ae892f18-b628-489e-bd1e-4c6c01ccccfe
2025-10-25 06:50:41,970 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_complex_task, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:36.235409+00:00, run_end_date=2025-10-25 06:50:41.396873+00:00, run_duration=5.161464, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=142, pool=default_pool, queue=default, priority_weight=5, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:50:35.859968+00:00, queued_by_job_id=123, pid=133483
2025-10-25 06:50:43,080 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.collect_results manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:43,080 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:43,080 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.collect_results manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:43,082 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.collect_results manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:43,083 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='collect_results', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 3 and queue default
2025-10-25 06:50:43,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'collect_results', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:43,140 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='collect_results', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:43,141 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='test_singularity_execution', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:43,148 INFO - Setting external_id for <TaskInstance: full_integration_test.collect_results manual__2025-10-25T06:50:29.396716+00:00 [queued]> to b9eaeed1-a56b-42c5-9531-6758de94eb1e
2025-10-25 06:50:43,149 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=test_singularity_execution, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:42.284173+00:00, run_end_date=2025-10-25 06:50:42.903888+00:00, run_duration=0.619715, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=143, pool=default_pool, queue=default, priority_weight=4, operator=SmartRemoteWorkerOperatorV2, queued_dttm=2025-10-25 06:50:41.911209+00:00, queued_by_job_id=123, pid=133524
2025-10-25 06:50:44,248 INFO - 1 tasks up for execution:
	<TaskInstance: full_integration_test.cleanup manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:44,249 INFO - DAG full_integration_test has 0/16 running and queued tasks
2025-10-25 06:50:44,249 INFO - Setting the following tasks to queued state:
	<TaskInstance: full_integration_test.cleanup manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>
2025-10-25 06:50:44,250 INFO - Trying to enqueue tasks: [<TaskInstance: full_integration_test.cleanup manual__2025-10-25T06:50:29.396716+00:00 [scheduled]>] for executor: CeleryExecutor(parallelism=32)
2025-10-25 06:50:44,251 INFO - Sending TaskInstanceKey(dag_id='full_integration_test', task_id='cleanup', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1) to CeleryExecutor with priority 2 and queue default
2025-10-25 06:50:44,251 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'full_integration_test', 'cleanup', 'manual__2025-10-25T06:50:29.396716+00:00', '--local', '--subdir', 'DAGS_FOLDER/full_integration_test.py']
2025-10-25 06:50:44,305 INFO - Received executor event with state queued for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='cleanup', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:44,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='collect_results', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:44,309 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=collect_results, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:43.453428+00:00, run_end_date=2025-10-25 06:50:43.731320+00:00, run_duration=0.277892, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=144, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-10-25 06:50:43.081340+00:00, queued_by_job_id=123, pid=133554
2025-10-25 06:50:44,310 INFO - Setting external_id for <TaskInstance: full_integration_test.cleanup manual__2025-10-25T06:50:29.396716+00:00 [queued]> to 63edd043-032c-4a93-bab7-ba1e8cb066ab
2025-10-25 06:50:45,913 INFO - Marking run <DagRun full_integration_test @ 2025-10-25 06:50:29.396716+00:00: manual__2025-10-25T06:50:29.396716+00:00, state:running, queued_at: 2025-10-25 06:50:29.410413+00:00. externally triggered: True> successful
2025-10-25 06:50:45,914 INFO - DagRun Finished: dag_id=full_integration_test, execution_date=2025-10-25 06:50:29.396716+00:00, run_id=manual__2025-10-25T06:50:29.396716+00:00, run_start_date=2025-10-25 06:50:29.618342+00:00, run_end_date=2025-10-25 06:50:45.914094+00:00, run_duration=16.295752, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-10-25 06:50:29.396716+00:00, data_interval_end=2025-10-25 06:50:29.396716+00:00, dag_hash=87853b6119145617d57e51f8fc06a555
2025-10-25 06:50:45,940 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='full_integration_test', task_id='cleanup', run_id='manual__2025-10-25T06:50:29.396716+00:00', try_number=1, map_index=-1)
2025-10-25 06:50:45,946 INFO - TaskInstance Finished: dag_id=full_integration_test, task_id=cleanup, run_id=manual__2025-10-25T06:50:29.396716+00:00, map_index=-1, run_start_date=2025-10-25 06:50:44.590660+00:00, run_end_date=2025-10-25 06:50:44.793839+00:00, run_duration=0.203179, state=success, executor=CeleryExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=145, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-25 06:50:44.249686+00:00, queued_by_job_id=123, pid=133582
2025-10-25 06:50:55,653 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 06:55:55,686 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 07:00:55,729 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 07:05:55,760 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 07:10:55,811 INFO - Adopting or resetting orphaned tasks for active dag runs
2025-10-25 07:15:55,849 INFO - Adopting or resetting orphaned tasks for active dag runs
