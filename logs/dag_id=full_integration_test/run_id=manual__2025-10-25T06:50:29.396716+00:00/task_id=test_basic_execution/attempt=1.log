[2025-10-25T06:50:35.009+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-25T06:50:35.033+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [queued]>
[2025-10-25T06:50:35.044+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [queued]>
[2025-10-25T06:50:35.044+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-10-25T06:50:35.058+0000] {taskinstance.py:2888} INFO - Executing <Task(SmartRemoteWorkerOperatorV2): test_basic_execution> on 2025-10-25 06:50:29.396716+00:00
[2025-10-25T06:50:35.066+0000] {warnings.py:110} WARNING - /home/airflow/airflow-env/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=133441) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-25T06:50:35.067+0000] {standard_task_runner.py:72} INFO - Started process 133452 to run task
[2025-10-25T06:50:35.068+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'full_integration_test', 'test_basic_execution', 'manual__2025-10-25T06:50:29.396716+00:00', '--job-id', '141', '--raw', '--subdir', 'DAGS_FOLDER/full_integration_test.py', '--cfg-path', '/tmp/tmp9q_8q32l']
[2025-10-25T06:50:35.071+0000] {standard_task_runner.py:105} INFO - Job 141: Subtask test_basic_execution
[2025-10-25T06:50:35.134+0000] {task_command.py:467} INFO - Running <TaskInstance: full_integration_test.test_basic_execution manual__2025-10-25T06:50:29.396716+00:00 [running]> on host masterdimpal-1
[2025-10-25T06:50:35.225+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='full_integration_test' AIRFLOW_CTX_TASK_ID='test_basic_execution' AIRFLOW_CTX_EXECUTION_DATE='2025-10-25T06:50:29.396716+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-25T06:50:29.396716+00:00'
[2025-10-25T06:50:35.226+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-25T06:50:35.241+0000] {smart_remote_worker_v2.py:254} INFO - ================================================================================
[2025-10-25T06:50:35.241+0000] {smart_remote_worker_v2.py:255} INFO - üöÄ Smart Remote Worker Operator V2 - Starting
[2025-10-25T06:50:35.241+0000] {smart_remote_worker_v2.py:256} INFO - ================================================================================
[2025-10-25T06:50:35.256+0000] {smart_remote_worker_v2.py:57} INFO - üìã Loaded 1 workers from registry
[2025-10-25T06:50:35.256+0000] {smart_remote_worker_v2.py:264} INFO - üìã Selected 1 worker(s)
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:266} INFO -    - worker-1 (priority: 1, host: 45.151.155.74)
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:272} INFO - ================================================================================
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:273} INFO - üéØ ATTEMPT 1/1: Trying worker 'worker-1'
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:274} INFO - ================================================================================
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:194} INFO - üéØ Executing on worker: worker-1
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:195} INFO -    Host: 45.151.155.74
[2025-10-25T06:50:35.257+0000] {smart_remote_worker_v2.py:196} INFO -    AIRFLOW_HOME: /home/airflow/airflow-worker
[2025-10-25T06:50:35.271+0000] {smart_remote_worker_v2.py:125} INFO - ‚úÖ Using existing SSH connection: worker_worker-1
[2025-10-25T06:50:35.284+0000] {base.py:84} INFO - Retrieving connection 'worker_worker-1'
[2025-10-25T06:50:35.287+0000] {smart_remote_worker_v2.py:208} INFO - üì§ Executing command via SSH...
[2025-10-25T06:50:35.287+0000] {smart_remote_worker_v2.py:209} INFO - Command:
#!/bin/bash
set -x

# Setup environment
export AIRFLOW_HOME=/home/airflow/airflow-worker
export WORKER_NAME=worker-1
export QUEUE_NAME=default

echo "====================================="
echo "Starting worker: $WORKER_NAME"
echo "AIRFLOW_HOME: $AIRFLOW_HOME"
echo "====================================="

# Go to Airflow directory
cd $AIRFLOW_HOME || exit 1

# Check for Singularity container
SINGULARITY_IMAGE=""
if [ -f "containers/airflow-worker.sif" ]; then
    SINGULARITY_IMAGE="containers/ai...
[2025-10-25T06:50:35.290+0000] {ssh.py:309} WARNING - No Host Key Verification. This won't protect against Man-In-The-Middle attacks
[2025-10-25T06:50:35.301+0000] {transport.py:1944} INFO - Connected (version 2.0, client OpenSSH_9.6p1)
[2025-10-25T06:50:35.399+0000] {transport.py:1944} INFO - Authentication (publickey) successful!
[2025-10-25T06:50:35.678+0000] {smart_remote_worker_v2.py:221} INFO - üìä Exit status: 0
[2025-10-25T06:50:35.678+0000] {smart_remote_worker_v2.py:224} INFO - üìÑ Output:
=====================================
Starting worker: worker-1
AIRFLOW_HOME: /home/airflow/airflow-worker
=====================================
Found Singularity image: containers/airflow-worker.sif
Singularity is available
Executing command in Singularity container...
==========================================
TEST 2: Basic Command Execution
==========================================

Environment variables:
  AIRFLOW_HOME: /airflow
  USER: airflow
  HOME: /home/airflow

File system check:

Python check:
Python 3.12.12

Network check:
  ‚ö†Ô∏è Internet: Limited

‚úÖ Basic execution tests passed!
==========================================
Command completed with exit code: 0

[2025-10-25T06:50:35.679+0000] {smart_remote_worker_v2.py:227} INFO - ‚ö†Ô∏è Stderr:
+ export AIRFLOW_HOME=/home/airflow/airflow-worker
+ AIRFLOW_HOME=/home/airflow/airflow-worker
+ export WORKER_NAME=worker-1
+ WORKER_NAME=worker-1
+ export QUEUE_NAME=default
+ QUEUE_NAME=default
+ echo =====================================
+ echo 'Starting worker: worker-1'
+ echo 'AIRFLOW_HOME: /home/airflow/airflow-worker'
+ echo =====================================
+ cd /home/airflow/airflow-worker
+ SINGULARITY_IMAGE=
+ '[' -f containers/airflow-worker.sif ']'
+ SINGULARITY_IMAGE=containers/airflow-worker.sif
+ '[' -n containers/airflow-worker.sif ']'
+ echo 'Found Singularity image: containers/airflow-worker.sif'
+ singularity --version
+ echo 'Singularity is available'
+ echo 'Executing command in Singularity container...'
+ singularity exec --bind /home/airflow/airflow-worker:/home/airflow/airflow-worker containers/airflow-worker.sif bash -c '
echo "=========================================="; echo "TEST 2: Basic Command Execution"; echo "=========================================="; echo ""; echo "Environment variables:"; echo "  AIRFLOW_HOME: $AIRFLOW_HOME"; echo "  USER: $USER"; echo "  HOME: $HOME"; echo ""; echo "File system check:"; ls -la $AIRFLOW_HOME | head -10; echo ""; echo "Python check:"; python3 --version 2>/dev/null || python --version; echo ""; echo "Network check:"; ping -c 2 google.com > /dev/null 2>&1 && echo "  ‚úÖ Internet: OK" || echo "  ‚ö†Ô∏è Internet: Limited"; echo ""; echo "‚úÖ Basic execution tests passed!"; echo "=========================================="
'
ls: cannot access '/airflow': No such file or directory
+ exit_code=0
+ echo 'Command completed with exit code: 0'
+ exit 0

[2025-10-25T06:50:35.679+0000] {smart_remote_worker_v2.py:238} INFO - ‚úÖ Task completed successfully on worker-1
[2025-10-25T06:50:35.679+0000] {smart_remote_worker_v2.py:279} INFO - ================================================================================
[2025-10-25T06:50:35.679+0000] {smart_remote_worker_v2.py:280} INFO - ‚úÖ SUCCESS: Task completed
[2025-10-25T06:50:35.679+0000] {smart_remote_worker_v2.py:281} INFO - ================================================================================
[2025-10-25T06:50:35.715+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-25T06:50:35.715+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=full_integration_test, task_id=test_basic_execution, run_id=manual__2025-10-25T06:50:29.396716+00:00, execution_date=20251025T065029, start_date=20251025T065035, end_date=20251025T065035
[2025-10-25T06:50:35.770+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-25T06:50:35.809+0000] {taskinstance.py:3900} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-10-25T06:50:35.811+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
