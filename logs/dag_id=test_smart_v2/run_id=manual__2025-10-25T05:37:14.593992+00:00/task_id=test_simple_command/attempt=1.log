[2025-10-25T05:37:17.703+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-10-25T05:37:17.728+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [queued]>
[2025-10-25T05:37:17.737+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [queued]>
[2025-10-25T05:37:17.738+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-10-25T05:37:17.749+0000] {taskinstance.py:2888} INFO - Executing <Task(SmartRemoteWorkerOperatorV2): test_simple_command> on 2025-10-25 05:37:14.593992+00:00
[2025-10-25T05:37:17.754+0000] {warnings.py:110} WARNING - /home/airflow/airflow-env/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=130038) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-25T05:37:17.755+0000] {standard_task_runner.py:72} INFO - Started process 130049 to run task
[2025-10-25T05:37:17.756+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'test_smart_v2', 'test_simple_command', 'manual__2025-10-25T05:37:14.593992+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/test_smart_v2.py', '--cfg-path', '/tmp/tmpjood4ib9']
[2025-10-25T05:37:17.758+0000] {standard_task_runner.py:105} INFO - Job 127: Subtask test_simple_command
[2025-10-25T05:37:17.815+0000] {task_command.py:467} INFO - Running <TaskInstance: test_smart_v2.test_simple_command manual__2025-10-25T05:37:14.593992+00:00 [running]> on host masterdimpal-1
[2025-10-25T05:37:17.907+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='test_smart_v2' AIRFLOW_CTX_TASK_ID='test_simple_command' AIRFLOW_CTX_EXECUTION_DATE='2025-10-25T05:37:14.593992+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-10-25T05:37:14.593992+00:00'
[2025-10-25T05:37:17.907+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-10-25T05:37:17.923+0000] {smart_remote_worker_v2.py:254} INFO - ================================================================================
[2025-10-25T05:37:17.923+0000] {smart_remote_worker_v2.py:255} INFO - üöÄ Smart Remote Worker Operator V2 - Starting
[2025-10-25T05:37:17.923+0000] {smart_remote_worker_v2.py:256} INFO - ================================================================================
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:57} INFO - üìã Loaded 1 workers from registry
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:264} INFO - üìã Selected 1 worker(s)
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:266} INFO -    - worker-1 (priority: 1, host: 45.151.155.74)
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:272} INFO - ================================================================================
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:273} INFO - üéØ ATTEMPT 1/1: Trying worker 'worker-1'
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:274} INFO - ================================================================================
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:194} INFO - üéØ Executing on worker: worker-1
[2025-10-25T05:37:17.936+0000] {smart_remote_worker_v2.py:195} INFO -    Host: 45.151.155.74
[2025-10-25T05:37:17.937+0000] {smart_remote_worker_v2.py:196} INFO -    AIRFLOW_HOME: /home/airflow/airflow-worker
[2025-10-25T05:37:17.950+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-10-25T05:37:17.954+0000] {smart_remote_worker_v2.py:123} INFO - ‚úÖ Created SSH connection: worker_worker-1
[2025-10-25T05:37:17.966+0000] {base.py:84} INFO - Retrieving connection 'worker_worker-1'
[2025-10-25T05:37:17.967+0000] {smart_remote_worker_v2.py:208} INFO - üì§ Executing command via SSH...
[2025-10-25T05:37:17.967+0000] {smart_remote_worker_v2.py:209} INFO - Command:
#!/bin/bash
set -x

# Setup environment
export AIRFLOW_HOME=/home/airflow/airflow-worker
export WORKER_NAME=worker-1
export QUEUE_NAME=default

echo "====================================="
echo "Starting worker: $WORKER_NAME"
echo "AIRFLOW_HOME: $AIRFLOW_HOME"
echo "====================================="

# Go to Airflow directory
cd $AIRFLOW_HOME || exit 1

# Check for Singularity container
SINGULARITY_IMAGE=""
if [ -f "containers/airflow-worker.sif" ]; then
    SINGULARITY_IMAGE="containers/ai...
[2025-10-25T05:37:17.970+0000] {ssh.py:309} WARNING - No Host Key Verification. This won't protect against Man-In-The-Middle attacks
[2025-10-25T05:37:17.982+0000] {transport.py:1944} INFO - Connected (version 2.0, client OpenSSH_9.6p1)
[2025-10-25T05:37:18.040+0000] {transport.py:1944} INFO - Authentication (publickey) successful!
[2025-10-25T05:37:18.582+0000] {smart_remote_worker_v2.py:221} INFO - üìä Exit status: 0
[2025-10-25T05:37:18.583+0000] {smart_remote_worker_v2.py:224} INFO - üìÑ Output:
=====================================
Starting worker: worker-1
AIRFLOW_HOME: /home/airflow/airflow-worker
=====================================
Found Singularity image: containers/airflow-worker.sif
Singularity is available
Executing command in Singularity container...
==========================================
Simple test on remote worker
Hostname: remotedimpal-2
Date: Sat Oct 25 05:37:18 UTC 2025
PWD: /home/airflow/airflow-worker
User: airflow
==========================================
Command completed with exit code: 0

[2025-10-25T05:37:18.583+0000] {smart_remote_worker_v2.py:227} INFO - ‚ö†Ô∏è Stderr:
+ export AIRFLOW_HOME=/home/airflow/airflow-worker
+ AIRFLOW_HOME=/home/airflow/airflow-worker
+ export WORKER_NAME=worker-1
+ WORKER_NAME=worker-1
+ export QUEUE_NAME=default
+ QUEUE_NAME=default
+ echo =====================================
+ echo 'Starting worker: worker-1'
+ echo 'AIRFLOW_HOME: /home/airflow/airflow-worker'
+ echo =====================================
+ cd /home/airflow/airflow-worker
+ SINGULARITY_IMAGE=
+ '[' -f containers/airflow-worker.sif ']'
+ SINGULARITY_IMAGE=containers/airflow-worker.sif
+ '[' -n containers/airflow-worker.sif ']'
+ echo 'Found Singularity image: containers/airflow-worker.sif'
+ singularity --version
+ echo 'Singularity is available'
+ echo 'Executing command in Singularity container...'
+ singularity exec --bind /home/airflow/airflow-worker:/home/airflow/airflow-worker containers/airflow-worker.sif bash -c '

echo "=========================================="
echo "Simple test on remote worker"
echo "Hostname: $(hostname)"
echo "Date: $(date)"
echo "PWD: $(pwd)"
echo "User: $(whoami)"
echo "=========================================="
'
+ exit_code=0
+ echo 'Command completed with exit code: 0'
+ exit 0

[2025-10-25T05:37:18.583+0000] {smart_remote_worker_v2.py:238} INFO - ‚úÖ Task completed successfully on worker-1
[2025-10-25T05:37:18.583+0000] {smart_remote_worker_v2.py:279} INFO - ================================================================================
[2025-10-25T05:37:18.583+0000] {smart_remote_worker_v2.py:280} INFO - ‚úÖ SUCCESS: Task completed
[2025-10-25T05:37:18.583+0000] {smart_remote_worker_v2.py:281} INFO - ================================================================================
[2025-10-25T05:37:18.615+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-10-25T05:37:18.615+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=test_smart_v2, task_id=test_simple_command, run_id=manual__2025-10-25T05:37:14.593992+00:00, execution_date=20251025T053714, start_date=20251025T053717, end_date=20251025T053718
[2025-10-25T05:37:18.653+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-10-25T05:37:18.688+0000] {taskinstance.py:3900} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-10-25T05:37:18.690+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
